{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a711d1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\domin\\anaconda3\\envs\\simulation_car_sharing\\lib\\site-packages\\geopandas\\_compat.py:123: UserWarning: The Shapely GEOS version (3.8.0-CAPI-1.13.1 ) is incompatible with the GEOS version PyGEOS was compiled with (3.10.4-CAPI-1.16.2). Conversions between both will be slow.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# import libaries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from rl_v2g import CarsharingEnv\n",
    "import math\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import A2C\n",
    "from gym.utils.env_checker import check_env as checker_gym\n",
    "from stable_baselines3.common.env_checker import check_env as checker_baselines3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.logger import configure\n",
    "import random\n",
    "# load the database credentials from the JSON file\n",
    "with open('config/credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "# create connection string\n",
    "connection_string = f\"postgresql://{credentials['username']}:{credentials['password']}@{credentials['host']}:{credentials['port']}/{credentials['database_name']}\"\n",
    "\n",
    "# create the engine with the connection string\n",
    "engine = create_engine(connection_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b0673-9dca-4b10-b742-4f4af1d3bc48",
   "metadata": {},
   "source": [
    "# Application of Car-sharing Simulation Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783aa047-30ec-4998-93ef-aa05f6d709f2",
   "metadata": {},
   "source": [
    "Choose the timespan for the simulation. The simulation will be executed chronologically, starting from the first day (2019-1-1) and continuing for subsequent days (2019-1-2, 2019-1-3, etc.). If a start date other than 2019-1-1 is selected, the \"Start simulation\" cell below may need to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92e923b-e2c0-4257-9028-d30dbdff5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learn period\n",
    "start_date = date(2019, 1, 8)\n",
    "end_date = date(2020, 7, 26)\n",
    "#end_date = date(2019, 1, 10)\n",
    "start_week = 1\n",
    "\n",
    "# set simulation period\n",
    "start_date_simulation = date(2019, 1, 1)\n",
    "end_date_simulation = date(2019, 1, 8)\n",
    "start_week_simulation = 0\n",
    "\n",
    "# calculate number of days to learn\n",
    "nr_iterations = (end_date - start_date).days\n",
    "\n",
    "# calculate number of days to simulate\n",
    "nr_iterations_simulation = (end_date_simulation - start_date_simulation).days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e51f9-3dc9-4a24-9527-95dc871616d6",
   "metadata": {},
   "source": [
    "# Load data for simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec0e94-a367-42fb-bf33-99ef8df0c844",
   "metadata": {},
   "source": [
    "### Car-sharing stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e17d3ddf-c804-442f-8d29-3a23c2305fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_no</th>\n",
       "      <th>geom</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2901</td>\n",
       "      <td>POINT (2555501.836 1145060.068)</td>\n",
       "      <td>2.555502e+06</td>\n",
       "      <td>1.145060e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2905</td>\n",
       "      <td>POINT (2752963.411 1260089.916)</td>\n",
       "      <td>2.752963e+06</td>\n",
       "      <td>1.260090e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2910</td>\n",
       "      <td>POINT (2501877.645 1126218.900)</td>\n",
       "      <td>2.501878e+06</td>\n",
       "      <td>1.126219e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2913</td>\n",
       "      <td>POINT (2682234.096 1243208.370)</td>\n",
       "      <td>2.682234e+06</td>\n",
       "      <td>1.243208e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2918</td>\n",
       "      <td>POINT (2736874.744 1253090.505)</td>\n",
       "      <td>2.736875e+06</td>\n",
       "      <td>1.253091e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_no                             geom             x             y\n",
       "0        2901  POINT (2555501.836 1145060.068)  2.555502e+06  1.145060e+06\n",
       "1        2905  POINT (2752963.411 1260089.916)  2.752963e+06  1.260090e+06\n",
       "2        2910  POINT (2501877.645 1126218.900)  2.501878e+06  1.126219e+06\n",
       "3        2913  POINT (2682234.096 1243208.370)  2.682234e+06  1.243208e+06\n",
       "4        2918  POINT (2736874.744 1253090.505)  2.736875e+06  1.253091e+06"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get station geodata, create spatial index\n",
    "sql = \" SELECT * FROM msc_2023_dominik.distinct_stations\"\n",
    "stations = gpd.read_postgis(sql, engine, geom_col='geom',crs = \"EPSG:2056\")\n",
    "stations[\"x\"] = stations.geom.x.values\n",
    "stations[\"y\"] = stations.geom.y.values\n",
    "stations.sindex\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75c9df-a17b-4aa5-82c7-6b1d9678cac2",
   "metadata": {},
   "source": [
    "### Vehicle information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d8127d0-ea76-4840-8b09-d9dccac60708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>model_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>charge_power</th>\n",
       "      <th>battery_capacity</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2879</td>\n",
       "      <td>Economy</td>\n",
       "      <td>113006</td>\n",
       "      <td>ZOE</td>\n",
       "      <td>Renault</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2880</td>\n",
       "      <td>Economy</td>\n",
       "      <td>113015</td>\n",
       "      <td>ZOE</td>\n",
       "      <td>Renault</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2881</td>\n",
       "      <td>Economy</td>\n",
       "      <td>113017</td>\n",
       "      <td>ZOE</td>\n",
       "      <td>Renault</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2882</td>\n",
       "      <td>Economy</td>\n",
       "      <td>113020</td>\n",
       "      <td>ZOE</td>\n",
       "      <td>Renault</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2883</td>\n",
       "      <td>Economy</td>\n",
       "      <td>113021</td>\n",
       "      <td>ZOE</td>\n",
       "      <td>Renault</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>200.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index vehicle_category  vehicle_no model_name brand_name  charge_power  \\\n",
       "0   2879          Economy      113006        ZOE    Renault          22.0   \n",
       "1   2880          Economy      113015        ZOE    Renault          22.0   \n",
       "2   2881          Economy      113017        ZOE    Renault          22.0   \n",
       "3   2882          Economy      113020        ZOE    Renault          22.0   \n",
       "4   2883          Economy      113021        ZOE    Renault          22.0   \n",
       "\n",
       "   battery_capacity  range  \n",
       "0              41.0  200.0  \n",
       "1              41.0  200.0  \n",
       "2              41.0  200.0  \n",
       "3              41.0  200.0  \n",
       "4              41.0  200.0  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get vehicle data\n",
    "sql = \"SELECT * FROM msc_2023_dominik.vehicle_information ORDER BY vehicle_no limit 15 offset 10\"\n",
    "vehicles = pd.read_sql(sql, engine)\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f35f408-b0ed-42c5-aa0e-225e7ace786f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_nr_list = tuple(vehicles.vehicle_no.values.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd729dc1-8210-4b36-89af-82de5ba78cad",
   "metadata": {},
   "source": [
    "### Reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "361f0fc4-42f0-4efa-a64b-1ded60e626a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_no</th>\n",
       "      <th>start_station_no</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>reservationfrom_time_discrete</th>\n",
       "      <th>drive_firststart_time_discrete</th>\n",
       "      <th>drive_lastend_time_discrete</th>\n",
       "      <th>reservation_duration</th>\n",
       "      <th>revenue_distance</th>\n",
       "      <th>required_soc</th>\n",
       "      <th>revenue_duration</th>\n",
       "      <th>drive_km</th>\n",
       "      <th>drive_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>230</th>\n",
       "      <td>24518458</td>\n",
       "      <td>2086</td>\n",
       "      <td>113023</td>\n",
       "      <td>700.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>24527445</td>\n",
       "      <td>3822</td>\n",
       "      <td>113114</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>24451016</td>\n",
       "      <td>4078</td>\n",
       "      <td>113103</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3692.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>652</th>\n",
       "      <td>24542806</td>\n",
       "      <td>1843</td>\n",
       "      <td>113017</td>\n",
       "      <td>706.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>24535701</td>\n",
       "      <td>1582</td>\n",
       "      <td>113111</td>\n",
       "      <td>714.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reservation_no  start_station_no  vehicle_no  \\\n",
       "230         24518458              2086      113023   \n",
       "307         24527445              3822      113114   \n",
       "315         24451016              4078      113103   \n",
       "652         24542806              1843      113017   \n",
       "1258        24535701              1582      113111   \n",
       "\n",
       "      reservationfrom_time_discrete  drive_firststart_time_discrete  \\\n",
       "230                           700.0                           702.0   \n",
       "307                           700.0                           700.0   \n",
       "315                           700.0                           700.0   \n",
       "652                           706.0                           707.0   \n",
       "1258                          714.0                           715.0   \n",
       "\n",
       "      drive_lastend_time_discrete  reservation_duration  revenue_distance  \\\n",
       "230                         702.0                  18.0              5.20   \n",
       "307                         706.0                   6.0              0.00   \n",
       "315                        3692.0                2992.0              0.00   \n",
       "652                         710.0                   4.0              3.33   \n",
       "1258                        715.0                   8.0              1.33   \n",
       "\n",
       "      required_soc  revenue_duration  drive_km  drive_duration  \n",
       "230            4.0             15.00       8.0             1.0  \n",
       "307            0.0              0.00       0.0             7.0  \n",
       "315            0.0              0.00       0.0          2993.0  \n",
       "652            2.5              6.25       5.0             4.0  \n",
       "1258           1.0              5.00       2.0             1.0  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get daily reservations, save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "reservations_dict = {}\n",
    "start_date_reservations = start_date\n",
    "while start_date_reservations <= end_date:\n",
    "    sql = \"\"\"SELECT reservation_no, start_station_no, vehicle_no, reservationfrom_time_discrete, drive_firststart_time_discrete, \n",
    "            drive_lastend_time_discrete, reservation_duration, revenue_distance, required_soc, revenue_duration, drive_km, \n",
    "            (floor(EXTRACT(epoch FROM (date_trunc('hour', TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) + \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes' \n",
    "                                - date_trunc('hour', TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) - \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes'\n",
    "                               )) / 900) * 900 + 900) / 900 AS drive_duration\n",
    "            FROM msc_2023_dominik.reservations_long_time \n",
    "            WHERE  DATE(reservationfrom_discrete_date) = '{}' or  DATE(drive_firststart_discrete_date) = '{}' \n",
    "            ORDER BY reservationfrom_discrete\"\"\".format(start_date_reservations, start_date_reservations, vehicle_nr_list) \n",
    "    reservations = pd.read_sql(sql, engine)\n",
    "    reservations = reservations[reservations['vehicle_no'].isin(vehicle_nr_list)]\n",
    "    reservations_dict[start_date_reservations.strftime('%Y-%m-%d')] = reservations\n",
    "    start_date_reservations += delta     \n",
    "reservations_dict[(start_date).strftime('%Y-%m-%d')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f0a110a9-b2b1-4887-b52d-4fc87278e1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_no</th>\n",
       "      <th>start_station_no</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>reservationfrom_time_discrete</th>\n",
       "      <th>drive_firststart_time_discrete</th>\n",
       "      <th>drive_lastend_time_discrete</th>\n",
       "      <th>reservation_duration</th>\n",
       "      <th>revenue_distance</th>\n",
       "      <th>required_soc</th>\n",
       "      <th>revenue_duration</th>\n",
       "      <th>drive_km</th>\n",
       "      <th>drive_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>24518458</td>\n",
       "      <td>2086</td>\n",
       "      <td>113023</td>\n",
       "      <td>700.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>702.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>5.20</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.00</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>24451016</td>\n",
       "      <td>4078</td>\n",
       "      <td>113103</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>3692.0</td>\n",
       "      <td>2992.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2993.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>24527445</td>\n",
       "      <td>3822</td>\n",
       "      <td>113114</td>\n",
       "      <td>700.0</td>\n",
       "      <td>700.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>701</th>\n",
       "      <td>24542806</td>\n",
       "      <td>1843</td>\n",
       "      <td>113017</td>\n",
       "      <td>706.0</td>\n",
       "      <td>707.0</td>\n",
       "      <td>710.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.33</td>\n",
       "      <td>2.5</td>\n",
       "      <td>6.25</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1235</th>\n",
       "      <td>24535701</td>\n",
       "      <td>1582</td>\n",
       "      <td>113111</td>\n",
       "      <td>714.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.00</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      reservation_no  start_station_no  vehicle_no  \\\n",
       "184         24518458              2086      113023   \n",
       "244         24451016              4078      113103   \n",
       "252         24527445              3822      113114   \n",
       "701         24542806              1843      113017   \n",
       "1235        24535701              1582      113111   \n",
       "\n",
       "      reservationfrom_time_discrete  drive_firststart_time_discrete  \\\n",
       "184                           700.0                           702.0   \n",
       "244                           700.0                           700.0   \n",
       "252                           700.0                           700.0   \n",
       "701                           706.0                           707.0   \n",
       "1235                          714.0                           715.0   \n",
       "\n",
       "      drive_lastend_time_discrete  reservation_duration  revenue_distance  \\\n",
       "184                         702.0                  18.0              5.20   \n",
       "244                        3692.0                2992.0              0.00   \n",
       "252                         706.0                   6.0              0.00   \n",
       "701                         710.0                   4.0              3.33   \n",
       "1235                        715.0                   8.0              1.33   \n",
       "\n",
       "      required_soc  revenue_duration  drive_km  drive_duration  \n",
       "184            4.0             15.00       8.0             1.0  \n",
       "244            0.0              0.00       0.0          2993.0  \n",
       "252            0.0              0.00       0.0             7.0  \n",
       "701            2.5              6.25       5.0             4.0  \n",
       "1235           1.0              5.00       2.0             1.0  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservations_dict_simulation['2019-01-08'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "67e6fc03-b963-4138-b7d7-618e371440de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_no</th>\n",
       "      <th>start_station_no</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>reservationfrom_time_discrete</th>\n",
       "      <th>drive_firststart_time_discrete</th>\n",
       "      <th>drive_lastend_time_discrete</th>\n",
       "      <th>reservation_duration</th>\n",
       "      <th>revenue_distance</th>\n",
       "      <th>required_soc</th>\n",
       "      <th>revenue_duration</th>\n",
       "      <th>drive_km</th>\n",
       "      <th>drive_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>24496058</td>\n",
       "      <td>2086</td>\n",
       "      <td>113023</td>\n",
       "      <td>28.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>4.55</td>\n",
       "      <td>3.5</td>\n",
       "      <td>12.50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>24519412</td>\n",
       "      <td>2160</td>\n",
       "      <td>113020</td>\n",
       "      <td>32.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.85</td>\n",
       "      <td>4.5</td>\n",
       "      <td>8.75</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227</th>\n",
       "      <td>24519429</td>\n",
       "      <td>4492</td>\n",
       "      <td>113006</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.90</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.50</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>24519701</td>\n",
       "      <td>4379</td>\n",
       "      <td>113103</td>\n",
       "      <td>44.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.10</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.50</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>24520039</td>\n",
       "      <td>2160</td>\n",
       "      <td>113020</td>\n",
       "      <td>54.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>20.15</td>\n",
       "      <td>15.5</td>\n",
       "      <td>12.50</td>\n",
       "      <td>31.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     reservation_no  start_station_no  vehicle_no  \\\n",
       "107        24496058              2086      113023   \n",
       "192        24519412              2160      113020   \n",
       "227        24519429              4492      113006   \n",
       "509        24519701              4379      113103   \n",
       "890        24520039              2160      113020   \n",
       "\n",
       "     reservationfrom_time_discrete  drive_firststart_time_discrete  \\\n",
       "107                           28.0                            30.0   \n",
       "192                           32.0                            32.0   \n",
       "227                           34.0                            34.0   \n",
       "509                           44.0                            45.0   \n",
       "890                           54.0                            56.0   \n",
       "\n",
       "     drive_lastend_time_discrete  reservation_duration  revenue_distance  \\\n",
       "107                         30.0                  20.0              4.55   \n",
       "192                         39.0                   8.0              5.85   \n",
       "227                         35.0                   4.0              3.90   \n",
       "509                         56.0                  12.0              9.10   \n",
       "890                         72.0                  18.0             20.15   \n",
       "\n",
       "     required_soc  revenue_duration  drive_km  drive_duration  \n",
       "107           3.5             12.50       7.0             1.0  \n",
       "192           4.5              8.75       9.0             8.0  \n",
       "227           3.0              2.50       6.0             2.0  \n",
       "509           7.0              7.50      14.0            11.0  \n",
       "890          15.5             12.50      31.0            16.0  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get daily reservations, save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "reservations_dict_simulation = {}\n",
    "start_date_reservations = start_date_simulation\n",
    "while start_date_reservations <= end_date_simulation:\n",
    "    sql = \"\"\"SELECT reservation_no, start_station_no, vehicle_no, reservationfrom_time_discrete, drive_firststart_time_discrete, \n",
    "            drive_lastend_time_discrete, reservation_duration, revenue_distance, required_soc, revenue_duration, drive_km, \n",
    "            (floor(EXTRACT(epoch FROM (date_trunc('hour', TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) + \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes' \n",
    "                                - date_trunc('hour', TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) - \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes'\n",
    "                               )) / 900) * 900 + 900) / 900 AS drive_duration\n",
    "            FROM msc_2023_dominik.reservations_long_time \n",
    "            WHERE  DATE(reservationfrom_discrete_date) = '{}' or  DATE(drive_firststart_discrete_date) = '{}'\n",
    "            ORDER BY reservationfrom_discrete\"\"\".format(start_date_reservations, start_date_reservations, vehicle_nr_list)\n",
    "    reservations = pd.read_sql(sql, engine)\n",
    "    reservations = reservations[reservations['vehicle_no'].isin(vehicle_nr_list)]\n",
    "    reservations_dict_simulation[start_date_reservations.strftime('%Y-%m-%d')] = reservations\n",
    "    start_date_reservations += delta\n",
    "reservations_dict_simulation[(start_date_simulation).strftime('%Y-%m-%d')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f85c1bb3-758e-455f-bbbb-4837ca89ee4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservations_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231981c3-a6b3-4fe1-b35c-38218488d645",
   "metadata": {},
   "source": [
    "### Electicity prices for charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea91fd7f-4e91-460b-acc1-971747c0dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_chf_kwh_0.0</th>\n",
       "      <th>Price_chf_kwh_0.25</th>\n",
       "      <th>Price_chf_kwh_0.5</th>\n",
       "      <th>Price_chf_kwh_0.75</th>\n",
       "      <th>Price_chf_kwh_1.0</th>\n",
       "      <th>Price_chf_kwh_1.25</th>\n",
       "      <th>Price_chf_kwh_1.5</th>\n",
       "      <th>Price_chf_kwh_1.75</th>\n",
       "      <th>Price_chf_kwh_2.0</th>\n",
       "      <th>Price_chf_kwh_2.25</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_chf_kwh_21.75</th>\n",
       "      <th>Price_chf_kwh_22.0</th>\n",
       "      <th>Price_chf_kwh_22.25</th>\n",
       "      <th>Price_chf_kwh_22.5</th>\n",
       "      <th>Price_chf_kwh_22.75</th>\n",
       "      <th>Price_chf_kwh_23.0</th>\n",
       "      <th>Price_chf_kwh_23.25</th>\n",
       "      <th>Price_chf_kwh_23.5</th>\n",
       "      <th>Price_chf_kwh_23.75</th>\n",
       "      <th>Delivery day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.049484</td>\n",
       "      <td>0.049484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065208</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>2019-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067586</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>2019-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072842</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>2019-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072212</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>2019-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.059366</td>\n",
       "      <td>0.059366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058595</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>2019-01-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price_chf_kwh_0.0  Price_chf_kwh_0.25  Price_chf_kwh_0.5  \\\n",
       "0           0.055468            0.055468           0.055468   \n",
       "1           0.061907            0.061907           0.061907   \n",
       "2           0.062939            0.062939           0.062939   \n",
       "3           0.068889            0.068889           0.068889   \n",
       "4           0.067521            0.067521           0.067521   \n",
       "\n",
       "   Price_chf_kwh_0.75  Price_chf_kwh_1.0  Price_chf_kwh_1.25  \\\n",
       "0            0.055468           0.050245            0.050245   \n",
       "1            0.061907           0.057564            0.057564   \n",
       "2            0.062939           0.058443            0.058443   \n",
       "3            0.068889           0.061907            0.061907   \n",
       "4            0.067521           0.061951            0.061951   \n",
       "\n",
       "   Price_chf_kwh_1.5  Price_chf_kwh_1.75  Price_chf_kwh_2.0  \\\n",
       "0           0.050245            0.050245           0.049484   \n",
       "1           0.057564            0.057564           0.057086   \n",
       "2           0.058443            0.058443           0.058150   \n",
       "3           0.061907            0.061907           0.060854   \n",
       "4           0.061951            0.061951           0.059366   \n",
       "\n",
       "   Price_chf_kwh_2.25  ...  Price_chf_kwh_21.75  Price_chf_kwh_22.0  \\\n",
       "0            0.049484  ...             0.065208            0.065165   \n",
       "1            0.057086  ...             0.067586            0.067641   \n",
       "2            0.058150  ...             0.072842            0.070312   \n",
       "3            0.060854  ...             0.072212            0.071756   \n",
       "4            0.059366  ...             0.058595            0.061353   \n",
       "\n",
       "   Price_chf_kwh_22.25  Price_chf_kwh_22.5  Price_chf_kwh_22.75  \\\n",
       "0             0.065165            0.065165             0.065165   \n",
       "1             0.067641            0.067641             0.067641   \n",
       "2             0.070312            0.070312             0.070312   \n",
       "3             0.071756            0.071756             0.071756   \n",
       "4             0.061353            0.061353             0.061353   \n",
       "\n",
       "   Price_chf_kwh_23.0  Price_chf_kwh_23.25  Price_chf_kwh_23.5  \\\n",
       "0            0.061071             0.061071            0.061071   \n",
       "1            0.064112             0.064112            0.064112   \n",
       "2            0.061842             0.061842            0.061842   \n",
       "3            0.069389             0.069389            0.069389   \n",
       "4            0.058606             0.058606            0.058606   \n",
       "\n",
       "   Price_chf_kwh_23.75  Delivery day  \n",
       "0             0.061071    2019-01-08  \n",
       "1             0.064112    2019-01-09  \n",
       "2             0.061842    2019-01-10  \n",
       "3             0.069389    2019-01-11  \n",
       "4             0.058606    2019-01-12  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get charging costs data\n",
    "prices = \"\"\n",
    "for i in range(0, 480, 5):\n",
    "    price = i / 20\n",
    "    prices += '\"Price_chf_kwh_{}\", '.format(price)\n",
    "\n",
    "sql = \"\"\"SELECT {} \"Delivery day\" FROM msc_2023_dominik.charging_costs WHERE \"Delivery day\" >=  '{}' and \"Delivery day\" <=  '{}' ORDER BY \"Delivery day\" \"\"\".format(prices, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "charging_costs = pd.read_sql(sql, engine)\n",
    "charging_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a518a3fd-5556-412e-8514-cb45384f601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "charging_costs_dict = {}\n",
    "start_date_electricity = start_date\n",
    "while start_date_electricity <= end_date:\n",
    "    electricity_price_day = charging_costs[charging_costs[\"Delivery day\"].dt.date == start_date_electricity].drop([\"Delivery day\"],axis = 1).iloc[0].values\n",
    "    charging_costs_dict[start_date_electricity.strftime('%Y-%m-%d')] = electricity_price_day\n",
    "    start_date_electricity += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08b385c5-f02c-40dd-8842-ec3436a920aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31', '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-29', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-25', '2019-05-26', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-20', '2019-06-21', '2019-06-22', '2019-06-23', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-19', '2019-07-20', '2019-07-21', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-27', '2019-07-28', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19', '2019-09-20', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-05', '2019-10-06', '2019-10-07', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-11', '2020-01-12', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16', '2020-01-17', '2020-01-18', '2020-01-19', '2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', '2020-02-01', '2020-02-02', '2020-02-03', '2020-02-04', '2020-02-05', '2020-02-06', '2020-02-07', '2020-02-08', '2020-02-09', '2020-02-10', '2020-02-11', '2020-02-12', '2020-02-13', '2020-02-14', '2020-02-15', '2020-02-16', '2020-02-17', '2020-02-18', '2020-02-19', '2020-02-20', '2020-02-21', '2020-02-22', '2020-02-23', '2020-02-24', '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28', '2020-02-29', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14', '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19', '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28', '2020-04-29', '2020-04-30', '2020-05-01', '2020-05-02', '2020-05-03', '2020-05-04', '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08', '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12', '2020-05-13', '2020-05-14', '2020-05-15', '2020-05-16', '2020-05-17', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21', '2020-05-22', '2020-05-23', '2020-05-24', '2020-05-25', '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29', '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02', '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-06', '2020-06-07', '2020-06-08', '2020-06-09', '2020-06-10', '2020-06-11', '2020-06-12', '2020-06-13', '2020-06-14', '2020-06-15', '2020-06-16', '2020-06-17', '2020-06-18', '2020-06-19', '2020-06-20', '2020-06-21', '2020-06-22', '2020-06-23', '2020-06-24', '2020-06-25', '2020-06-26', '2020-06-27', '2020-06-28', '2020-06-29', '2020-06-30', '2020-07-01', '2020-07-02', '2020-07-03', '2020-07-04', '2020-07-05', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-09', '2020-07-10', '2020-07-11', '2020-07-12', '2020-07-13', '2020-07-14', '2020-07-15', '2020-07-16', '2020-07-17', '2020-07-18', '2020-07-19', '2020-07-20', '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24', '2020-07-25', '2020-07-26'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charging_costs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd3cd53e-3ed3-498b-9610-75fd56a57ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_chf_kwh_0.0</th>\n",
       "      <th>Price_chf_kwh_0.25</th>\n",
       "      <th>Price_chf_kwh_0.5</th>\n",
       "      <th>Price_chf_kwh_0.75</th>\n",
       "      <th>Price_chf_kwh_1.0</th>\n",
       "      <th>Price_chf_kwh_1.25</th>\n",
       "      <th>Price_chf_kwh_1.5</th>\n",
       "      <th>Price_chf_kwh_1.75</th>\n",
       "      <th>Price_chf_kwh_2.0</th>\n",
       "      <th>Price_chf_kwh_2.25</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_chf_kwh_21.75</th>\n",
       "      <th>Price_chf_kwh_22.0</th>\n",
       "      <th>Price_chf_kwh_22.25</th>\n",
       "      <th>Price_chf_kwh_22.5</th>\n",
       "      <th>Price_chf_kwh_22.75</th>\n",
       "      <th>Price_chf_kwh_23.0</th>\n",
       "      <th>Price_chf_kwh_23.25</th>\n",
       "      <th>Price_chf_kwh_23.5</th>\n",
       "      <th>Price_chf_kwh_23.75</th>\n",
       "      <th>Delivery day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055055</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066175</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.054241</td>\n",
       "      <td>0.054241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065045</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price_chf_kwh_0.0  Price_chf_kwh_0.25  Price_chf_kwh_0.5  \\\n",
       "0           0.054577            0.054577           0.054577   \n",
       "1           0.054262            0.054262           0.054262   \n",
       "2           0.057585            0.057585           0.057585   \n",
       "3           0.057107            0.057107           0.057107   \n",
       "4           0.068477            0.068477           0.068477   \n",
       "\n",
       "   Price_chf_kwh_0.75  Price_chf_kwh_1.0  Price_chf_kwh_1.25  \\\n",
       "0            0.054577           0.052927            0.052927   \n",
       "1            0.054262           0.052840            0.052840   \n",
       "2            0.057585           0.054838            0.054838   \n",
       "3            0.057107           0.056130            0.056130   \n",
       "4            0.068477           0.063503            0.063503   \n",
       "\n",
       "   Price_chf_kwh_1.5  Price_chf_kwh_1.75  Price_chf_kwh_2.0  \\\n",
       "0           0.052927            0.052927           0.051298   \n",
       "1           0.052840            0.052840           0.045130   \n",
       "2           0.054838            0.054838           0.052471   \n",
       "3           0.056130            0.056130           0.054241   \n",
       "4           0.063503            0.063503           0.059431   \n",
       "\n",
       "   Price_chf_kwh_2.25  ...  Price_chf_kwh_21.75  Price_chf_kwh_22.0  \\\n",
       "0            0.051298  ...             0.055055            0.059855   \n",
       "1            0.045130  ...             0.066175            0.065230   \n",
       "2            0.052471  ...             0.068433            0.066262   \n",
       "3            0.054241  ...             0.070214            0.070301   \n",
       "4            0.059431  ...             0.065045            0.066381   \n",
       "\n",
       "   Price_chf_kwh_22.25  Price_chf_kwh_22.5  Price_chf_kwh_22.75  \\\n",
       "0             0.059855            0.059855             0.059855   \n",
       "1             0.065230            0.065230             0.065230   \n",
       "2             0.066262            0.066262             0.066262   \n",
       "3             0.070301            0.070301             0.070301   \n",
       "4             0.066381            0.066381             0.066381   \n",
       "\n",
       "   Price_chf_kwh_23.0  Price_chf_kwh_23.25  Price_chf_kwh_23.5  \\\n",
       "0            0.059844             0.059844            0.059844   \n",
       "1            0.064036             0.064036            0.064036   \n",
       "2            0.062276             0.062276            0.062276   \n",
       "3            0.065914             0.065914            0.065914   \n",
       "4            0.066370             0.066370            0.066370   \n",
       "\n",
       "   Price_chf_kwh_23.75  Delivery day  \n",
       "0             0.059844    2019-01-01  \n",
       "1             0.064036    2019-01-02  \n",
       "2             0.062276    2019-01-03  \n",
       "3             0.065914    2019-01-04  \n",
       "4             0.066370    2019-01-05  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get charging costs data\n",
    "prices = \"\"\n",
    "for i in range(0, 480, 5):\n",
    "    price = i / 20\n",
    "    prices += '\"Price_chf_kwh_{}\", '.format(price)\n",
    "\n",
    "sql = \"\"\"SELECT {} \"Delivery day\" FROM msc_2023_dominik.charging_costs WHERE \"Delivery day\" >=  '{}' and \"Delivery day\" <=  '{}' ORDER BY \"Delivery day\" \"\"\".format(prices, start_date_simulation.strftime('%Y-%m-%d'), end_date_simulation.strftime('%Y-%m-%d'))\n",
    "\n",
    "charging_costs = pd.read_sql(sql, engine)\n",
    "charging_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97d9360b-58a7-4abc-a745-fa48e34b63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "charging_costs_dict_simulation = {}\n",
    "start_date_electricity = start_date_simulation\n",
    "while start_date_electricity <= end_date_simulation:\n",
    "    electricity_price_day = charging_costs[charging_costs[\"Delivery day\"].dt.date == start_date_electricity].drop([\"Delivery day\"],axis = 1).iloc[0].values\n",
    "    charging_costs_dict_simulation[start_date_electricity.strftime('%Y-%m-%d')] = electricity_price_day\n",
    "    start_date_electricity += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a4bcea5-de92-4b8b-b338-f1c6e920b6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charging_costs_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf046c-5db6-45c4-ab6e-edf86bfd9f77",
   "metadata": {},
   "source": [
    "### Secondary energy prices (for V2G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "45a1fb02-3e5d-4d8c-8394-f465d7cff15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Secondary_positive_v2g_prices_chf_kwh</th>\n",
       "      <th>Secondary_negative_v2g_prices_chf_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-08 00:00:00</td>\n",
       "      <td>0.052801</td>\n",
       "      <td>0.035201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-08 00:15:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-08 00:30:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-08 00:45:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08 01:00:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Secondary_positive_v2g_prices_chf_kwh  \\\n",
       "0 2019-01-08 00:00:00                               0.052801   \n",
       "1 2019-01-08 00:15:00                               0.052687   \n",
       "2 2019-01-08 00:30:00                               0.052687   \n",
       "3 2019-01-08 00:45:00                               0.052687   \n",
       "4 2019-01-08 01:00:00                               0.052687   \n",
       "\n",
       "   Secondary_negative_v2g_prices_chf_kwh  \n",
       "0                               0.035201  \n",
       "1                               0.035132  \n",
       "2                               0.035132  \n",
       "3                               0.035132  \n",
       "4                               0.035132  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get v2g price data\n",
    "sql = \"\"\"SELECT \"Timestamp\", \"Secondary_positive_v2g_prices_chf_kwh\", \"Secondary_negative_v2g_prices_chf_kwh\" FROM msc_2023_dominik.v2g_prices WHERE \"Timestamp\" >=  '{}' and \"Timestamp\" <=  '{}' ORDER BY \"Timestamp\" \"\"\".format(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "v2g_prices = pd.read_sql(sql, engine)\n",
    "v2g_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c003997-a4e1-496c-8b8f-f034b238efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "v2g_price_dict = {}\n",
    "start_date_v2g = start_date\n",
    "while start_date_v2g <= end_date:\n",
    "    v2g_price_day_positive = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_positive_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_day_negative = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_negative_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_dict[start_date_v2g.strftime('%Y-%m-%d')] = [v2g_price_day_positive, v2g_price_day_negative]\n",
    "    start_date_v2g += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "035a9fce-2bb1-47e8-a5e7-f902655900aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31', '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-29', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-25', '2019-05-26', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-20', '2019-06-21', '2019-06-22', '2019-06-23', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-19', '2019-07-20', '2019-07-21', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-27', '2019-07-28', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19', '2019-09-20', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-05', '2019-10-06', '2019-10-07', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-11', '2020-01-12', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16', '2020-01-17', '2020-01-18', '2020-01-19', '2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', '2020-02-01', '2020-02-02', '2020-02-03', '2020-02-04', '2020-02-05', '2020-02-06', '2020-02-07', '2020-02-08', '2020-02-09', '2020-02-10', '2020-02-11', '2020-02-12', '2020-02-13', '2020-02-14', '2020-02-15', '2020-02-16', '2020-02-17', '2020-02-18', '2020-02-19', '2020-02-20', '2020-02-21', '2020-02-22', '2020-02-23', '2020-02-24', '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28', '2020-02-29', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14', '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19', '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28', '2020-04-29', '2020-04-30', '2020-05-01', '2020-05-02', '2020-05-03', '2020-05-04', '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08', '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12', '2020-05-13', '2020-05-14', '2020-05-15', '2020-05-16', '2020-05-17', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21', '2020-05-22', '2020-05-23', '2020-05-24', '2020-05-25', '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29', '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02', '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-06', '2020-06-07', '2020-06-08', '2020-06-09', '2020-06-10', '2020-06-11', '2020-06-12', '2020-06-13', '2020-06-14', '2020-06-15', '2020-06-16', '2020-06-17', '2020-06-18', '2020-06-19', '2020-06-20', '2020-06-21', '2020-06-22', '2020-06-23', '2020-06-24', '2020-06-25', '2020-06-26', '2020-06-27', '2020-06-28', '2020-06-29', '2020-06-30', '2020-07-01', '2020-07-02', '2020-07-03', '2020-07-04', '2020-07-05', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-09', '2020-07-10', '2020-07-11', '2020-07-12', '2020-07-13', '2020-07-14', '2020-07-15', '2020-07-16', '2020-07-17', '2020-07-18', '2020-07-19', '2020-07-20', '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24', '2020-07-25', '2020-07-26'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2g_price_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ed1cc3d-e732-4e7a-b427-5d16f7fad311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Secondary_positive_v2g_prices_chf_kwh</th>\n",
       "      <th>Secondary_negative_v2g_prices_chf_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.068370</td>\n",
       "      <td>0.045588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Secondary_positive_v2g_prices_chf_kwh  \\\n",
       "0 2019-01-01 00:00:00                               0.068370   \n",
       "1 2019-01-01 00:15:00                               0.068838   \n",
       "2 2019-01-01 00:30:00                               0.068838   \n",
       "3 2019-01-01 00:45:00                               0.068838   \n",
       "4 2019-01-01 01:00:00                               0.068838   \n",
       "\n",
       "   Secondary_negative_v2g_prices_chf_kwh  \n",
       "0                               0.045588  \n",
       "1                               0.045896  \n",
       "2                               0.045896  \n",
       "3                               0.045896  \n",
       "4                               0.045896  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get v2g price data\n",
    "sql = \"\"\"SELECT \"Timestamp\", \"Secondary_positive_v2g_prices_chf_kwh\", \"Secondary_negative_v2g_prices_chf_kwh\" FROM msc_2023_dominik.v2g_prices WHERE \"Timestamp\" >=  '{}' and \"Timestamp\" <=  '{}' ORDER BY \"Timestamp\" \"\"\".format(start_date_simulation.strftime('%Y-%m-%d'), end_date_simulation.strftime('%Y-%m-%d'))\n",
    "v2g_prices = pd.read_sql(sql, engine)\n",
    "v2g_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e336d8c8-67e2-4a61-b30b-71e43a1189c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "v2g_price_dict_simulation = {}\n",
    "start_date_v2g = start_date_simulation\n",
    "while start_date_v2g <= end_date_simulation:\n",
    "    v2g_price_day_positive = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_positive_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_day_negative = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_negative_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_dict_simulation[start_date_v2g.strftime('%Y-%m-%d')] = [v2g_price_day_positive, v2g_price_day_negative]\n",
    "    start_date_v2g += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "efdd8077-9174-4e94-88dd-034a39c1d2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2g_price_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4bdff-3156-46e4-bf59-d2cc1a042ec9",
   "metadata": {},
   "source": [
    "# Check environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f88a71db-6071-422c-b45b-0ff53dd4a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if enviornment fullfils requirements of gym and stable-baselines3\n",
    "\n",
    "# load discrete table\n",
    "sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(0)\n",
    "data = pd.read_sql(sql, engine)\n",
    "    \n",
    "# load discrete planned reservation table\n",
    "sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(0)\n",
    "planned_reservations = pd.read_sql(sql, engine)\n",
    "    \n",
    "# load discrete planned reservation duration table\n",
    "sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(0)\n",
    "planned_durations = pd.read_sql(sql, engine)\n",
    "end = time.time()\n",
    "\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "    \n",
    "count = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for week_nr in range(start_week, 1):\n",
    "    # iteration for each day\n",
    "    for day in range(98,99,96):\n",
    "        \n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = count * 96\n",
    "        \n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "            \n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "        \n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "        \n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "    \n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "        \n",
    "        # create environment\n",
    "        env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 10000, penalty_per_kwh = 0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day, RL = True)\n",
    "        \n",
    "        # check implementation \n",
    "        checker_gym(env)\n",
    "        checker_baselines3(env)\n",
    "        # count number of simulated days\n",
    "        count += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15f8c0-60b6-441a-a835-3a291ba491d1",
   "metadata": {},
   "source": [
    "# Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "264c2bc8-fd14-4481-921d-88eeef84a395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check support of GPU\n",
    "stable_baselines3.common.utils.get_device(device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4295f-9b5b-4051-a8e0-6b5301f4968c",
   "metadata": {},
   "source": [
    "Start simulation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a1265bd7-6d26-4db8-ac46-e29da18cf5f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_week_simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "00860e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    nr_vehicles = len(vehicles)\n",
    "    \n",
    "    global nr_iterations_simulation\n",
    "\n",
    "    # maximal simulation length\n",
    "    if nr_iterations_simulation > 577:\n",
    "        nr_iterations_simulation = 577\n",
    "        \n",
    "    total_reward = 0\n",
    "\n",
    "    count = 0\n",
    "    # iterate over weeks (for loading weekly discrete data)\n",
    "    for week_nr in range(start_week_simulation, math.ceil((start_week_simulation * 7 + nr_iterations_simulation) / 7)):\n",
    "        # load discrete car-sharing table\n",
    "        sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 15 offset 10\".format(week_nr)\n",
    "        data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 15 offset 10\".format(week_nr)\n",
    "        planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 15 offset 10\".format(week_nr)\n",
    "        planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "\n",
    "        # iteration for each day\n",
    "        for day in range(98,676,96):\n",
    "            # calculate number of timesteps since first day of simulation\n",
    "            timesteps_since_start = count * 96\n",
    "\n",
    "            # all requested days are simulated\n",
    "            if count == nr_iterations:\n",
    "                break\n",
    "\n",
    "            # get date\n",
    "            date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "            date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "            # load reservations\n",
    "            reservations = reservations_dict_simulation[date_day_string]\n",
    "\n",
    "            # load electricity prices for charging\n",
    "            electricity_price = charging_costs_dict_simulation[date_day_string]\n",
    "\n",
    "            # load secondary energy prices for v2g\n",
    "            v2g_price = v2g_price_dict_simulation[date_day_string]\n",
    "\n",
    "            # select discrete data of day\n",
    "            daily_data = data.iloc[:,day-97:day-1]\n",
    "            planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "            planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "            # reset environment at beginnning of simulation\n",
    "            if count == 0:\n",
    "                environment = CarsharingEnv(stations, vehicles, planned_bookings = True, \n",
    "                                   daily_data = daily_data, reservations = reservations, electricity_price = electricity_price, soc_initial_low=0.0, soc_initial_high=0.0,\n",
    "                                    timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day, \n",
    "                                    planned_durations = planned_durations_day,cancellation_penalty=0, penalty_per_kwh = 1.0, random_seed_number = 42, v2g_demand_event_min = 10, v2g_demand_event_max = 10, v2g_penalty = 10, RL = True)\n",
    "                s = environment.reset()\n",
    "\n",
    "            # beginn new day without reseting environemnt \n",
    "            else:\n",
    "                environment.next_day(daily_data, reservations, electricity_price, timesteps_since_start, v2g_price, planned_reservations_day, planned_durations_day)\n",
    "                s = environment.reset()\n",
    "            # simulate day in 15 min steps\n",
    "            done = False\n",
    "            counter = 0\n",
    "            while not done:\n",
    "\n",
    "                # get your action \n",
    "                act, _states = model.predict(s)\n",
    "\n",
    "                # proceed one time step\n",
    "                s, rew, done, _ = environment.step(act)\n",
    "                \n",
    "                total_reward += rew\n",
    "\n",
    "                counter +=1\n",
    "\n",
    "            # plot summary statistics of episode (day)\n",
    "            #environment.daily_summary_statistics()\n",
    "\n",
    "            # plot summary statistic over full simulation period\n",
    "            #if count == nr_iterations - 1:\n",
    "              #  environment.episode_summary_statistics(nr_iterations)\n",
    "\n",
    "            # count number of simulated days\n",
    "            count += 1\n",
    "            \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /tmp/sb3_log/\n",
      "Validation reward:  637.9223460694644  CHF   Episodes learned:  0\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -49.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.5    |\n",
      "|    explained_variance | 0.0341   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 94       |\n",
      "|    policy_loss        | -7.05    |\n",
      "|    value_loss         | 0.207    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 33       |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.5    |\n",
      "|    explained_variance | 0.00924  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 189      |\n",
      "|    policy_loss        | -27.8    |\n",
      "|    value_loss         | 11.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 14.6     |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.5    |\n",
      "|    explained_variance | -0.038   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 284      |\n",
      "|    policy_loss        | -18.5    |\n",
      "|    value_loss         | 1.46     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -49.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.5    |\n",
      "|    explained_variance | -0.0227  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 379      |\n",
      "|    policy_loss        | -13.3    |\n",
      "|    value_loss         | 0.876    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -174     |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.5    |\n",
      "|    explained_variance | -0.00123 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 474      |\n",
      "|    policy_loss        | -684     |\n",
      "|    value_loss         | 2.07e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.5    |\n",
      "|    explained_variance | -0.00483 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 569      |\n",
      "|    policy_loss        | -3.04    |\n",
      "|    value_loss         | 0.0691   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -281     |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.000711 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 664      |\n",
      "|    policy_loss        | -556     |\n",
      "|    value_loss         | 1.41e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  643.9495994000989  CHF   Episodes learned:  42\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -38.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.0676   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 759      |\n",
      "|    policy_loss        | 3.32     |\n",
      "|    value_loss         | 0.0512   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.00154 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 854      |\n",
      "|    policy_loss        | -706     |\n",
      "|    value_loss         | 2.25e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -270      |\n",
      "| time/                 |           |\n",
      "|    fps                | 75        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 12        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -0.000545 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 949       |\n",
      "|    policy_loss        | -712      |\n",
      "|    value_loss         | 2.4e+03   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -187     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.00123  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1044     |\n",
      "|    policy_loss        | -436     |\n",
      "|    value_loss         | 1.23e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.161    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1139     |\n",
      "|    policy_loss        | 2.2      |\n",
      "|    value_loss         | 0.0227   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -244     |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.161    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1234     |\n",
      "|    policy_loss        | 2.1      |\n",
      "|    value_loss         | 0.0206   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -319     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0021  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1329     |\n",
      "|    policy_loss        | -725     |\n",
      "|    value_loss         | 2.35e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  633.520673995524  CHF   Episodes learned:  91\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.172    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1424     |\n",
      "|    policy_loss        | 2.02     |\n",
      "|    value_loss         | 0.0197   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -98.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.00222 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1519     |\n",
      "|    policy_loss        | -697     |\n",
      "|    value_loss         | 2.23e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -262      |\n",
      "| time/                 |           |\n",
      "|    fps                | 80        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -0.000479 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 1614      |\n",
      "|    policy_loss        | -771      |\n",
      "|    value_loss         | 2.84e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -183     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.00202  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1709     |\n",
      "|    policy_loss        | -418     |\n",
      "|    value_loss         | 1.18e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -164     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.27     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1804     |\n",
      "|    policy_loss        | 0.0201   |\n",
      "|    value_loss         | 0.000671 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.272    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1899     |\n",
      "|    policy_loss        | 1.28     |\n",
      "|    value_loss         | 0.00727  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -319     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00209 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 1994     |\n",
      "|    policy_loss        | -754     |\n",
      "|    value_loss         | 2.56e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  616.9232206803534  CHF   Episodes learned:  140\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.227    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2089     |\n",
      "|    policy_loss        | 1.67     |\n",
      "|    value_loss         | 0.0135   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -94.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00286 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2184     |\n",
      "|    policy_loss        | -687     |\n",
      "|    value_loss         | 2.27e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -267      |\n",
      "| time/                 |           |\n",
      "|    fps                | 72        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 13        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -0.000505 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 2279      |\n",
      "|    policy_loss        | -772      |\n",
      "|    value_loss         | 2.85e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -188     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.00245  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2374     |\n",
      "|    policy_loss        | -435     |\n",
      "|    value_loss         | 1.33e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -168     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.329    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2469     |\n",
      "|    policy_loss        | 0.242    |\n",
      "|    value_loss         | 0.0013   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -257     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.341    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2564     |\n",
      "|    policy_loss        | 0.66     |\n",
      "|    value_loss         | 0.00204  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -326     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00289 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2659     |\n",
      "|    policy_loss        | -690     |\n",
      "|    value_loss         | 2.26e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  654.2557149907286  CHF   Episodes learned:  189\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 88       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.237   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2754     |\n",
      "|    policy_loss        | 0.177    |\n",
      "|    value_loss         | 0.00245  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -98.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00349 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 2849     |\n",
      "|    policy_loss        | -679     |\n",
      "|    value_loss         | 2.13e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -273      |\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -0.000504 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 2944      |\n",
      "|    policy_loss        | -833      |\n",
      "|    value_loss         | 3.21e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -196     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.00388  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3039     |\n",
      "|    policy_loss        | -412     |\n",
      "|    value_loss         | 1.19e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -171     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.417    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3134     |\n",
      "|    policy_loss        | 0.866    |\n",
      "|    value_loss         | 0.00362  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -262     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.356    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3229     |\n",
      "|    policy_loss        | -0.185   |\n",
      "|    value_loss         | 0.00112  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -338     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00358 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3324     |\n",
      "|    policy_loss        | -790     |\n",
      "|    value_loss         | 2.87e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  618.8603543466687  CHF   Episodes learned:  238\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0403  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3419     |\n",
      "|    policy_loss        | 0.456    |\n",
      "|    value_loss         | 0.0015   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -97.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00424 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3514     |\n",
      "|    policy_loss        | -684     |\n",
      "|    value_loss         | 2.21e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -278      |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 14        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -0.000333 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 3609      |\n",
      "|    policy_loss        | -747      |\n",
      "|    value_loss         | 2.68e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -199     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.00415  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3704     |\n",
      "|    policy_loss        | -440     |\n",
      "|    value_loss         | 1.32e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -174     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.466    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3799     |\n",
      "|    policy_loss        | 0.791    |\n",
      "|    value_loss         | 0.00299  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -262     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.417    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3894     |\n",
      "|    policy_loss        | 0.871    |\n",
      "|    value_loss         | 0.00368  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -338     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00401 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 3989     |\n",
      "|    policy_loss        | -775     |\n",
      "|    value_loss         | 2.8e+03  |\n",
      "------------------------------------\n",
      "Validation reward:  632.3417995294443  CHF   Episodes learned:  287\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40      |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.486    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4084     |\n",
      "|    policy_loss        | 0.734    |\n",
      "|    value_loss         | 0.00266  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00438 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4179     |\n",
      "|    policy_loss        | -795     |\n",
      "|    value_loss         | 2.93e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -280      |\n",
      "| time/                 |           |\n",
      "|    fps                | 81        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -0.000687 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 4274      |\n",
      "|    policy_loss        | -847      |\n",
      "|    value_loss         | 3.26e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -199     |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.00496  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4369     |\n",
      "|    policy_loss        | -434     |\n",
      "|    value_loss         | 1.32e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.248    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4464     |\n",
      "|    policy_loss        | 0.0213   |\n",
      "|    value_loss         | 0.000331 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -263     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.525   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4559     |\n",
      "|    policy_loss        | -0.687   |\n",
      "|    value_loss         | 0.00265  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -339     |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00479 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4654     |\n",
      "|    policy_loss        | -785     |\n",
      "|    value_loss         | 2.9e+03  |\n",
      "------------------------------------\n",
      "Validation reward:  628.702572392704  CHF   Episodes learned:  336\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40      |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.144   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4749     |\n",
      "|    policy_loss        | 0.282    |\n",
      "|    value_loss         | 0.00111  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -98.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00553 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 4844     |\n",
      "|    policy_loss        | -733     |\n",
      "|    value_loss         | 2.49e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -281      |\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -0.000766 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 4939      |\n",
      "|    policy_loss        | -855      |\n",
      "|    value_loss         | 3.59e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -203     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.00579  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5034     |\n",
      "|    policy_loss        | -440     |\n",
      "|    value_loss         | 1.32e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -176     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.512    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5129     |\n",
      "|    policy_loss        | 0.778    |\n",
      "|    value_loss         | 0.00292  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.482    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5224     |\n",
      "|    policy_loss        | 0.812    |\n",
      "|    value_loss         | 0.00314  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -338     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00588 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5319     |\n",
      "|    policy_loss        | -743     |\n",
      "|    value_loss         | 2.57e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  631.7695277770487  CHF   Episodes learned:  385\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.531    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5414     |\n",
      "|    policy_loss        | 0.729    |\n",
      "|    value_loss         | 0.00257  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00562 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5509     |\n",
      "|    policy_loss        | -784     |\n",
      "|    value_loss         | 2.97e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -282      |\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -0.000832 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 5604      |\n",
      "|    policy_loss        | -847      |\n",
      "|    value_loss         | 3.44e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -201     |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.00658  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5699     |\n",
      "|    policy_loss        | -437     |\n",
      "|    value_loss         | 1.32e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.529    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5794     |\n",
      "|    policy_loss        | 0.78     |\n",
      "|    value_loss         | 0.0029   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -266     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.465    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5889     |\n",
      "|    policy_loss        | -0.249   |\n",
      "|    value_loss         | 0.00102  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -344     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00579 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 5984     |\n",
      "|    policy_loss        | -820     |\n",
      "|    value_loss         | 3.09e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  604.8067701962688  CHF   Episodes learned:  434\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.547    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6079     |\n",
      "|    policy_loss        | 0.745    |\n",
      "|    value_loss         | 0.00264  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00634 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6174     |\n",
      "|    policy_loss        | -802     |\n",
      "|    value_loss         | 2.97e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -284      |\n",
      "| time/                 |           |\n",
      "|    fps                | 84        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 11        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -0.000862 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 6269      |\n",
      "|    policy_loss        | -863      |\n",
      "|    value_loss         | 3.59e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -204     |\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.00773  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6364     |\n",
      "|    policy_loss        | -428     |\n",
      "|    value_loss         | 1.25e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -178     |\n",
      "| time/                 |          |\n",
      "|    fps                | 82       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.561    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6459     |\n",
      "|    policy_loss        | 0.741    |\n",
      "|    value_loss         | 0.00268  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.516    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6554     |\n",
      "|    policy_loss        | 0.805    |\n",
      "|    value_loss         | 0.00317  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -343     |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.007   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6649     |\n",
      "|    policy_loss        | -796     |\n",
      "|    value_loss         | 2.71e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  584.41911365761  CHF   Episodes learned:  483\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.104   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6744     |\n",
      "|    policy_loss        | 0.218    |\n",
      "|    value_loss         | 0.000958 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -105     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00807 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 6839     |\n",
      "|    policy_loss        | -753     |\n",
      "|    value_loss         | 2.65e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -285      |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -0.000903 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 6934      |\n",
      "|    policy_loss        | -865      |\n",
      "|    value_loss         | 3.59e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -205     |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.00823  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7029     |\n",
      "|    policy_loss        | -434     |\n",
      "|    value_loss         | 1.32e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -177     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.567    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7124     |\n",
      "|    policy_loss        | 0.766    |\n",
      "|    value_loss         | 0.00284  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 73       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.532    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7219     |\n",
      "|    policy_loss        | 0.811    |\n",
      "|    value_loss         | 0.00315  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -342     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00698 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7314     |\n",
      "|    policy_loss        | -803     |\n",
      "|    value_loss         | 3.09e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  652.2622808860738  CHF   Episodes learned:  532\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.145   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7409     |\n",
      "|    policy_loss        | -0.142   |\n",
      "|    value_loss         | 0.00077  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0097  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7504     |\n",
      "|    policy_loss        | -731     |\n",
      "|    value_loss         | 2.47e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -286     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00108 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7599     |\n",
      "|    policy_loss        | -836     |\n",
      "|    value_loss         | 3.44e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -206     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.0095   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7694     |\n",
      "|    policy_loss        | -428     |\n",
      "|    value_loss         | 1.18e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.575    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7789     |\n",
      "|    policy_loss        | 0.762    |\n",
      "|    value_loss         | 0.00287  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -268     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.546    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7884     |\n",
      "|    policy_loss        | 0.788    |\n",
      "|    value_loss         | 0.00305  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -345     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00804 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 7979     |\n",
      "|    policy_loss        | -791     |\n",
      "|    value_loss         | 2.93e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  666.5064608149183  CHF   Episodes learned:  581\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.617    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8074     |\n",
      "|    policy_loss        | 0.654    |\n",
      "|    value_loss         | 0.00207  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00817 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8169     |\n",
      "|    policy_loss        | -809     |\n",
      "|    value_loss         | 3.1e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -285      |\n",
      "| time/                 |           |\n",
      "|    fps                | 63        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -0.000944 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 8264      |\n",
      "|    policy_loss        | -840      |\n",
      "|    value_loss         | 3.33e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -206     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.00992  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8359     |\n",
      "|    policy_loss        | -434     |\n",
      "|    value_loss         | 1.31e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -177     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.596    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8454     |\n",
      "|    policy_loss        | 0.732    |\n",
      "|    value_loss         | 0.00265  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.513    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8549     |\n",
      "|    policy_loss        | -0.0815  |\n",
      "|    value_loss         | 0.000578 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -346     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00818 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8644     |\n",
      "|    policy_loss        | -808     |\n",
      "|    value_loss         | 3.09e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  626.5169115416942  CHF   Episodes learned:  630\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.611    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8739     |\n",
      "|    policy_loss        | 0.692    |\n",
      "|    value_loss         | 0.00232  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -108     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00948 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 8834     |\n",
      "|    policy_loss        | -769     |\n",
      "|    value_loss         | 2.85e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | -286      |\n",
      "| time/                 |           |\n",
      "|    fps                | 62        |\n",
      "|    iterations         | 95        |\n",
      "|    time_elapsed       | 15        |\n",
      "|    total_timesteps    | 950       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -0.000996 |\n",
      "|    learning_rate      | 5e-05     |\n",
      "|    n_updates          | 8929      |\n",
      "|    policy_loss        | -859      |\n",
      "|    value_loss         | 3.59e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -207     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.0108   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9024     |\n",
      "|    policy_loss        | -432     |\n",
      "|    value_loss         | 1.31e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -177     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.506    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9119     |\n",
      "|    policy_loss        | 0.228    |\n",
      "|    value_loss         | 0.000409 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -268     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.508    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9214     |\n",
      "|    policy_loss        | 0.0365   |\n",
      "|    value_loss         | 0.000423 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -346     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00947 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9309     |\n",
      "|    policy_loss        | -791     |\n",
      "|    value_loss         | 2.93e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  592.3635182752788  CHF   Episodes learned:  679\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.65     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9404     |\n",
      "|    policy_loss        | 0.64     |\n",
      "|    value_loss         | 0.00199  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.011   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9499     |\n",
      "|    policy_loss        | -775     |\n",
      "|    value_loss         | 2.76e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -286     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00104 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9594     |\n",
      "|    policy_loss        | -855     |\n",
      "|    value_loss         | 3.59e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -205     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.0117   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9689     |\n",
      "|    policy_loss        | -429     |\n",
      "|    value_loss         | 1.31e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.62     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9784     |\n",
      "|    policy_loss        | 0.748    |\n",
      "|    value_loss         | 0.00275  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.573    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9879     |\n",
      "|    policy_loss        | 0.83     |\n",
      "|    value_loss         | 0.0033   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -348     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00952 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 9974     |\n",
      "|    policy_loss        | -799     |\n",
      "|    value_loss         | 3.09e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  665.0152266181739  CHF   Episodes learned:  728\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.658    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10069    |\n",
      "|    policy_loss        | 0.643    |\n",
      "|    value_loss         | 0.00201  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -106     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0114  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10164    |\n",
      "|    policy_loss        | -775     |\n",
      "|    value_loss         | 2.88e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -286     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00107 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10259    |\n",
      "|    policy_loss        | -844     |\n",
      "|    value_loss         | 3.59e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -206     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.013    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10354    |\n",
      "|    policy_loss        | -417     |\n",
      "|    value_loss         | 1.21e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -177     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.613    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10449    |\n",
      "|    policy_loss        | 0.799    |\n",
      "|    value_loss         | 0.00303  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -266     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.579    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10544    |\n",
      "|    policy_loss        | 0.829    |\n",
      "|    value_loss         | 0.00338  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -342     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0106  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10639    |\n",
      "|    policy_loss        | -798     |\n",
      "|    value_loss         | 2.97e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  684.8422981903786  CHF   Episodes learned:  777\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.645    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10734    |\n",
      "|    policy_loss        | 0.7      |\n",
      "|    value_loss         | 0.00234  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0131  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10829    |\n",
      "|    policy_loss        | -768     |\n",
      "|    value_loss         | 2.75e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -283     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00111 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 10924    |\n",
      "|    policy_loss        | -869     |\n",
      "|    value_loss         | 3.59e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -203     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.014    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11019    |\n",
      "|    policy_loss        | -422     |\n",
      "|    value_loss         | 1.16e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -176     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.614    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11114    |\n",
      "|    policy_loss        | 0.819    |\n",
      "|    value_loss         | 0.00325  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.579    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11209    |\n",
      "|    policy_loss        | 0.855    |\n",
      "|    value_loss         | 0.00365  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -346     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0109  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11304    |\n",
      "|    policy_loss        | -818     |\n",
      "|    value_loss         | 3.09e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  656.2974810394238  CHF   Episodes learned:  826\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.672    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11399    |\n",
      "|    policy_loss        | 0.659    |\n",
      "|    value_loss         | 0.0021   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0122  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11494    |\n",
      "|    policy_loss        | -802     |\n",
      "|    value_loss         | 2.97e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -283     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00126 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11589    |\n",
      "|    policy_loss        | -863     |\n",
      "|    value_loss         | 3.38e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -207     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.0153   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11684    |\n",
      "|    policy_loss        | -432     |\n",
      "|    value_loss         | 1.27e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.625    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11779    |\n",
      "|    policy_loss        | 0.815    |\n",
      "|    value_loss         | 0.00324  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.596    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11874    |\n",
      "|    policy_loss        | 0.855    |\n",
      "|    value_loss         | 0.00351  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -343     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0115  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 11969    |\n",
      "|    policy_loss        | -811     |\n",
      "|    value_loss         | 3.09e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  626.7098598511585  CHF   Episodes learned:  875\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.669    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12064    |\n",
      "|    policy_loss        | 0.681    |\n",
      "|    value_loss         | 0.00226  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -107     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0131  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12159    |\n",
      "|    policy_loss        | -789     |\n",
      "|    value_loss         | 2.98e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -283     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00068 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12254    |\n",
      "|    policy_loss        | -828     |\n",
      "|    value_loss         | 3.31e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -203     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.0159   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12349    |\n",
      "|    policy_loss        | -435     |\n",
      "|    value_loss         | 1.26e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.635    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12444    |\n",
      "|    policy_loss        | 0.811    |\n",
      "|    value_loss         | 0.00316  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.585    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12539    |\n",
      "|    policy_loss        | 0.89     |\n",
      "|    value_loss         | 0.00391  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -343     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0146  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12634    |\n",
      "|    policy_loss        | -767     |\n",
      "|    value_loss         | 2.66e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  628.7285190413339  CHF   Episodes learned:  924\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40      |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.594    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12729    |\n",
      "|    policy_loss        | 0.642    |\n",
      "|    value_loss         | 0.00208  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0161  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12824    |\n",
      "|    policy_loss        | -756     |\n",
      "|    value_loss         | 2.66e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -282     |\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00164 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 12919    |\n",
      "|    policy_loss        | -790     |\n",
      "|    value_loss         | 2.96e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -202     |\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.0173   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13014    |\n",
      "|    policy_loss        | -412     |\n",
      "|    value_loss         | 1.16e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -176     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.631    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13109    |\n",
      "|    policy_loss        | 0.838    |\n",
      "|    value_loss         | 0.00344  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -263     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.607    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13204    |\n",
      "|    policy_loss        | 0.65     |\n",
      "|    value_loss         | 0.00187  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -339     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0152  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13299    |\n",
      "|    policy_loss        | -778     |\n",
      "|    value_loss         | 2.73e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  671.6337415625536  CHF   Episodes learned:  973\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.667    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13394    |\n",
      "|    policy_loss        | 0.739    |\n",
      "|    value_loss         | 0.00265  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0143  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13489    |\n",
      "|    policy_loss        | -766     |\n",
      "|    value_loss         | 2.72e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -279     |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00353 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13584    |\n",
      "|    policy_loss        | -734     |\n",
      "|    value_loss         | 2.65e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -204     |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.0179   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13679    |\n",
      "|    policy_loss        | -429     |\n",
      "|    value_loss         | 1.3e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -171     |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.627    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13774    |\n",
      "|    policy_loss        | 0.88     |\n",
      "|    value_loss         | 0.00383  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -264     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.605    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13869    |\n",
      "|    policy_loss        | 0.902    |\n",
      "|    value_loss         | 0.00398  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -340     |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0186  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 13964    |\n",
      "|    policy_loss        | -738     |\n",
      "|    value_loss         | 2.53e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  622.797005869474  CHF   Episodes learned:  1022\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.683    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14059    |\n",
      "|    policy_loss        | 0.714    |\n",
      "|    value_loss         | 0.00246  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0201  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14154    |\n",
      "|    policy_loss        | -740     |\n",
      "|    value_loss         | 2.49e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -281     |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00126 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14249    |\n",
      "|    policy_loss        | -848     |\n",
      "|    value_loss         | 3.58e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -203     |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.019    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14344    |\n",
      "|    policy_loss        | -430     |\n",
      "|    value_loss         | 1.29e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -175     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.653    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14439    |\n",
      "|    policy_loss        | 0.833    |\n",
      "|    value_loss         | 0.00339  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.613    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14534    |\n",
      "|    policy_loss        | 0.904    |\n",
      "|    value_loss         | 0.00396  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -344     |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0159  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14629    |\n",
      "|    policy_loss        | -800     |\n",
      "|    value_loss         | 2.94e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  653.4271241833034  CHF   Episodes learned:  1071\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.691    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14724    |\n",
      "|    policy_loss        | 0.716    |\n",
      "|    value_loss         | 0.00246  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -103     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0159  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14819    |\n",
      "|    policy_loss        | -806     |\n",
      "|    value_loss         | 3.11e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -282     |\n",
      "| time/                 |          |\n",
      "|    fps                | 73       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00153 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 14914    |\n",
      "|    policy_loss        | -875     |\n",
      "|    value_loss         | 3.48e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -205     |\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.0209   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15009    |\n",
      "|    policy_loss        | -430     |\n",
      "|    value_loss         | 1.29e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -174     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.656    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15104    |\n",
      "|    policy_loss        | 0.849    |\n",
      "|    value_loss         | 0.00352  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.625    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15199    |\n",
      "|    policy_loss        | 0.896    |\n",
      "|    value_loss         | 0.00389  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -340     |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0195  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15294    |\n",
      "|    policy_loss        | -765     |\n",
      "|    value_loss         | 2.7e+03  |\n",
      "------------------------------------\n",
      "Validation reward:  660.6450260052334  CHF   Episodes learned:  1120\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 97       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.703    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15389    |\n",
      "|    policy_loss        | 0.701    |\n",
      "|    value_loss         | 0.00236  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -104     |\n",
      "| time/                 |          |\n",
      "|    fps                | 77       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.0213  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15484    |\n",
      "|    policy_loss        | -760     |\n",
      "|    value_loss         | 2.55e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -282     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | -0.00198 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15579    |\n",
      "|    policy_loss        | -826     |\n",
      "|    value_loss         | 3.3e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -202     |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0.0219   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15674    |\n",
      "|    policy_loss        | -428     |\n",
      "|    value_loss         | 1.25e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -176     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.677    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15769    |\n",
      "|    policy_loss        | 0.815    |\n",
      "|    value_loss         | 0.00323  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -266     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.616    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15864    |\n",
      "|    policy_loss        | 0.95     |\n",
      "|    value_loss         | 0.00442  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -343     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0164  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 15959    |\n",
      "|    policy_loss        | -808     |\n",
      "|    value_loss         | 3.1e+03  |\n",
      "------------------------------------\n",
      "Validation reward:  635.5200210659632  CHF   Episodes learned:  1169\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40      |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.683    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16054    |\n",
      "|    policy_loss        | 0.781    |\n",
      "|    value_loss         | 0.00296  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -100     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0226  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16149    |\n",
      "|    policy_loss        | -704     |\n",
      "|    value_loss         | 2.42e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -280     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00205 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16244    |\n",
      "|    policy_loss        | -808     |\n",
      "|    value_loss         | 3.26e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -199     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.0257   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16339    |\n",
      "|    policy_loss        | -432     |\n",
      "|    value_loss         | 1.16e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -171     |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.67     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16434    |\n",
      "|    policy_loss        | 0.879    |\n",
      "|    value_loss         | 0.00369  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -264     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.764    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16529    |\n",
      "|    policy_loss        | 0.444    |\n",
      "|    value_loss         | 0.000881 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -339     |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0183  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16624    |\n",
      "|    policy_loss        | -796     |\n",
      "|    value_loss         | 2.98e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  656.126769527014  CHF   Episodes learned:  1218\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.711    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16719    |\n",
      "|    policy_loss        | 0.75     |\n",
      "|    value_loss         | 0.00269  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -101     |\n",
      "| time/                 |          |\n",
      "|    fps                | 60       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0241  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16814    |\n",
      "|    policy_loss        | -768     |\n",
      "|    value_loss         | 2.71e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -274     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00328 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 16909    |\n",
      "|    policy_loss        | -815     |\n",
      "|    value_loss         | 3.19e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -195     |\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.025    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17004    |\n",
      "|    policy_loss        | -358     |\n",
      "|    value_loss         | 899      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -172     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.625    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17099    |\n",
      "|    policy_loss        | 0.272    |\n",
      "|    value_loss         | 0.000627 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -258     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.659    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17194    |\n",
      "|    policy_loss        | 0.91     |\n",
      "|    value_loss         | 0.00395  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -331     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0225  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17289    |\n",
      "|    policy_loss        | -722     |\n",
      "|    value_loss         | 2.4e+03  |\n",
      "------------------------------------\n",
      "Validation reward:  574.6805375143341  CHF   Episodes learned:  1267\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.704    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17384    |\n",
      "|    policy_loss        | 0.791    |\n",
      "|    value_loss         | 0.00303  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -99.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0227  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17479    |\n",
      "|    policy_loss        | -788     |\n",
      "|    value_loss         | 2.77e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -274     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00339 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17574    |\n",
      "|    policy_loss        | -726     |\n",
      "|    value_loss         | 2.63e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -195     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.0272   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17669    |\n",
      "|    policy_loss        | -386     |\n",
      "|    value_loss         | 984      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -170     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.687    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17764    |\n",
      "|    policy_loss        | 0.903    |\n",
      "|    value_loss         | 0.0039   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -258     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.637    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17859    |\n",
      "|    policy_loss        | 1.01     |\n",
      "|    value_loss         | 0.00496  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -330     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0234  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 17954    |\n",
      "|    policy_loss        | -704     |\n",
      "|    value_loss         | 2.24e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  662.2630925753241  CHF   Episodes learned:  1316\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 0.684    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18049    |\n",
      "|    policy_loss        | 0.0871   |\n",
      "|    value_loss         | 0.000287 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -97.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0357  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18144    |\n",
      "|    policy_loss        | -643     |\n",
      "|    value_loss         | 1.91e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -276     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.00493 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18239    |\n",
      "|    policy_loss        | -717     |\n",
      "|    value_loss         | 2.53e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -192     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0272   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18334    |\n",
      "|    policy_loss        | -403     |\n",
      "|    value_loss         | 1.14e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -169     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.704    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18429    |\n",
      "|    policy_loss        | 0.46     |\n",
      "|    value_loss         | 0.000911 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -260     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.698    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18524    |\n",
      "|    policy_loss        | 0.402    |\n",
      "|    value_loss         | 0.000787 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -328     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0265  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18619    |\n",
      "|    policy_loss        | -713     |\n",
      "|    value_loss         | 2.38e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  609.4261813185294  CHF   Episodes learned:  1365\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.703    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18714    |\n",
      "|    policy_loss        | 0.877    |\n",
      "|    value_loss         | 0.00373  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -97.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | -0.0294  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18809    |\n",
      "|    policy_loss        | -737     |\n",
      "|    value_loss         | 2.52e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -268     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00809 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18904    |\n",
      "|    policy_loss        | -712     |\n",
      "|    value_loss         | 2.41e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -190     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0296   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 18999    |\n",
      "|    policy_loss        | -417     |\n",
      "|    value_loss         | 1.17e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -172     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.649    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19094    |\n",
      "|    policy_loss        | 0.982    |\n",
      "|    value_loss         | 0.0044   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -256     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.705    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19189    |\n",
      "|    policy_loss        | 0.891    |\n",
      "|    value_loss         | 0.00381  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -331     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0214  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19284    |\n",
      "|    policy_loss        | -818     |\n",
      "|    value_loss         | 3.1e+03  |\n",
      "------------------------------------\n",
      "Validation reward:  669.5176864986432  CHF   Episodes learned:  1414\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 88       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.691    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19379    |\n",
      "|    policy_loss        | 0.231    |\n",
      "|    value_loss         | 0.00154  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -98.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0268  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19474    |\n",
      "|    policy_loss        | -785     |\n",
      "|    value_loss         | 2.71e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -269     |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00377 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19569    |\n",
      "|    policy_loss        | -805     |\n",
      "|    value_loss         | 3.05e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -189     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0313   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19664    |\n",
      "|    policy_loss        | -404     |\n",
      "|    value_loss         | 1.12e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -169     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.712    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19759    |\n",
      "|    policy_loss        | 0.818    |\n",
      "|    value_loss         | 0.00308  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -258     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.628    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19854    |\n",
      "|    policy_loss        | 0.244    |\n",
      "|    value_loss         | 0.000503 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -325     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0322  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 19949    |\n",
      "|    policy_loss        | -675     |\n",
      "|    value_loss         | 2.14e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  656.2075108812235  CHF   Episodes learned:  1463\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -38.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 87       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.723    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20044    |\n",
      "|    policy_loss        | -0.0892  |\n",
      "|    value_loss         | 0.00139  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -96.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0308  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20139    |\n",
      "|    policy_loss        | -687     |\n",
      "|    value_loss         | 2.27e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -268     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00173 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20234    |\n",
      "|    policy_loss        | -837     |\n",
      "|    value_loss         | 3.14e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -190     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0364   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20329    |\n",
      "|    policy_loss        | -445     |\n",
      "|    value_loss         | 1.23e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -168     |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.743    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20424    |\n",
      "|    policy_loss        | 0.241    |\n",
      "|    value_loss         | 0.000619 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.623    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20519    |\n",
      "|    policy_loss        | 0.508    |\n",
      "|    value_loss         | 0.00119  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -321     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0415  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20614    |\n",
      "|    policy_loss        | -672     |\n",
      "|    value_loss         | 2.03e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  679.4989856221337  CHF   Episodes learned:  1512\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.75     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20709    |\n",
      "|    policy_loss        | 0.674    |\n",
      "|    value_loss         | 0.00207  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -96.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0342  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20804    |\n",
      "|    policy_loss        | -756     |\n",
      "|    value_loss         | 2.61e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00695 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20899    |\n",
      "|    policy_loss        | -708     |\n",
      "|    value_loss         | 2.41e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -186     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0338   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 20994    |\n",
      "|    policy_loss        | -432     |\n",
      "|    value_loss         | 1.26e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -165     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.768    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21089    |\n",
      "|    policy_loss        | 0.834    |\n",
      "|    value_loss         | 0.00334  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -252     |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.89     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21184    |\n",
      "|    policy_loss        | -0.129   |\n",
      "|    value_loss         | 0.000213 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -322     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0259  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21279    |\n",
      "|    policy_loss        | -789     |\n",
      "|    value_loss         | 2.86e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  664.0679777296842  CHF   Episodes learned:  1561\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.756    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21374    |\n",
      "|    policy_loss        | 0.473    |\n",
      "|    value_loss         | 0.00109  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -94.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0393  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21469    |\n",
      "|    policy_loss        | -692     |\n",
      "|    value_loss         | 2.26e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00553 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21564    |\n",
      "|    policy_loss        | -809     |\n",
      "|    value_loss         | 3.09e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -186     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0356   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21659    |\n",
      "|    policy_loss        | -381     |\n",
      "|    value_loss         | 1e+03    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -167     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.825    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21754    |\n",
      "|    policy_loss        | 0.168    |\n",
      "|    value_loss         | 0.000193 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.606    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21849    |\n",
      "|    policy_loss        | 0.771    |\n",
      "|    value_loss         | 0.00273  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -319     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0366  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 21944    |\n",
      "|    policy_loss        | -743     |\n",
      "|    value_loss         | 2.44e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  643.3464033241291  CHF   Episodes learned:  1610\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.732    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22039    |\n",
      "|    policy_loss        | 0.984    |\n",
      "|    value_loss         | 0.00469  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -98.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0411  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22134    |\n",
      "|    policy_loss        | -658     |\n",
      "|    value_loss         | 2.06e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00192 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22229    |\n",
      "|    policy_loss        | -854     |\n",
      "|    value_loss         | 3.57e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -187     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0374   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22324    |\n",
      "|    policy_loss        | -423     |\n",
      "|    value_loss         | 1.22e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -167     |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.784    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22419    |\n",
      "|    policy_loss        | 0.848    |\n",
      "|    value_loss         | 0.00341  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.499    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22514    |\n",
      "|    policy_loss        | 0.673    |\n",
      "|    value_loss         | 0.002    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -319     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0323  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22609    |\n",
      "|    policy_loss        | -755     |\n",
      "|    value_loss         | 2.59e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  678.7576446507292  CHF   Episodes learned:  1659\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 88       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.697    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22704    |\n",
      "|    policy_loss        | 0.386    |\n",
      "|    value_loss         | 0.00152  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -95      |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.041   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22799    |\n",
      "|    policy_loss        | -735     |\n",
      "|    value_loss         | 2.5e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -267     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00739 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22894    |\n",
      "|    policy_loss        | -763     |\n",
      "|    value_loss         | 2.72e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -190     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0395   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 22989    |\n",
      "|    policy_loss        | -359     |\n",
      "|    value_loss         | 923      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -167     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.718    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23084    |\n",
      "|    policy_loss        | 0.564    |\n",
      "|    value_loss         | 0.00171  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.643    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23179    |\n",
      "|    policy_loss        | 0.732    |\n",
      "|    value_loss         | 0.00239  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -318     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0417  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23274    |\n",
      "|    policy_loss        | -645     |\n",
      "|    value_loss         | 1.98e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  669.9955515182435  CHF   Episodes learned:  1708\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.1    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.798    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23369    |\n",
      "|    policy_loss        | 0.799    |\n",
      "|    value_loss         | 0.00301  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -95.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.037   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23464    |\n",
      "|    policy_loss        | -779     |\n",
      "|    value_loss         | 2.72e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -268     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00514 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23559    |\n",
      "|    policy_loss        | -786     |\n",
      "|    value_loss         | 2.9e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -188     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0451   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23654    |\n",
      "|    policy_loss        | -333     |\n",
      "|    value_loss         | 758      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -167     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.799    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23749    |\n",
      "|    policy_loss        | 0.502    |\n",
      "|    value_loss         | 0.00107  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -248     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.664    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23844    |\n",
      "|    policy_loss        | 0.416    |\n",
      "|    value_loss         | 0.00118  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -320     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0376  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 23939    |\n",
      "|    policy_loss        | -748     |\n",
      "|    value_loss         | 2.57e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  633.9765342199688  CHF   Episodes learned:  1757\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -40.7    |\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.78     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24034    |\n",
      "|    policy_loss        | 0.213    |\n",
      "|    value_loss         | 0.000437 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -97      |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.04    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24129    |\n",
      "|    policy_loss        | -772     |\n",
      "|    value_loss         | 2.73e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00924 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24224    |\n",
      "|    policy_loss        | -701     |\n",
      "|    value_loss         | 2.37e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -186     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0472   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24319    |\n",
      "|    policy_loss        | -394     |\n",
      "|    value_loss         | 1.05e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -166     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.796    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24414    |\n",
      "|    policy_loss        | 0.891    |\n",
      "|    value_loss         | 0.00378  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -251     |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.507    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24509    |\n",
      "|    policy_loss        | 0.791    |\n",
      "|    value_loss         | 0.00264  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -315     |\n",
      "| time/                 |          |\n",
      "|    fps                | 76       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0335  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24604    |\n",
      "|    policy_loss        | -733     |\n",
      "|    value_loss         | 2.43e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  678.7983013736241  CHF   Episodes learned:  1806\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -38.4    |\n",
      "| time/                 |          |\n",
      "|    fps                | 72       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.833    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24699    |\n",
      "|    policy_loss        | 0.728    |\n",
      "|    value_loss         | 0.00247  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -95.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0422  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24794    |\n",
      "|    policy_loss        | -773     |\n",
      "|    value_loss         | 2.62e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00525 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24889    |\n",
      "|    policy_loss        | -783     |\n",
      "|    value_loss         | 2.9e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -185     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.0478   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 24984    |\n",
      "|    policy_loss        | -425     |\n",
      "|    value_loss         | 1.24e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -167     |\n",
      "| time/                 |          |\n",
      "|    fps                | 73       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.743    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25079    |\n",
      "|    policy_loss        | 0.736    |\n",
      "|    value_loss         | 0.00242  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.734    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25174    |\n",
      "|    policy_loss        | 0.307    |\n",
      "|    value_loss         | 0.000611 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -321     |\n",
      "| time/                 |          |\n",
      "|    fps                | 69       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0498  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25269    |\n",
      "|    policy_loss        | -718     |\n",
      "|    value_loss         | 2.24e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  674.3805391765336  CHF   Episodes learned:  1855\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -38.2    |\n",
      "| time/                 |          |\n",
      "|    fps                | 75       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.801    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25364    |\n",
      "|    policy_loss        | 0.352    |\n",
      "|    value_loss         | 0.000748 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -97.5    |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0387  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25459    |\n",
      "|    policy_loss        | -770     |\n",
      "|    value_loss         | 2.75e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -266     |\n",
      "| time/                 |          |\n",
      "|    fps                | 66       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00467 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25554    |\n",
      "|    policy_loss        | -810     |\n",
      "|    value_loss         | 2.99e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -185     |\n",
      "| time/                 |          |\n",
      "|    fps                | 74       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.0509   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25649    |\n",
      "|    policy_loss        | -376     |\n",
      "|    value_loss         | 974      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -165     |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.807    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25744    |\n",
      "|    policy_loss        | 0.541    |\n",
      "|    value_loss         | 0.00131  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -249     |\n",
      "| time/                 |          |\n",
      "|    fps                | 81       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.761    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25839    |\n",
      "|    policy_loss        | 1.06     |\n",
      "|    value_loss         | 0.00532  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -318     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0467  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 25934    |\n",
      "|    policy_loss        | -715     |\n",
      "|    value_loss         | 2.32e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  660.5946440490292  CHF   Episodes learned:  1904\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -38.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 88       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.779    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26029    |\n",
      "|    policy_loss        | -0.114   |\n",
      "|    value_loss         | 0.000365 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -92.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0439  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26124    |\n",
      "|    policy_loss        | -732     |\n",
      "|    value_loss         | 2.53e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -265     |\n",
      "| time/                 |          |\n",
      "|    fps                | 79       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.00879 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26219    |\n",
      "|    policy_loss        | -772     |\n",
      "|    value_loss         | 2.76e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -184     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.0549   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26314    |\n",
      "|    policy_loss        | -408     |\n",
      "|    value_loss         | 1.07e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -170     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.862    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26409    |\n",
      "|    policy_loss        | 0.559    |\n",
      "|    value_loss         | 0.00141  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -250     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.658    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26504    |\n",
      "|    policy_loss        | 0.946    |\n",
      "|    value_loss         | 0.004    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -323     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0471  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26599    |\n",
      "|    policy_loss        | -689     |\n",
      "|    value_loss         | 2.15e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  674.742692729309  CHF   Episodes learned:  1953\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 71       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.782    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26694    |\n",
      "|    policy_loss        | 0.925    |\n",
      "|    value_loss         | 0.00384  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -98.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0545  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26789    |\n",
      "|    policy_loss        | -710     |\n",
      "|    value_loss         | 2.34e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -264     |\n",
      "| time/                 |          |\n",
      "|    fps                | 73       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00601 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26884    |\n",
      "|    policy_loss        | -794     |\n",
      "|    value_loss         | 2.86e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -187     |\n",
      "| time/                 |          |\n",
      "|    fps                | 63       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0.0562   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 26979    |\n",
      "|    policy_loss        | -374     |\n",
      "|    value_loss         | 966      |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -165     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.818    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27074    |\n",
      "|    policy_loss        | 0.619    |\n",
      "|    value_loss         | 0.00171  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -248     |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.822    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27169    |\n",
      "|    policy_loss        | 0.438    |\n",
      "|    value_loss         | 0.000832 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -320     |\n",
      "| time/                 |          |\n",
      "|    fps                | 73       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0463  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27264    |\n",
      "|    policy_loss        | -777     |\n",
      "|    value_loss         | 2.69e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  658.088049165989  CHF   Episodes learned:  2002\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -38.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.824    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27359    |\n",
      "|    policy_loss        | 0.835    |\n",
      "|    value_loss         | 0.00324  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -97.3    |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0474  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27454    |\n",
      "|    policy_loss        | -754     |\n",
      "|    value_loss         | 2.5e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -263     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.00759 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27549    |\n",
      "|    policy_loss        | -731     |\n",
      "|    value_loss         | 2.49e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -183     |\n",
      "| time/                 |          |\n",
      "|    fps                | 68       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.0612   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27644    |\n",
      "|    policy_loss        | -398     |\n",
      "|    value_loss         | 1.03e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -163     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.702    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27739    |\n",
      "|    policy_loss        | 0.297    |\n",
      "|    value_loss         | 0.000751 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -251     |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.782    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27834    |\n",
      "|    policy_loss        | 0.0838   |\n",
      "|    value_loss         | 0.0002   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -317     |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0436  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 27929    |\n",
      "|    policy_loss        | -732     |\n",
      "|    value_loss         | 2.48e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  633.4204841876092  CHF   Episodes learned:  2051\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -38.8    |\n",
      "| time/                 |          |\n",
      "|    fps                | 78       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.78     |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28024    |\n",
      "|    policy_loss        | 0.891    |\n",
      "|    value_loss         | 0.00354  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -96      |\n",
      "| time/                 |          |\n",
      "|    fps                | 65       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0508  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28119    |\n",
      "|    policy_loss        | -795     |\n",
      "|    value_loss         | 2.72e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -261     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.00389 |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28214    |\n",
      "|    policy_loss        | -756     |\n",
      "|    value_loss         | 2.82e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -186     |\n",
      "| time/                 |          |\n",
      "|    fps                | 70       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 13       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.0607   |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28309    |\n",
      "|    policy_loss        | -405     |\n",
      "|    value_loss         | 1.11e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -165     |\n",
      "| time/                 |          |\n",
      "|    fps                | 61       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.833    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28404    |\n",
      "|    policy_loss        | 0.676    |\n",
      "|    value_loss         | 0.00203  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -247     |\n",
      "| time/                 |          |\n",
      "|    fps                | 67       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.786    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28499    |\n",
      "|    policy_loss        | 1.03     |\n",
      "|    value_loss         | 0.00501  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -320     |\n",
      "| time/                 |          |\n",
      "|    fps                | 64       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 14       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0554  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28594    |\n",
      "|    policy_loss        | -718     |\n",
      "|    value_loss         | 2.37e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  647.046915800819  CHF   Episodes learned:  2100\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -39.9    |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 0.815    |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28689    |\n",
      "|    policy_loss        | 0.892    |\n",
      "|    value_loss         | 0.0037   |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | -96.6    |\n",
      "| time/                 |          |\n",
      "|    fps                | 62       |\n",
      "|    iterations         | 95       |\n",
      "|    time_elapsed       | 15       |\n",
      "|    total_timesteps    | 950      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | -0.0575  |\n",
      "|    learning_rate      | 5e-05    |\n",
      "|    n_updates          | 28784    |\n",
      "|    policy_loss        | -669     |\n",
      "|    value_loss         | 2.2e+03  |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "model = None\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for j in range(0,4286):\n",
    "    week_nr =  random.randint(0, 81)\n",
    "    \n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 15 offset 10\".format(week_nr)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 15 offset 10\".format(week_nr)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 15 offset 10\".format(week_nr)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "    counter = 0\n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "\n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = counter * 96 + week_nr * 96 * 7\n",
    "\n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "\n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "\n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "\n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "        # reset environment at beginnning of simulation\n",
    "        if count == 0:\n",
    "            environment = CarsharingEnv(stations, vehicles, planned_bookings = True, \n",
    "                               daily_data = daily_data, reservations = reservations, electricity_price = electricity_price, soc_initial_low=0.0, soc_initial_high=0.0,\n",
    "                                timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day, \n",
    "                                planned_durations = planned_durations_day, random_seed_number = 42, cancellation_penalty=0, penalty_per_kwh = 1.0, v2g_demand_event_min = 10, v2g_demand_event_max = 10, v2g_penalty = 10, RL = True)\n",
    "            s = environment.reset()\n",
    "\n",
    "            # create RL model\n",
    "             #model = PPO(\"MlpPolicy\",environment, verbose=2, ent_coef=0.0, stats_window_size = 10, n_epochs = 1, n_steps=95, batch_size = 95, device =\"cpu\", max_grad_norm = 10)\n",
    "            model = A2C(\"MlpPolicy\",environment, verbose=2, device =\"cpu\", n_steps=20,stats_window_size = 1000, learning_rate=0.00005,  vf_coef=0.25, ent_coef=0.01, max_grad_norm=0.5)\n",
    "            #model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "            #    nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 100),  # Modify the first layer\n",
    "            #    nn.Tanh(),\n",
    "             #   nn.Linear(100, 42),\n",
    "             #   model.policy.mlp_extractor.policy_net[3]\n",
    "            #)\n",
    "            #model.policy.action_net =  nn.Linear(42, 300)\n",
    "            #model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "            #    nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 42),  # Modify the first layer\n",
    "            #    nn.Tanh(),\n",
    "            #    nn.Linear(42, 42),\n",
    "            #    model.policy.mlp_extractor.value_net[3]\n",
    "            #)\n",
    "            #model.policy.value_net =  nn.Linear(42, 1)\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"stdout\", \"tensorboard\"])\n",
    "            model.set_logger(new_logger)\n",
    "\n",
    "            #model.policy.to(device)\n",
    "\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        else: \n",
    "            environment.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                          electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                          planned_durations = planned_durations_day)\n",
    "            s = environment.reset()\n",
    "\n",
    "\n",
    "        # learn one episode\n",
    "        model.learn(total_timesteps=95*10, reset_num_timesteps=True, log_interval  = 95)\n",
    "\n",
    "        if day == 674:\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count * 7)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count* 10 * 7)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        count += 1\n",
    "    if count == 5000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 10000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 20000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 29990:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1e44289c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46560"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.timesteps_since_start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bba8ea12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46565"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "environment.t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2d599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298858e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c744a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc3af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c086a0e-e349-4b00-9f13-e68bf34c1d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = None\n",
    "count_next_start = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for j in range(0,70):\n",
    "    print(j)\n",
    "    week_nr = random.randrange(1,80)\n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "\n",
    "    # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "    # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "    counter = 0\n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "\n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = counter * 96 + week_nr*7*96\n",
    "\n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "\n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "\n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "\n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "\n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "        # reset environment at beginnning of simulation\n",
    "        if count_next_start == 0:\n",
    "\n",
    "            model2 = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "            model2.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 64),\n",
    "                model.policy.mlp_extractor.policy_net[3]\n",
    "            )\n",
    "            model2.policy.action_net =  nn.Linear(64, 30)\n",
    "            model2.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 64),\n",
    "                model.policy.mlp_extractor.value_net[3]\n",
    "            )\n",
    "            model2.policy.value_net =  nn.Linear(64, 1)\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "            model2.set_logger(new_logger)\n",
    "            model2.set_parameters(\"car_sharing_v2g_model_small\", device = \"cpu\")\n",
    "\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "            model2.set_logger(new_logger)\n",
    "\n",
    "            #model.policy.to(device)\n",
    "\n",
    "            r = validation(model2)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        else: \n",
    "            env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                          electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                          planned_durations = planned_durations_day)\n",
    "            s = env.reset()\n",
    "\n",
    "\n",
    "        # learn one episode\n",
    "        model2.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "\n",
    "\n",
    "        if count in range(5,30000,100):\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        count_next_start += 1\n",
    "\n",
    "model2.save(\"car_sharing_v2g_model_small\")\n",
    "np.save(\"reward_list_model_small\", reward_list)\n",
    "np.save(\"count_list_model_small\", count_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69091f9-3d5e-492a-bf2a-cbe1fd137a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "    model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.policy_net[3]\n",
    "    )\n",
    "    model.policy.action_net =  nn.Linear(64, 30)\n",
    "    model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.value_net[3]\n",
    "    )\n",
    "    model.policy.value_net =  nn.Linear(64, 1)\n",
    "    new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "    model.set_logger(new_logger)\n",
    "    model.set_parameters(\"car_sharing_v2g_model_small\", device = \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451e90e-d376-4e58-8429-399408b467e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b11ce-2cdf-4e51-8f4d-be8e7ffac0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd422f3-658c-4baf-8e96-bd97eb0658fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fac97-9e37-4001-b613-312ed70d4240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "\n",
    "model = None\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for i in range(0,60):\n",
    "    print(i)\n",
    "    for j in range(0,70):\n",
    "        print(j)\n",
    "        week_nr = random.randrange(1,80)\n",
    "        # load discrete car-sharing table\n",
    "        sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "        data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "        planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "        planned_durations = pd.read_sql(sql, engine)\n",
    "        counter = 0\n",
    "        # iteration for each day\n",
    "        for day in range(98,676,96):\n",
    "\n",
    "            # calculate number of timesteps since first day of simulation\n",
    "            timesteps_since_start = counter * 96 + week_nr*7*96\n",
    "\n",
    "            # all requested days are simulated\n",
    "            if count == nr_iterations:\n",
    "                break\n",
    "\n",
    "            # get date\n",
    "            date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "            date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "            # load reservations\n",
    "            reservations = reservations_dict[date_day_string]\n",
    "\n",
    "            # load electricity prices for charging\n",
    "            electricity_price = charging_costs_dict[date_day_string]\n",
    "\n",
    "            # load secondary energy prices for v2g\n",
    "            v2g_price = v2g_price_dict[date_day_string]\n",
    "\n",
    "            # select discrete data of day\n",
    "            daily_data = data.iloc[:,day-97:day-1]\n",
    "            planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "            planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "            # reset environment at beginnning of simulation\n",
    "            if count == 0:\n",
    "\n",
    "                # create environment\n",
    "                env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 100, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                               electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                               planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 234, RL = True, v2g_demand_event_min = 10, v2g_demand_event_max = 10)\n",
    "\n",
    "                # create RL model\n",
    "                model = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "                model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                    nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    model.policy.mlp_extractor.policy_net[3]\n",
    "                )\n",
    "                model.policy.action_net =  nn.Linear(64, 30)\n",
    "                model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                    nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    model.policy.mlp_extractor.value_net[3]\n",
    "                )\n",
    "                model.policy.value_net =  nn.Linear(64, 1)\n",
    "                new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "                model.set_logger(new_logger)\n",
    "\n",
    "                #model.policy.to(device)\n",
    "\n",
    "                r = validation(model)\n",
    "                print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "                reward_list.append(r)\n",
    "                count_list.append(count)\n",
    "\n",
    "            else: \n",
    "                env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                              electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                              planned_durations = planned_durations_day)\n",
    "                s = env.reset()\n",
    "                \n",
    "            print(\"day\")\n",
    "\n",
    "\n",
    "            # learn one episode\n",
    "            model.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "\n",
    "\n",
    "            if count in range(5,30000,100):\n",
    "                r = validation(model)\n",
    "                print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "                reward_list.append(r)\n",
    "                count_list.append(count)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            count += 1\n",
    "   \n",
    "    model.save(\"car_sharing_v2g_model_small\")\n",
    "    np.save(\"reward_list_model_small\", reward_list)\n",
    "    np.save(\"count_list_model_small\", count_list)\n",
    "    \n",
    "    # create environment\n",
    "    env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 100, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                               electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                               planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 234, RL = True, v2g_demand_event_min = 10, v2g_demand_event_max = 10)\n",
    "\n",
    "    \n",
    "    \n",
    "    model = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "    model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.policy_net[3]\n",
    "    )\n",
    "    model.policy.action_net =  nn.Linear(64, 30)\n",
    "    model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.value_net[3]\n",
    "    )\n",
    "    model.policy.value_net =  nn.Linear(64, 1)\n",
    "    new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "    model.set_logger(new_logger)\n",
    "    model.set_parameters(\"car_sharing_v2g_model_small\", device = \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3541b2-3be5-4b3f-a9d7-55e5ed210aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for week_nr in range(start_week, math.ceil((start_week * 7 + nr_iterations) / 7)):\n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "        \n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = count * 96 + week_nr*7*96\n",
    "        \n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "            \n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "        \n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "        \n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "    \n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "        \n",
    "        # reset environment at beginnning of simulation\n",
    "        if count == 0:\n",
    "            \n",
    "            # create environment\n",
    "            env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 499, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 15451)\n",
    "            model = PPO(\"MlpPolicy\",env, verbose=1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "            model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 1024),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1024, 5120),\n",
    "                model.policy.mlp_extractor.policy_net[3]\n",
    "            )\n",
    "            model.policy.action_net =  nn.Linear(5120, 13260)\n",
    "            model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 1028),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1028, 128),\n",
    "                model.policy.mlp_extractor.value_net[3]\n",
    "            )\n",
    "            model.policy.value_net =  nn.Linear(128, 1)\n",
    "            \n",
    "            # load parameters \n",
    "            model.set_parameters(\"car_sharing_v2g_model1\", device = \"cpu\")\n",
    "            \n",
    "            #model.policy.to(device)\n",
    "            \n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "            \n",
    "        else: \n",
    "            env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day)\n",
    "            s = env.reset()\n",
    "            \n",
    "        \n",
    "        # learn one episode\n",
    "        model.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "            \n",
    "          \n",
    "        print(\"\")\n",
    "        print(\"Learned episode: \",count)\n",
    "        print(\"\")\n",
    "        \n",
    "        if count in range(5,nr_iterations + 1,10):\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a3bacf7-83ff-4d58-b2ea-05128d063238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f597a3b1-539c-464f-b981-71dd9440d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model2\")\n",
    "np.save(\"reward_list_model2\", reward_list)\n",
    "np.save(\"count_list_model2\", count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4add6625-62ad-4953-a52f-7c966fa6e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 105, 205, 305, 405, 505]\n"
     ]
    }
   ],
   "source": [
    "print(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02dc0c25-c4b2-4e29-97aa-6b90a5bfe5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d820746-3aff-4879-82cb-f52c5f7183e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=17682, out_features=1024, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "  (3): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.mlp_extractor.policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2b96a66-e203-4bb3-b96f-ecb7eb66befe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=17682, out_features=1024, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=17682, out_features=1028, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1028, out_features=128, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=5120, out_features=13260, bias=True)\n",
       "  (value_net): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "    nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 1024),  # Modify the first layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 5120),\n",
    "    model.policy.mlp_extractor.policy_net[3]\n",
    ")\n",
    "model.policy.action_net =  nn.Linear(5120, 13260)\n",
    "model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "    nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 1028),  # Modify the first layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1028, 128),\n",
    "    model.policy.mlp_extractor.value_net[3]\n",
    ")\n",
    "model.policy.value_net =  nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "# print network\n",
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee091266-a85c-4ddb-b5d7-21312f6afd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_parameters(\"car_sharing_v2g_model1\", device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d26182bc-b234-410b-90bd-c1511fffc59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stable_baselines3.common.net_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ActorCriticPolicy\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlattenExtractor, MlpExtractor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomPolicy\u001b[39;00m(ActorCriticPolicy):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3.common.net_util'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.net_util import FlattenExtractor, MlpExtractor\n",
    "\n",
    "class CustomPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(*args, **kwargs,\n",
    "                                            net_arch=[dict(pi=[64, 64], vf=[64, 64])],\n",
    "                                            features_extractor_class=FlattenExtractor,\n",
    "                                            features_extractor_kwargs=dict(flatten_dim=1),\n",
    "                                            )\n",
    "        self.mlp_extractor = MlpExtractor(\n",
    "            self.features_extractor.features_dim,\n",
    "            net_arch=[1024, 5120],\n",
    "            activation_fn=torch.nn.Tanh\n",
    "        )\n",
    "\n",
    "model = PPO(CustomPolicy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db7882f4-89cc-4217-a284-d06348b956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad4be9a8-5aa4-496c-8baa-c5d7af8a6170",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ActorCriticPolicy' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ActorCriticPolicy' object has no attribute 'weights'"
     ]
    }
   ],
   "source": [
    "model1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa465bbc-980f-4482-898a-034c5a0867cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.0.weight: copying a param with shape torch.Size([1024, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.policy_net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.policy_net.2.weight: copying a param with shape torch.Size([5120, 1024]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.policy_net.2.bias: copying a param with shape torch.Size([5120]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.0.weight: copying a param with shape torch.Size([1028, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.value_net.0.bias: copying a param with shape torch.Size([1028]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.2.weight: copying a param with shape torch.Size([128, 1028]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.value_net.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for action_net.weight: copying a param with shape torch.Size([13260, 5120]) from checkpoint, the shape in current model is torch.Size([13260, 64]).\n\tsize mismatch for value_net.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcar_sharing_v2g_model1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:737\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably loading a model saved with SB3 < 1.7.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwe deactivated exact_match so you can save the model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: the model should still work fine, this only a warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m         )\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# put other pytorch variables back in place\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pytorch_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:721\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m model\u001b[38;5;241m.\u001b[39m_setup_model()\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# put state_dicts back in place\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# Patch to load Policy saved using SB3 < 1.7.0\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;66;03m# the error is probably due to old policy being loaded\u001b[39;00m\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;66;03m# See https://github.com/DLR-RM/stable-baselines3/issues/1233\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi_features_extractor\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:615\u001b[0m, in \u001b[0;36mBaseAlgorithm.set_parameters\u001b[1;34m(self, load_path_or_dict, exact_match, device)\u001b[0m\n\u001b[0;32m    612\u001b[0m         attr\u001b[38;5;241m.\u001b[39mload_state_dict(params[name])\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;66;03m# Assume attr is th.nn.Module\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m         \u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_match\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m     updated_objects\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_match \u001b[38;5;129;01mand\u001b[39;00m updated_objects \u001b[38;5;241m!=\u001b[39m objects_needing_update:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.0.weight: copying a param with shape torch.Size([1024, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.policy_net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.policy_net.2.weight: copying a param with shape torch.Size([5120, 1024]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.policy_net.2.bias: copying a param with shape torch.Size([5120]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.0.weight: copying a param with shape torch.Size([1028, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.value_net.0.bias: copying a param with shape torch.Size([1028]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.2.weight: copying a param with shape torch.Size([128, 1028]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.value_net.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for action_net.weight: copying a param with shape torch.Size([13260, 5120]) from checkpoint, the shape in current model is torch.Size([13260, 64]).\n\tsize mismatch for value_net.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 64])."
     ]
    }
   ],
   "source": [
    "model.load(\"car_sharing_v2g_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35175df5-602a-4d59-a40c-1c07ee9ea4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

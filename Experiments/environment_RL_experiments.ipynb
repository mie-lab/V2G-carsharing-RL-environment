{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a711d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from rl_v2g import CarsharingEnv\n",
    "import math\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "from gym.utils.env_checker import check_env as checker_gym\n",
    "from stable_baselines3.common.env_checker import check_env as checker_baselines3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "# load the database credentials from the JSON file\n",
    "with open('config/credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "# create connection string\n",
    "connection_string = f\"postgresql://{credentials['username']}:{credentials['password']}@{credentials['host']}:{credentials['port']}/{credentials['database_name']}\"\n",
    "\n",
    "# create the engine with the connection string\n",
    "engine = create_engine(connection_string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29ef2f8-3483-4b7a-8fa8-7a3179142a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef043073-4e4b-4e33-9861-e3e660ef8259",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'snakeviz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mload_ext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msnakeviz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2369\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[1;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[0;32m   2367\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[0;32m   2368\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[1;32m-> 2369\u001b[0m     result \u001b[38;5;241m=\u001b[39m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2371\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[0;32m   2372\u001b[0m \u001b[38;5;66;03m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[0;32m   2373\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[0;32m   2374\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\IPython\\core\\magics\\extension.py:33\u001b[0m, in \u001b[0;36mExtensionMagics.load_ext\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m module_str:\n\u001b[0;32m     32\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m UsageError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing module name.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 33\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshell\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextension_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124malready loaded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m extension is already loaded. To reload it, use:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m module_str)\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\IPython\\core\\extensions.py:76\u001b[0m, in \u001b[0;36mExtensionManager.load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load an IPython extension by its module name.\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \n\u001b[0;32m     71\u001b[0m \u001b[38;5;124;03mReturns the string \"already loaded\" if the extension is already loaded,\u001b[39;00m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"no load function\" if the module doesn't have a load_ipython_extension\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;124;03mfunction, or None if it succeeded.\u001b[39;00m\n\u001b[0;32m     74\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_extension\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m:\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01min\u001b[39;00m BUILTINS_EXTS:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\IPython\\core\\extensions.py:91\u001b[0m, in \u001b[0;36mExtensionManager._load_extension\u001b[1;34m(self, module_str)\u001b[0m\n\u001b[0;32m     89\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshell\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m module_str \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mmodules:\n\u001b[1;32m---> 91\u001b[0m         mod \u001b[38;5;241m=\u001b[39m \u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     92\u001b[0m     mod \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mmodules[module_str]\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_load_ipython_extension(mod):\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    125\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1030\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1007\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:984\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'snakeviz'"
     ]
    }
   ],
   "source": [
    "%load_ext snakeviz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b0673-9dca-4b10-b742-4f4af1d3bc48",
   "metadata": {},
   "source": [
    "# Application of Car-sharing Simulation Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783aa047-30ec-4998-93ef-aa05f6d709f2",
   "metadata": {},
   "source": [
    "Choose the timespan for the simulation. The simulation will be executed chronologically, starting from the first day (2019-1-1) and continuing for subsequent days (2019-1-2, 2019-1-3, etc.). If a start date other than 2019-1-1 is selected, the \"Start simulation\" cell below may need to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c92e923b-e2c0-4257-9028-d30dbdff5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learn period\n",
    "start_date = date(2019, 1, 8)\n",
    "end_date = date(2020, 1, 1)\n",
    "#end_date = date(2019, 1, 10)\n",
    "start_week = 1\n",
    "\n",
    "# set simulation period\n",
    "start_date_simulation = date(2019, 1, 1)\n",
    "end_date_simulation = date(2019, 1, 8)\n",
    "start_week_simulation = 0\n",
    "\n",
    "# calculate number of days to learn\n",
    "nr_iterations = (end_date - start_date).days\n",
    "\n",
    "# calculate number of days to simulate\n",
    "nr_iterations_simulation = (end_date_simulation - start_date_simulation).days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e51f9-3dc9-4a24-9527-95dc871616d6",
   "metadata": {},
   "source": [
    "# Load data for simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec0e94-a367-42fb-bf33-99ef8df0c844",
   "metadata": {},
   "source": [
    "### Car-sharing stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e17d3ddf-c804-442f-8d29-3a23c2305fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_no</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2901</td>\n",
       "      <td>POINT (2555501.836 1145060.068)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2905</td>\n",
       "      <td>POINT (2752963.411 1260089.916)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2910</td>\n",
       "      <td>POINT (2501877.645 1126218.900)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2913</td>\n",
       "      <td>POINT (2682234.096 1243208.370)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2918</td>\n",
       "      <td>POINT (2736874.744 1253090.505)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_no                             geom\n",
       "0        2901  POINT (2555501.836 1145060.068)\n",
       "1        2905  POINT (2752963.411 1260089.916)\n",
       "2        2910  POINT (2501877.645 1126218.900)\n",
       "3        2913  POINT (2682234.096 1243208.370)\n",
       "4        2918  POINT (2736874.744 1253090.505)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get station geodata, create spatial index\n",
    "sql = \" SELECT * FROM msc_2023_dominik.distinct_stations\"\n",
    "stations = gpd.read_postgis(sql, engine, geom_col='geom',crs = \"EPSG:2056\")\n",
    "stations.sindex\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75c9df-a17b-4aa5-82c7-6b1d9678cac2",
   "metadata": {},
   "source": [
    "### Vehicle information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d8127d0-ea76-4840-8b09-d9dccac60708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>model_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>charge_power</th>\n",
       "      <th>battery_capacity</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2962</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106516</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2963</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106517</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2964</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106518</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2965</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106519</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2966</td>\n",
       "      <td>Combi</td>\n",
       "      <td>106526</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index vehicle_category  vehicle_no                   model_name  \\\n",
       "0   2962          Minivan      106516  eVito 129KB Tourer Pro 3200   \n",
       "1   2963          Minivan      106517  eVito 129KB Tourer Pro 3200   \n",
       "2   2964          Minivan      106518  eVito 129KB Tourer Pro 3200   \n",
       "3   2965          Minivan      106519  eVito 129KB Tourer Pro 3200   \n",
       "4   2966            Combi      106526                   Enyaq iV80   \n",
       "\n",
       "      brand_name  charge_power  battery_capacity  range  \n",
       "0  Mercedes-Benz          11.0             100.0  378.0  \n",
       "1  Mercedes-Benz          11.0             100.0  378.0  \n",
       "2  Mercedes-Benz          11.0             100.0  378.0  \n",
       "3  Mercedes-Benz          11.0             100.0  378.0  \n",
       "4          Skoda          11.0              82.0  420.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get vehicle data\n",
    "sql = \"SELECT * FROM msc_2023_dominik.vehicle_information ORDER BY vehicle_no\"\n",
    "vehicles = pd.read_sql(sql, engine)\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd729dc1-8210-4b36-89af-82de5ba78cad",
   "metadata": {},
   "source": [
    "### Reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "361f0fc4-42f0-4efa-a64b-1ded60e626a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_no</th>\n",
       "      <th>start_station_no</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>reservationfrom_time_discrete</th>\n",
       "      <th>drive_firststart_time_discrete</th>\n",
       "      <th>drive_lastend_time_discrete</th>\n",
       "      <th>reservation_duration</th>\n",
       "      <th>revenue_distance</th>\n",
       "      <th>required_soc</th>\n",
       "      <th>revenue_duration</th>\n",
       "      <th>drive_km</th>\n",
       "      <th>drive_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24281745</td>\n",
       "      <td>4714</td>\n",
       "      <td>114572</td>\n",
       "      <td>72.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24281754</td>\n",
       "      <td>4714</td>\n",
       "      <td>114582</td>\n",
       "      <td>72.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22919882</td>\n",
       "      <td>4173</td>\n",
       "      <td>116242</td>\n",
       "      <td>576.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24340023</td>\n",
       "      <td>2902</td>\n",
       "      <td>116881</td>\n",
       "      <td>604.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>178.4</td>\n",
       "      <td>53.095238</td>\n",
       "      <td>301.5</td>\n",
       "      <td>223.0</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24154068</td>\n",
       "      <td>3057</td>\n",
       "      <td>113667</td>\n",
       "      <td>604.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reservation_no  start_station_no  vehicle_no  \\\n",
       "0        24281745              4714      114572   \n",
       "1        24281754              4714      114582   \n",
       "2        22919882              4173      116242   \n",
       "3        24340023              2902      116881   \n",
       "4        24154068              3057      113667   \n",
       "\n",
       "   reservationfrom_time_discrete  drive_firststart_time_discrete  \\\n",
       "0                           72.0                           715.0   \n",
       "1                           72.0                           716.0   \n",
       "2                          576.0                           734.0   \n",
       "3                          604.0                           701.0   \n",
       "4                          604.0                           706.0   \n",
       "\n",
       "   drive_lastend_time_discrete  reservation_duration  revenue_distance  \\\n",
       "0                        715.0                1804.0               0.0   \n",
       "1                        716.0                1804.0               0.0   \n",
       "2                        925.0                 672.0               0.0   \n",
       "3                        982.0                 380.0             178.4   \n",
       "4                        924.0                 424.0              68.5   \n",
       "\n",
       "   required_soc  revenue_duration  drive_km  drive_duration  \n",
       "0      0.000000               0.0       1.0             1.0  \n",
       "1      0.000000               0.0       1.0             1.0  \n",
       "2      9.500000               0.0      19.0           191.0  \n",
       "3     53.095238             301.5     223.0           283.0  \n",
       "4     51.500000             265.0     103.0           219.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get daily reservations, save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "reservations_dict = {}\n",
    "start_date_reservations = start_date\n",
    "while start_date_reservations <= end_date:\n",
    "    sql = \"\"\"SELECT reservation_no, start_station_no, vehicle_no, reservationfrom_time_discrete, drive_firststart_time_discrete, \n",
    "            drive_lastend_time_discrete, reservation_duration, revenue_distance, required_soc, revenue_duration, drive_km, \n",
    "            (floor(EXTRACT(epoch FROM (date_trunc('hour', TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) + \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes' \n",
    "                                - date_trunc('hour', TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) - \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes'\n",
    "                               )) / 900) * 900 + 900) / 900 AS drive_duration\n",
    "            FROM msc_2023_dominik.reservations_long_time \n",
    "            WHERE  DATE(reservationfrom_discrete_date) = '{}' or  DATE(drive_firststart_discrete_date) = '{}' \n",
    "            ORDER BY reservationfrom_discrete\"\"\".format(start_date_reservations, start_date_reservations)\n",
    "    reservations = pd.read_sql(sql, engine)\n",
    "    reservations_dict[start_date_reservations.strftime('%Y-%m-%d')] = reservations\n",
    "    start_date_reservations += delta\n",
    "reservations_dict[(start_date).strftime('%Y-%m-%d')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f0a110a9-b2b1-4887-b52d-4fc87278e1c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31', '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-29', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-25', '2019-05-26', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-20', '2019-06-21', '2019-06-22', '2019-06-23', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-19', '2019-07-20', '2019-07-21', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-27', '2019-07-28', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19', '2019-09-20', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-05', '2019-10-06', '2019-10-07', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01'])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservations_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67e6fc03-b963-4138-b7d7-618e371440de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_no</th>\n",
       "      <th>start_station_no</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>reservationfrom_time_discrete</th>\n",
       "      <th>drive_firststart_time_discrete</th>\n",
       "      <th>drive_lastend_time_discrete</th>\n",
       "      <th>reservation_duration</th>\n",
       "      <th>revenue_distance</th>\n",
       "      <th>required_soc</th>\n",
       "      <th>revenue_duration</th>\n",
       "      <th>drive_km</th>\n",
       "      <th>drive_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24519192</td>\n",
       "      <td>2886</td>\n",
       "      <td>114874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.50</td>\n",
       "      <td>5.384615</td>\n",
       "      <td>5.25</td>\n",
       "      <td>14.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24519174</td>\n",
       "      <td>1557</td>\n",
       "      <td>115969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.75</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>43.75</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24514447</td>\n",
       "      <td>2702</td>\n",
       "      <td>114871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24519221</td>\n",
       "      <td>3165</td>\n",
       "      <td>116525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24519097</td>\n",
       "      <td>4407</td>\n",
       "      <td>113833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reservation_no  start_station_no  vehicle_no  \\\n",
       "0        24519192              2886      114874   \n",
       "1        24519174              1557      115969   \n",
       "2        24514447              2702      114871   \n",
       "3        24519221              3165      116525   \n",
       "4        24519097              4407      113833   \n",
       "\n",
       "   reservationfrom_time_discrete  drive_firststart_time_discrete  \\\n",
       "0                            0.0                             0.0   \n",
       "1                            0.0                             0.0   \n",
       "2                            0.0                             4.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             2.0   \n",
       "\n",
       "   drive_lastend_time_discrete  reservation_duration  revenue_distance  \\\n",
       "0                          4.0                   6.0             10.50   \n",
       "1                         49.0                  50.0             45.75   \n",
       "2                          5.0                   6.0              2.66   \n",
       "3                         96.0                  96.0              0.00   \n",
       "4                          9.0                  10.0             13.00   \n",
       "\n",
       "   required_soc  revenue_duration  drive_km  drive_duration  \n",
       "0      5.384615              5.25      14.0             4.0  \n",
       "1     30.500000             43.75      61.0            50.0  \n",
       "2      1.538462              7.50       4.0             2.0  \n",
       "3      0.000000              0.00       0.0            97.0  \n",
       "4     10.000000              6.25      20.0             7.0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get daily reservations, save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "reservations_dict_simulation = {}\n",
    "start_date_reservations = start_date_simulation\n",
    "while start_date_reservations <= end_date_simulation:\n",
    "    sql = \"\"\"SELECT reservation_no, start_station_no, vehicle_no, reservationfrom_time_discrete, drive_firststart_time_discrete, \n",
    "            drive_lastend_time_discrete, reservation_duration, revenue_distance, required_soc, revenue_duration, drive_km, \n",
    "            (floor(EXTRACT(epoch FROM (date_trunc('hour', TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) + \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes' \n",
    "                                - date_trunc('hour', TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) - \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes'\n",
    "                               )) / 900) * 900 + 900) / 900 AS drive_duration\n",
    "            FROM msc_2023_dominik.reservations_long_time \n",
    "            WHERE  DATE(reservationfrom_discrete_date) = '{}' or  DATE(drive_firststart_discrete_date) = '{}' \n",
    "            ORDER BY reservationfrom_discrete\"\"\".format(start_date_reservations, start_date_reservations)\n",
    "    reservations = pd.read_sql(sql, engine)\n",
    "    reservations_dict_simulation[start_date_reservations.strftime('%Y-%m-%d')] = reservations\n",
    "    start_date_reservations += delta\n",
    "reservations_dict_simulation[(start_date_simulation).strftime('%Y-%m-%d')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f85c1bb3-758e-455f-bbbb-4837ca89ee4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservations_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231981c3-a6b3-4fe1-b35c-38218488d645",
   "metadata": {},
   "source": [
    "### Electicity prices for charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea91fd7f-4e91-460b-acc1-971747c0dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_chf_kwh_0.0</th>\n",
       "      <th>Price_chf_kwh_0.25</th>\n",
       "      <th>Price_chf_kwh_0.5</th>\n",
       "      <th>Price_chf_kwh_0.75</th>\n",
       "      <th>Price_chf_kwh_1.0</th>\n",
       "      <th>Price_chf_kwh_1.25</th>\n",
       "      <th>Price_chf_kwh_1.5</th>\n",
       "      <th>Price_chf_kwh_1.75</th>\n",
       "      <th>Price_chf_kwh_2.0</th>\n",
       "      <th>Price_chf_kwh_2.25</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_chf_kwh_21.75</th>\n",
       "      <th>Price_chf_kwh_22.0</th>\n",
       "      <th>Price_chf_kwh_22.25</th>\n",
       "      <th>Price_chf_kwh_22.5</th>\n",
       "      <th>Price_chf_kwh_22.75</th>\n",
       "      <th>Price_chf_kwh_23.0</th>\n",
       "      <th>Price_chf_kwh_23.25</th>\n",
       "      <th>Price_chf_kwh_23.5</th>\n",
       "      <th>Price_chf_kwh_23.75</th>\n",
       "      <th>Delivery day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.049484</td>\n",
       "      <td>0.049484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065208</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>2019-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067586</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>2019-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072842</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>2019-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072212</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>2019-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.059366</td>\n",
       "      <td>0.059366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058595</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>2019-01-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price_chf_kwh_0.0  Price_chf_kwh_0.25  Price_chf_kwh_0.5  \\\n",
       "0           0.055468            0.055468           0.055468   \n",
       "1           0.061907            0.061907           0.061907   \n",
       "2           0.062939            0.062939           0.062939   \n",
       "3           0.068889            0.068889           0.068889   \n",
       "4           0.067521            0.067521           0.067521   \n",
       "\n",
       "   Price_chf_kwh_0.75  Price_chf_kwh_1.0  Price_chf_kwh_1.25  \\\n",
       "0            0.055468           0.050245            0.050245   \n",
       "1            0.061907           0.057564            0.057564   \n",
       "2            0.062939           0.058443            0.058443   \n",
       "3            0.068889           0.061907            0.061907   \n",
       "4            0.067521           0.061951            0.061951   \n",
       "\n",
       "   Price_chf_kwh_1.5  Price_chf_kwh_1.75  Price_chf_kwh_2.0  \\\n",
       "0           0.050245            0.050245           0.049484   \n",
       "1           0.057564            0.057564           0.057086   \n",
       "2           0.058443            0.058443           0.058150   \n",
       "3           0.061907            0.061907           0.060854   \n",
       "4           0.061951            0.061951           0.059366   \n",
       "\n",
       "   Price_chf_kwh_2.25  ...  Price_chf_kwh_21.75  Price_chf_kwh_22.0  \\\n",
       "0            0.049484  ...             0.065208            0.065165   \n",
       "1            0.057086  ...             0.067586            0.067641   \n",
       "2            0.058150  ...             0.072842            0.070312   \n",
       "3            0.060854  ...             0.072212            0.071756   \n",
       "4            0.059366  ...             0.058595            0.061353   \n",
       "\n",
       "   Price_chf_kwh_22.25  Price_chf_kwh_22.5  Price_chf_kwh_22.75  \\\n",
       "0             0.065165            0.065165             0.065165   \n",
       "1             0.067641            0.067641             0.067641   \n",
       "2             0.070312            0.070312             0.070312   \n",
       "3             0.071756            0.071756             0.071756   \n",
       "4             0.061353            0.061353             0.061353   \n",
       "\n",
       "   Price_chf_kwh_23.0  Price_chf_kwh_23.25  Price_chf_kwh_23.5  \\\n",
       "0            0.061071             0.061071            0.061071   \n",
       "1            0.064112             0.064112            0.064112   \n",
       "2            0.061842             0.061842            0.061842   \n",
       "3            0.069389             0.069389            0.069389   \n",
       "4            0.058606             0.058606            0.058606   \n",
       "\n",
       "   Price_chf_kwh_23.75  Delivery day  \n",
       "0             0.061071    2019-01-08  \n",
       "1             0.064112    2019-01-09  \n",
       "2             0.061842    2019-01-10  \n",
       "3             0.069389    2019-01-11  \n",
       "4             0.058606    2019-01-12  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get charging costs data\n",
    "prices = \"\"\n",
    "for i in range(0, 480, 5):\n",
    "    price = i / 20\n",
    "    prices += '\"Price_chf_kwh_{}\", '.format(price)\n",
    "\n",
    "sql = \"\"\"SELECT {} \"Delivery day\" FROM msc_2023_dominik.charging_costs WHERE \"Delivery day\" >=  '{}' and \"Delivery day\" <=  '{}' ORDER BY \"Delivery day\" \"\"\".format(prices, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "charging_costs = pd.read_sql(sql, engine)\n",
    "charging_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a518a3fd-5556-412e-8514-cb45384f601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "charging_costs_dict = {}\n",
    "start_date_electricity = start_date\n",
    "while start_date_electricity <= end_date:\n",
    "    electricity_price_day = charging_costs[charging_costs[\"Delivery day\"].dt.date == start_date_electricity].drop([\"Delivery day\"],axis = 1).iloc[0].values\n",
    "    charging_costs_dict[start_date_electricity.strftime('%Y-%m-%d')] = electricity_price_day\n",
    "    start_date_electricity += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b385c5-f02c-40dd-8842-ec3436a920aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31', '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-29', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-25', '2019-05-26', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-20', '2019-06-21', '2019-06-22', '2019-06-23', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-19', '2019-07-20', '2019-07-21', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-27', '2019-07-28', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19', '2019-09-20', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-05', '2019-10-06', '2019-10-07', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charging_costs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fd3cd53e-3ed3-498b-9610-75fd56a57ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_chf_kwh_0.0</th>\n",
       "      <th>Price_chf_kwh_0.25</th>\n",
       "      <th>Price_chf_kwh_0.5</th>\n",
       "      <th>Price_chf_kwh_0.75</th>\n",
       "      <th>Price_chf_kwh_1.0</th>\n",
       "      <th>Price_chf_kwh_1.25</th>\n",
       "      <th>Price_chf_kwh_1.5</th>\n",
       "      <th>Price_chf_kwh_1.75</th>\n",
       "      <th>Price_chf_kwh_2.0</th>\n",
       "      <th>Price_chf_kwh_2.25</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_chf_kwh_21.75</th>\n",
       "      <th>Price_chf_kwh_22.0</th>\n",
       "      <th>Price_chf_kwh_22.25</th>\n",
       "      <th>Price_chf_kwh_22.5</th>\n",
       "      <th>Price_chf_kwh_22.75</th>\n",
       "      <th>Price_chf_kwh_23.0</th>\n",
       "      <th>Price_chf_kwh_23.25</th>\n",
       "      <th>Price_chf_kwh_23.5</th>\n",
       "      <th>Price_chf_kwh_23.75</th>\n",
       "      <th>Delivery day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055055</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066175</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.054241</td>\n",
       "      <td>0.054241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065045</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price_chf_kwh_0.0  Price_chf_kwh_0.25  Price_chf_kwh_0.5  \\\n",
       "0           0.054577            0.054577           0.054577   \n",
       "1           0.054262            0.054262           0.054262   \n",
       "2           0.057585            0.057585           0.057585   \n",
       "3           0.057107            0.057107           0.057107   \n",
       "4           0.068477            0.068477           0.068477   \n",
       "\n",
       "   Price_chf_kwh_0.75  Price_chf_kwh_1.0  Price_chf_kwh_1.25  \\\n",
       "0            0.054577           0.052927            0.052927   \n",
       "1            0.054262           0.052840            0.052840   \n",
       "2            0.057585           0.054838            0.054838   \n",
       "3            0.057107           0.056130            0.056130   \n",
       "4            0.068477           0.063503            0.063503   \n",
       "\n",
       "   Price_chf_kwh_1.5  Price_chf_kwh_1.75  Price_chf_kwh_2.0  \\\n",
       "0           0.052927            0.052927           0.051298   \n",
       "1           0.052840            0.052840           0.045130   \n",
       "2           0.054838            0.054838           0.052471   \n",
       "3           0.056130            0.056130           0.054241   \n",
       "4           0.063503            0.063503           0.059431   \n",
       "\n",
       "   Price_chf_kwh_2.25  ...  Price_chf_kwh_21.75  Price_chf_kwh_22.0  \\\n",
       "0            0.051298  ...             0.055055            0.059855   \n",
       "1            0.045130  ...             0.066175            0.065230   \n",
       "2            0.052471  ...             0.068433            0.066262   \n",
       "3            0.054241  ...             0.070214            0.070301   \n",
       "4            0.059431  ...             0.065045            0.066381   \n",
       "\n",
       "   Price_chf_kwh_22.25  Price_chf_kwh_22.5  Price_chf_kwh_22.75  \\\n",
       "0             0.059855            0.059855             0.059855   \n",
       "1             0.065230            0.065230             0.065230   \n",
       "2             0.066262            0.066262             0.066262   \n",
       "3             0.070301            0.070301             0.070301   \n",
       "4             0.066381            0.066381             0.066381   \n",
       "\n",
       "   Price_chf_kwh_23.0  Price_chf_kwh_23.25  Price_chf_kwh_23.5  \\\n",
       "0            0.059844             0.059844            0.059844   \n",
       "1            0.064036             0.064036            0.064036   \n",
       "2            0.062276             0.062276            0.062276   \n",
       "3            0.065914             0.065914            0.065914   \n",
       "4            0.066370             0.066370            0.066370   \n",
       "\n",
       "   Price_chf_kwh_23.75  Delivery day  \n",
       "0             0.059844    2019-01-01  \n",
       "1             0.064036    2019-01-02  \n",
       "2             0.062276    2019-01-03  \n",
       "3             0.065914    2019-01-04  \n",
       "4             0.066370    2019-01-05  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get charging costs data\n",
    "prices = \"\"\n",
    "for i in range(0, 480, 5):\n",
    "    price = i / 20\n",
    "    prices += '\"Price_chf_kwh_{}\", '.format(price)\n",
    "\n",
    "sql = \"\"\"SELECT {} \"Delivery day\" FROM msc_2023_dominik.charging_costs WHERE \"Delivery day\" >=  '{}' and \"Delivery day\" <=  '{}' ORDER BY \"Delivery day\" \"\"\".format(prices, start_date_simulation.strftime('%Y-%m-%d'), end_date_simulation.strftime('%Y-%m-%d'))\n",
    "\n",
    "charging_costs = pd.read_sql(sql, engine)\n",
    "charging_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97d9360b-58a7-4abc-a745-fa48e34b63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "charging_costs_dict_simulation = {}\n",
    "start_date_electricity = start_date_simulation\n",
    "while start_date_electricity <= end_date_simulation:\n",
    "    electricity_price_day = charging_costs[charging_costs[\"Delivery day\"].dt.date == start_date_electricity].drop([\"Delivery day\"],axis = 1).iloc[0].values\n",
    "    charging_costs_dict_simulation[start_date_electricity.strftime('%Y-%m-%d')] = electricity_price_day\n",
    "    start_date_electricity += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a4bcea5-de92-4b8b-b338-f1c6e920b6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charging_costs_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf046c-5db6-45c4-ab6e-edf86bfd9f77",
   "metadata": {},
   "source": [
    "### Secondary energy prices (for V2G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45a1fb02-3e5d-4d8c-8394-f465d7cff15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Secondary_positive_v2g_prices_chf_kwh</th>\n",
       "      <th>Secondary_negative_v2g_prices_chf_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-08 00:00:00</td>\n",
       "      <td>0.052801</td>\n",
       "      <td>0.035201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-08 00:15:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-08 00:30:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-08 00:45:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08 01:00:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Secondary_positive_v2g_prices_chf_kwh  \\\n",
       "0 2019-01-08 00:00:00                               0.052801   \n",
       "1 2019-01-08 00:15:00                               0.052687   \n",
       "2 2019-01-08 00:30:00                               0.052687   \n",
       "3 2019-01-08 00:45:00                               0.052687   \n",
       "4 2019-01-08 01:00:00                               0.052687   \n",
       "\n",
       "   Secondary_negative_v2g_prices_chf_kwh  \n",
       "0                               0.035201  \n",
       "1                               0.035132  \n",
       "2                               0.035132  \n",
       "3                               0.035132  \n",
       "4                               0.035132  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get v2g price data\n",
    "sql = \"\"\"SELECT \"Timestamp\", \"Secondary_positive_v2g_prices_chf_kwh\", \"Secondary_negative_v2g_prices_chf_kwh\" FROM msc_2023_dominik.v2g_prices WHERE \"Timestamp\" >=  '{}' and \"Timestamp\" <=  '{}' ORDER BY \"Timestamp\" \"\"\".format(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "v2g_prices = pd.read_sql(sql, engine)\n",
    "v2g_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2c003997-a4e1-496c-8b8f-f034b238efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "v2g_price_dict = {}\n",
    "start_date_v2g = start_date\n",
    "while start_date_v2g <= end_date:\n",
    "    v2g_price_day_positive = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_positive_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_day_negative = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_negative_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_dict[start_date_v2g.strftime('%Y-%m-%d')] = [v2g_price_day_positive, v2g_price_day_negative]\n",
    "    start_date_v2g += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "035a9fce-2bb1-47e8-a5e7-f902655900aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31', '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-29', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-25', '2019-05-26', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-20', '2019-06-21', '2019-06-22', '2019-06-23', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-19', '2019-07-20', '2019-07-21', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-27', '2019-07-28', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19', '2019-09-20', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-05', '2019-10-06', '2019-10-07', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2g_price_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4ed1cc3d-e732-4e7a-b427-5d16f7fad311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Secondary_positive_v2g_prices_chf_kwh</th>\n",
       "      <th>Secondary_negative_v2g_prices_chf_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.068370</td>\n",
       "      <td>0.045588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Secondary_positive_v2g_prices_chf_kwh  \\\n",
       "0 2019-01-01 00:00:00                               0.068370   \n",
       "1 2019-01-01 00:15:00                               0.068838   \n",
       "2 2019-01-01 00:30:00                               0.068838   \n",
       "3 2019-01-01 00:45:00                               0.068838   \n",
       "4 2019-01-01 01:00:00                               0.068838   \n",
       "\n",
       "   Secondary_negative_v2g_prices_chf_kwh  \n",
       "0                               0.045588  \n",
       "1                               0.045896  \n",
       "2                               0.045896  \n",
       "3                               0.045896  \n",
       "4                               0.045896  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get v2g price data\n",
    "sql = \"\"\"SELECT \"Timestamp\", \"Secondary_positive_v2g_prices_chf_kwh\", \"Secondary_negative_v2g_prices_chf_kwh\" FROM msc_2023_dominik.v2g_prices WHERE \"Timestamp\" >=  '{}' and \"Timestamp\" <=  '{}' ORDER BY \"Timestamp\" \"\"\".format(start_date_simulation.strftime('%Y-%m-%d'), end_date_simulation.strftime('%Y-%m-%d'))\n",
    "v2g_prices = pd.read_sql(sql, engine)\n",
    "v2g_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e336d8c8-67e2-4a61-b30b-71e43a1189c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "v2g_price_dict_simulation = {}\n",
    "start_date_v2g = start_date_simulation\n",
    "while start_date_v2g <= end_date_simulation:\n",
    "    v2g_price_day_positive = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_positive_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_day_negative = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_negative_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_dict_simulation[start_date_v2g.strftime('%Y-%m-%d')] = [v2g_price_day_positive, v2g_price_day_negative]\n",
    "    start_date_v2g += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efdd8077-9174-4e94-88dd-034a39c1d2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2g_price_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4bdff-3156-46e4-bf59-d2cc1a042ec9",
   "metadata": {},
   "source": [
    "# Check environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f88a71db-6071-422c-b45b-0ff53dd4a5aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if enviornment fullfils requirements of gym and stable-baselines3\n",
    "\n",
    "# load discrete table\n",
    "sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(0)\n",
    "data = pd.read_sql(sql, engine)\n",
    "    \n",
    "# load discrete planned reservation table\n",
    "sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(0)\n",
    "planned_reservations = pd.read_sql(sql, engine)\n",
    "    \n",
    "# load discrete planned reservation duration table\n",
    "sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(0)\n",
    "planned_durations = pd.read_sql(sql, engine)\n",
    "end = time.time()\n",
    "\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "    \n",
    "count = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for week_nr in range(start_week, 1):\n",
    "    # iteration for each day\n",
    "    for day in range(98,99,96):\n",
    "        \n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = count * 96\n",
    "        \n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "            \n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "        \n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "        \n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "    \n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "        \n",
    "        # create environment\n",
    "        env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 10000, penalty_per_kwh = 0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day)\n",
    "        \n",
    "        # check implementation \n",
    "        checker_gym(env)\n",
    "        checker_baselines3(env)\n",
    "        # count number of simulated days\n",
    "        count += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15f8c0-60b6-441a-a835-3a291ba491d1",
   "metadata": {},
   "source": [
    "# Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "264c2bc8-fd14-4481-921d-88eeef84a395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check support of GPU\n",
    "stable_baselines3.common.utils.get_device(device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4295f-9b5b-4051-a8e0-6b5301f4968c",
   "metadata": {},
   "source": [
    "Start simulation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3bce6a6d-ea89-4347-becd-c98a0d328e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    nr_vehicles = len(vehicles)\n",
    "    \n",
    "    global nr_iterations_simulation\n",
    "\n",
    "    # maximal simulation length\n",
    "    if nr_iterations_simulation > 577:\n",
    "        nr_iterations_simulation = 577\n",
    "        \n",
    "    total_reward = 0\n",
    "\n",
    "    count = 0\n",
    "    # iterate over weeks (for loading weekly discrete data)\n",
    "    for week_nr in range(start_week_simulation, math.ceil((start_week_simulation * 7 + nr_iterations_simulation) / 7)):\n",
    "        # load discrete car-sharing table\n",
    "        sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "        data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "        planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "        planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "\n",
    "        # iteration for each day\n",
    "        for day in range(98,676,96):\n",
    "\n",
    "            # calculate number of timesteps since first day of simulation\n",
    "            timesteps_since_start = count * 96\n",
    "\n",
    "            # all requested days are simulated\n",
    "            if count == nr_iterations:\n",
    "                break\n",
    "\n",
    "            # get date\n",
    "            date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "            date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "            # load reservations\n",
    "            reservations = reservations_dict_simulation[date_day_string]\n",
    "\n",
    "            # load electricity prices for charging\n",
    "            electricity_price = charging_costs_dict_simulation[date_day_string]\n",
    "\n",
    "            # load secondary energy prices for v2g\n",
    "            v2g_price = v2g_price_dict_simulation[date_day_string]\n",
    "\n",
    "            # select discrete data of day\n",
    "            daily_data = data.iloc[:,day-97:day-1]\n",
    "            planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "            planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "            # reset environment at beginnning of simulation\n",
    "            if count == 0:\n",
    "                environment = CarsharingEnv(stations, vehicles, planned_bookings = True, \n",
    "                                   daily_data = daily_data, reservations = reservations, electricity_price = electricity_price,\n",
    "                                    timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day, \n",
    "                                    planned_durations = planned_durations_day, random_seed_number = 42, v2g_penalty = 10000)\n",
    "                s = environment.reset()\n",
    "\n",
    "            # beginn new day without reseting environemnt \n",
    "            else:\n",
    "                environment.next_day(daily_data, reservations, electricity_price, timesteps_since_start, v2g_price, planned_reservations_day, planned_durations_day)\n",
    "\n",
    "            # simulate day in 15 min steps\n",
    "            done = False\n",
    "            counter = 0\n",
    "            while not done:\n",
    "\n",
    "                # get your action \n",
    "                act, _states = model.predict(s)\n",
    "\n",
    "                # proceed one time step\n",
    "                s, rew, done, _ = environment.step(act)\n",
    "                \n",
    "                total_reward += rew\n",
    "\n",
    "                counter +=1\n",
    "\n",
    "            # plot summary statistics of episode (day)\n",
    "            #environment.daily_summary_statistics()\n",
    "\n",
    "            # plot summary statistic over full simulation period\n",
    "            #if count == nr_iterations - 1:\n",
    "              #  environment.episode_summary_statistics(nr_iterations)\n",
    "\n",
    "            # count number of simulated days\n",
    "            count += 1\n",
    "            \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "90a4f297-7852-4abe-8403-3d37d8e7e071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=17682, out_features=1024, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "  (3): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.mlp_extractor.policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1bc6e57c-326a-458c-9efa-1882f7b1bf09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stable_baselines3.common.logger import configure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fac97-9e37-4001-b613-312ed70d4240",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment to timestamp:  672\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /tmp/sb3_log/\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 9.92e+04 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 123      |\n",
      "|    total_timesteps | 95       |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  0\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 190           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.08e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 1             |\n",
      "|    policy_gradient_loss | -4.54e-05     |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  1\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 285           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.25e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 2             |\n",
      "|    policy_gradient_loss | -2.33e-05     |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  2\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 122           |\n",
      "|    total_timesteps      | 380           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.17e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 3             |\n",
      "|    policy_gradient_loss | -3.46e-05     |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  3\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.93e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 122           |\n",
      "|    total_timesteps      | 475           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.11e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 4             |\n",
      "|    policy_gradient_loss | -6.56e-05     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  4\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 122           |\n",
      "|    total_timesteps      | 570           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.23e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 5             |\n",
      "|    policy_gradient_loss | -3.23e-05     |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  5\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.9e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 665           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.48e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 6             |\n",
      "|    policy_gradient_loss | -1.25e-07     |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  6\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.95e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 122           |\n",
      "|    total_timesteps      | 760           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7683717e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.17e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 7             |\n",
      "|    policy_gradient_loss | 1.46e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  7\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.98e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 855           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7567684e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.31e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 8             |\n",
      "|    policy_gradient_loss | 2.12e-05      |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  8\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.76e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 950           |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.07e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.88e+08      |\n",
      "|    n_updates            | 9             |\n",
      "|    policy_gradient_loss | -1.9e-05      |\n",
      "|    value_loss           | 3.75e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  9\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.97e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 1045          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.53e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | 2.67e-05      |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  10\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 1140          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1448218e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.11e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 11            |\n",
      "|    policy_gradient_loss | 3.52e-06      |\n",
      "|    value_loss           | 3.74e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  11\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 1235          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1e-05         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 12            |\n",
      "|    policy_gradient_loss | 2.57e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  12\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.98e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 1330          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.34e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 13            |\n",
      "|    policy_gradient_loss | 1.94e-05      |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  13\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 1425          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.26e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 14            |\n",
      "|    policy_gradient_loss | -1.99e-05     |\n",
      "|    value_loss           | 3.74e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  14\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 1520          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.13e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 15            |\n",
      "|    policy_gradient_loss | 2.14e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  15\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.81e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 1615          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.58e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 16            |\n",
      "|    policy_gradient_loss | 1.01e-05      |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  16\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.75e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 124         |\n",
      "|    total_timesteps      | 1710        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 9.3e-06     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+08    |\n",
      "|    n_updates            | 17          |\n",
      "|    policy_gradient_loss | -7.05e-06   |\n",
      "|    value_loss           | 3.65e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  17\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.92e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 1805         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.29e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+08     |\n",
      "|    n_updates            | 18           |\n",
      "|    policy_gradient_loss | -1.76e-07    |\n",
      "|    value_loss           | 3.63e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  18\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 1900          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5308983e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.48e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 19            |\n",
      "|    policy_gradient_loss | 1.74e-05      |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  19\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.76e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 1995          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.36e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -1.26e-05     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  20\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.85e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 2090          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.03e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 21            |\n",
      "|    policy_gradient_loss | 3.14e-05      |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  21\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.81e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 2185          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 22            |\n",
      "|    policy_gradient_loss | 2.25e-06      |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  22\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 2280          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.27e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 23            |\n",
      "|    policy_gradient_loss | -3.83e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  23\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 2375          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.31e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 24            |\n",
      "|    policy_gradient_loss | -1.78e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  24\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 2470          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.45e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 25            |\n",
      "|    policy_gradient_loss | -2.83e-05     |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  25\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 2565          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.9324453e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.11e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 26            |\n",
      "|    policy_gradient_loss | -0.000117     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  26\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 2660          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.38e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 27            |\n",
      "|    policy_gradient_loss | 2.14e-05      |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  27\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.96e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 125           |\n",
      "|    total_timesteps      | 2755          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8899874e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.18e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 28            |\n",
      "|    policy_gradient_loss | 1.68e-05      |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  28\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 2850          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.24e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 29            |\n",
      "|    policy_gradient_loss | -4.92e-05     |\n",
      "|    value_loss           | 3.73e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  29\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 125           |\n",
      "|    total_timesteps      | 2945          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.28e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | 3.3e-05       |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  30\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.9e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 3040         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 8.532876e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.31e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+08     |\n",
      "|    n_updates            | 31           |\n",
      "|    policy_gradient_loss | 7.54e-05     |\n",
      "|    value_loss           | 3.71e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  31\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.84e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 125          |\n",
      "|    total_timesteps      | 3135         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.04e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+08     |\n",
      "|    n_updates            | 32           |\n",
      "|    policy_gradient_loss | -1.19e-05    |\n",
      "|    value_loss           | 3.7e+08      |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  32\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 125           |\n",
      "|    total_timesteps      | 3230          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1409542e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.06e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 33            |\n",
      "|    policy_gradient_loss | 2.14e-05      |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  33\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.77e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 3325          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.17e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 34            |\n",
      "|    policy_gradient_loss | 2.88e-06      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  34\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.77e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 3420          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.19e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 35            |\n",
      "|    policy_gradient_loss | 2.84e-05      |\n",
      "|    value_loss           | 3.61e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  35\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.82e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 124          |\n",
      "|    total_timesteps      | 3515         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.631285e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.01e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+08     |\n",
      "|    n_updates            | 36           |\n",
      "|    policy_gradient_loss | -1.97e-05    |\n",
      "|    value_loss           | 3.62e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  36\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.69e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 123           |\n",
      "|    total_timesteps      | 3610          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1409542e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 37            |\n",
      "|    policy_gradient_loss | 1.46e-05      |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  37\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 127           |\n",
      "|    total_timesteps      | 3705          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.14e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+08      |\n",
      "|    n_updates            | 38            |\n",
      "|    policy_gradient_loss | -9.83e-06     |\n",
      "|    value_loss           | 3.59e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  38\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.85e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 127          |\n",
      "|    total_timesteps      | 3800         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0003502118 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.24e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 39           |\n",
      "|    policy_gradient_loss | -0.00327     |\n",
      "|    value_loss           | 3.68e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  39\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 124           |\n",
      "|    total_timesteps      | 3895          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.06e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -4.27e-06     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  40\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.89e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 3990         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.03e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 41           |\n",
      "|    policy_gradient_loss | -2.37e-05    |\n",
      "|    value_loss           | 3.66e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  41\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.93e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 135         |\n",
      "|    total_timesteps      | 4085        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.16e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+08    |\n",
      "|    n_updates            | 42          |\n",
      "|    policy_gradient_loss | -2.99e-06   |\n",
      "|    value_loss           | 3.67e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  42\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.77e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 140           |\n",
      "|    total_timesteps      | 4180          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.24e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 43            |\n",
      "|    policy_gradient_loss | 2.72e-05      |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  43\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.88e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 136         |\n",
      "|    total_timesteps      | 4275        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.12e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.81e+08    |\n",
      "|    n_updates            | 44          |\n",
      "|    policy_gradient_loss | 4.86e-06    |\n",
      "|    value_loss           | 3.62e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  44\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 4370          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.83e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 45            |\n",
      "|    policy_gradient_loss | 3.79e-05      |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  45\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.81e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 138           |\n",
      "|    total_timesteps      | 4465          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.4e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 46            |\n",
      "|    policy_gradient_loss | 8.3e-05       |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  46\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 135           |\n",
      "|    total_timesteps      | 4560          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.46e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 47            |\n",
      "|    policy_gradient_loss | 1.85e-05      |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  47\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.85e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 4655         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.14e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+08     |\n",
      "|    n_updates            | 48           |\n",
      "|    policy_gradient_loss | 3.82e-05     |\n",
      "|    value_loss           | 3.63e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  48\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.85e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 4750          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8899874e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.1e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 49            |\n",
      "|    policy_gradient_loss | -1.91e-05     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  49\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 134           |\n",
      "|    total_timesteps      | 4845          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.23e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | 1.95e-05      |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  50\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 138           |\n",
      "|    total_timesteps      | 4940          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.95e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 51            |\n",
      "|    policy_gradient_loss | -1.18e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  51\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.85e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 5035          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 52            |\n",
      "|    policy_gradient_loss | -7.93e-06     |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  52\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 137           |\n",
      "|    total_timesteps      | 5130          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 5.6e-06       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 53            |\n",
      "|    policy_gradient_loss | -1.86e-05     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  53\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.75e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 136          |\n",
      "|    total_timesteps      | 5225         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.631285e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 9.54e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 54           |\n",
      "|    policy_gradient_loss | 7.15e-06     |\n",
      "|    value_loss           | 3.66e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  54\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.8e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 135          |\n",
      "|    total_timesteps      | 5320         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.631285e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 8.11e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+08      |\n",
      "|    n_updates            | 55           |\n",
      "|    policy_gradient_loss | -1.04e-05    |\n",
      "|    value_loss           | 3.59e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  55\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.86e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 5415         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.391921e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 8.76e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+08     |\n",
      "|    n_updates            | 56           |\n",
      "|    policy_gradient_loss | -1.23e-05    |\n",
      "|    value_loss           | 3.63e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  56\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 137           |\n",
      "|    total_timesteps      | 5510          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.64e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 57            |\n",
      "|    policy_gradient_loss | -4.23e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  57\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 137           |\n",
      "|    total_timesteps      | 5605          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.14e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 58            |\n",
      "|    policy_gradient_loss | -5.72e-05     |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  58\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.91e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 136           |\n",
      "|    total_timesteps      | 5700          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7567684e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.11e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 59            |\n",
      "|    policy_gradient_loss | -2.19e-05     |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  59\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.87e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 134          |\n",
      "|    total_timesteps      | 5795         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.642888e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.27e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+08     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | 2.55e-05     |\n",
      "|    value_loss           | 3.72e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  60\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.84e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 137          |\n",
      "|    total_timesteps      | 5890         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0002529753 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 7.87e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 61           |\n",
      "|    policy_gradient_loss | 0.000733     |\n",
      "|    value_loss           | 3.68e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  61\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 137           |\n",
      "|    total_timesteps      | 5985          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1409542e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.16e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 62            |\n",
      "|    policy_gradient_loss | -3.04e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  62\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 6080          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.03e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 63            |\n",
      "|    policy_gradient_loss | -8.63e-07     |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  63\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.83e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 138          |\n",
      "|    total_timesteps      | 6175         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.47e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 64           |\n",
      "|    policy_gradient_loss | -1.85e-05    |\n",
      "|    value_loss           | 3.69e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  64\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.72e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 6270          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.2e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 65            |\n",
      "|    policy_gradient_loss | 1.95e-05      |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  65\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 144           |\n",
      "|    total_timesteps      | 6365          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.54e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+08      |\n",
      "|    n_updates            | 66            |\n",
      "|    policy_gradient_loss | 1.09e-06      |\n",
      "|    value_loss           | 3.57e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  66\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.75e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 6460          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.19e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 67            |\n",
      "|    policy_gradient_loss | 2.63e-05      |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  67\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 6555          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7683717e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.2e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 68            |\n",
      "|    policy_gradient_loss | 6.52e-06      |\n",
      "|    value_loss           | 3.61e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  68\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.73e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 6650          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.17e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 69            |\n",
      "|    policy_gradient_loss | 2.28e-05      |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  69\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.77e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 6745         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.133219e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.15e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+08     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | 1.35e-05     |\n",
      "|    value_loss           | 3.59e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  70\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.77e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 6840          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1448218e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.15e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 71            |\n",
      "|    policy_gradient_loss | -4.81e-05     |\n",
      "|    value_loss           | 3.61e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  71\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 6935          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.89e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 72            |\n",
      "|    policy_gradient_loss | -2.13e-06     |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  72\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 7030          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3803181e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.47e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 73            |\n",
      "|    policy_gradient_loss | -1.66e-06     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  73\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.76e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 7125          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.27e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 74            |\n",
      "|    policy_gradient_loss | -1.23e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  74\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 7220          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7683717e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.21e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 75            |\n",
      "|    policy_gradient_loss | -5.59e-06     |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  75\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.91e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 7315          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.2e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 76            |\n",
      "|    policy_gradient_loss | -4.28e-05     |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  76\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.8e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 7410         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 8.76e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+08     |\n",
      "|    n_updates            | 77           |\n",
      "|    policy_gradient_loss | -2.88e-05    |\n",
      "|    value_loss           | 3.71e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  77\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 7505          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.35e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 78            |\n",
      "|    policy_gradient_loss | -2.79e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  78\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.76e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 7600         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.41e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 79           |\n",
      "|    policy_gradient_loss | 9.51e-05     |\n",
      "|    value_loss           | 3.65e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  79\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 7695          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.16e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+08      |\n",
      "|    n_updates            | 80            |\n",
      "|    policy_gradient_loss | -1.86e-06     |\n",
      "|    value_loss           | 3.59e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  80\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 7790          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5058015e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.23e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 81            |\n",
      "|    policy_gradient_loss | -1.9e-06      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  81\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 7885          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3803181e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.42e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 82            |\n",
      "|    policy_gradient_loss | 5.58e-06      |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  82\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 7980          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.04e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 83            |\n",
      "|    policy_gradient_loss | 1.59e-05      |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  83\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.77e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 8075          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.02e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 84            |\n",
      "|    policy_gradient_loss | 6.11e-06      |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  84\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.86e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 8170         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.59e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+08     |\n",
      "|    n_updates            | 85           |\n",
      "|    policy_gradient_loss | 7.73e-06     |\n",
      "|    value_loss           | 3.62e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  85\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.71e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 8265          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.18e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 86            |\n",
      "|    policy_gradient_loss | -3.9e-05      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  86\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 8360          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.14e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+08      |\n",
      "|    n_updates            | 87            |\n",
      "|    policy_gradient_loss | -3.15e-05     |\n",
      "|    value_loss           | 3.57e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  87\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 8455          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.03e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 88            |\n",
      "|    policy_gradient_loss | 4.12e-05      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  88\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 8550          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.34e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 89            |\n",
      "|    policy_gradient_loss | -4e-05        |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  89\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.81e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 8645         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.48e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+08     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -3.37e-06    |\n",
      "|    value_loss           | 3.63e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  90\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.97e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 8740          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 5.3e-06       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 91            |\n",
      "|    policy_gradient_loss | -1.05e-05     |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  91\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 8835          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.72e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 92            |\n",
      "|    policy_gradient_loss | 6.52e-06      |\n",
      "|    value_loss           | 3.73e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  92\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 8930          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.26e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 93            |\n",
      "|    policy_gradient_loss | -3.07e-05     |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  93\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 9025          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.7e-06       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 94            |\n",
      "|    policy_gradient_loss | 7.67e-06      |\n",
      "|    value_loss           | 3.61e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  94\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 9120          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.4697434e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.26e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 95            |\n",
      "|    policy_gradient_loss | -0.000581     |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  95\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 9215          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.18e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 96            |\n",
      "|    policy_gradient_loss | -1.96e-05     |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  96\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 9310          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.19e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 97            |\n",
      "|    policy_gradient_loss | 1.25e-05      |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  97\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.97e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 9405          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.7683717e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.32e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 98            |\n",
      "|    policy_gradient_loss | -5.97e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  98\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.76e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 9500         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.08e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+08     |\n",
      "|    n_updates            | 99           |\n",
      "|    policy_gradient_loss | -1.8e-05     |\n",
      "|    value_loss           | 3.75e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  99\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.93e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 9595          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.5e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 100           |\n",
      "|    policy_gradient_loss | -6.64e-06     |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  100\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.91e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 9690          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.58e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 101           |\n",
      "|    policy_gradient_loss | -5.07e-05     |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  101\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 9785          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.22e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 102           |\n",
      "|    policy_gradient_loss | 4.44e-06      |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  102\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 9880          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 103           |\n",
      "|    policy_gradient_loss | -1.95e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  103\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.93e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 9975          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.09e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 104           |\n",
      "|    policy_gradient_loss | 1.1e-05       |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  104\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 10070         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.23e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 105           |\n",
      "|    policy_gradient_loss | -1.45e-05     |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  105\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.96e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 10165         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.06e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 106           |\n",
      "|    policy_gradient_loss | -7.27e-07     |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  106\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 10260         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.22e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 107           |\n",
      "|    policy_gradient_loss | 1.78e-06      |\n",
      "|    value_loss           | 3.73e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  107\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.95e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 10355         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.33e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 108           |\n",
      "|    policy_gradient_loss | -1.18e-05     |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  108\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.79e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 10450        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 9.6e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+08     |\n",
      "|    n_updates            | 109          |\n",
      "|    policy_gradient_loss | 2.04e-05     |\n",
      "|    value_loss           | 3.72e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  109\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 10545         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.19e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -3.7e-06      |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  110\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.81e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 10640         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7567684e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.27e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 111           |\n",
      "|    policy_gradient_loss | -2.12e-05     |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  111\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 10735         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.32e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 112           |\n",
      "|    policy_gradient_loss | -1.83e-05     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  112\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 10830         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5174048e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.44e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 113           |\n",
      "|    policy_gradient_loss | -2.38e-05     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  113\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.84e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 10925        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.34e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+08     |\n",
      "|    n_updates            | 114          |\n",
      "|    policy_gradient_loss | 3.63e-05     |\n",
      "|    value_loss           | 3.69e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  114\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.88e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 11020        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 5.188741e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.04e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 115          |\n",
      "|    policy_gradient_loss | -0.000165    |\n",
      "|    value_loss           | 3.66e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  115\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 11115         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.03e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 116           |\n",
      "|    policy_gradient_loss | -7.42e-06     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  116\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 11210         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.3e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 117           |\n",
      "|    policy_gradient_loss | 3.2e-05       |\n",
      "|    value_loss           | 3.73e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  117\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.98e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 11305         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.81e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 118           |\n",
      "|    policy_gradient_loss | -3.28e-06     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  118\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.9e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 11400        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.26e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.87e+08     |\n",
      "|    n_updates            | 119          |\n",
      "|    policy_gradient_loss | 6.26e-05     |\n",
      "|    value_loss           | 3.74e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  119\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.68e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 11495         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.06e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 120           |\n",
      "|    policy_gradient_loss | -5.25e-06     |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  120\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.92e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 11590        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.06e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.77e+08     |\n",
      "|    n_updates            | 121          |\n",
      "|    policy_gradient_loss | 9.32e-06     |\n",
      "|    value_loss           | 3.55e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  121\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 11685         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.17e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 122           |\n",
      "|    policy_gradient_loss | 3.15e-05      |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  122\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.9e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 11780         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.04e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 123           |\n",
      "|    policy_gradient_loss | -3.11e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  123\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 148           |\n",
      "|    total_timesteps      | 11875         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.07e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 124           |\n",
      "|    policy_gradient_loss | -8.15e-06     |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  124\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.87e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 151         |\n",
      "|    total_timesteps      | 11970       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.28e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85e+08    |\n",
      "|    n_updates            | 125         |\n",
      "|    policy_gradient_loss | -3.93e-05   |\n",
      "|    value_loss           | 3.69e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  125\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.78e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 12065       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.15e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+08    |\n",
      "|    n_updates            | 126         |\n",
      "|    policy_gradient_loss | -1e-05      |\n",
      "|    value_loss           | 3.69e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  126\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.91e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 12160         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.1448218e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 5.48e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 127           |\n",
      "|    policy_gradient_loss | -4.32e-05     |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  127\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.76e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 12255        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.14e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+08     |\n",
      "|    n_updates            | 128          |\n",
      "|    policy_gradient_loss | 7.84e-06     |\n",
      "|    value_loss           | 3.72e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  128\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 12350         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.3803181e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.22e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 129           |\n",
      "|    policy_gradient_loss | -1.1e-05      |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  129\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.8e+04     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 153         |\n",
      "|    total_timesteps      | 12445       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.12e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+08    |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | 2.53e-05    |\n",
      "|    value_loss           | 3.68e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  130\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 12540         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.04e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 131           |\n",
      "|    policy_gradient_loss | 4.11e-05      |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  131\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.74e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 12635         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.08e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 132           |\n",
      "|    policy_gradient_loss | -8.12e-06     |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  132\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.78e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 12730        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.5e-05      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+08      |\n",
      "|    n_updates            | 133          |\n",
      "|    policy_gradient_loss | -3.8e-05     |\n",
      "|    value_loss           | 3.6e+08      |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  133\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 12825         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.08e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 134           |\n",
      "|    policy_gradient_loss | 4.02e-05      |\n",
      "|    value_loss           | 3.61e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  134\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.72e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 12920        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 8.34e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 135          |\n",
      "|    policy_gradient_loss | -2.14e-05    |\n",
      "|    value_loss           | 3.67e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  135\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 13015         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.11e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+08      |\n",
      "|    n_updates            | 136           |\n",
      "|    policy_gradient_loss | -5.87e-06     |\n",
      "|    value_loss           | 3.58e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  136\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 13110         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.24e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 137           |\n",
      "|    policy_gradient_loss | -1.75e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  137\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.8e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 13205        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.133219e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.47e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 138          |\n",
      "|    policy_gradient_loss | -5.15e-06    |\n",
      "|    value_loss           | 3.68e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  138\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.89e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 13300       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.19e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+08    |\n",
      "|    n_updates            | 139         |\n",
      "|    policy_gradient_loss | -3.91e-05   |\n",
      "|    value_loss           | 3.64e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  139\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "--------------------------------------------\n",
      "| rollout/                |                |\n",
      "|    ep_len_mean          | 95             |\n",
      "|    ep_rew_mean          | 9.89e+04       |\n",
      "| time/                   |                |\n",
      "|    fps                  | 0              |\n",
      "|    iterations           | 1              |\n",
      "|    time_elapsed         | 152            |\n",
      "|    total_timesteps      | 13395          |\n",
      "| train/                  |                |\n",
      "|    approx_kl            | 1.00386774e-08 |\n",
      "|    clip_fraction        | 0              |\n",
      "|    clip_range           | 0.2            |\n",
      "|    entropy_loss         | -4.75e+03      |\n",
      "|    explained_variance   | 1.03e-05       |\n",
      "|    learning_rate        | 0.0003         |\n",
      "|    loss                 | 1.85e+08       |\n",
      "|    n_updates            | 140            |\n",
      "|    policy_gradient_loss | 1.82e-05       |\n",
      "|    value_loss           | 3.69e+08       |\n",
      "--------------------------------------------\n",
      "\n",
      "Learned episode:  140\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.75e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 13490        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 6.08e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 141          |\n",
      "|    policy_gradient_loss | 5.17e-07     |\n",
      "|    value_loss           | 3.68e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  141\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.79e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 13585         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.15e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 142           |\n",
      "|    policy_gradient_loss | 4.54e-06      |\n",
      "|    value_loss           | 3.59e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  142\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 13680         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.38e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 143           |\n",
      "|    policy_gradient_loss | 1.64e-05      |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  143\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 13775         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7567684e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.04e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 144           |\n",
      "|    policy_gradient_loss | -4.7e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  144\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 13870         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1409542e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.51e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 145           |\n",
      "|    policy_gradient_loss | -1.74e-05     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  145\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 13965         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.32e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 146           |\n",
      "|    policy_gradient_loss | -1.88e-05     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  146\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 14060         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5058015e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.25e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 147           |\n",
      "|    policy_gradient_loss | 2.82e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  147\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.79e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 14155         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 6.68e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 148           |\n",
      "|    policy_gradient_loss | -4.07e-05     |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  148\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.8e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 14250        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.631285e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.14e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+08     |\n",
      "|    n_updates            | 149          |\n",
      "|    policy_gradient_loss | -2.19e-06    |\n",
      "|    value_loss           | 3.64e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  149\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 14345         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.29e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 150           |\n",
      "|    policy_gradient_loss | -6.81e-06     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  150\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 14440         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.1e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 151           |\n",
      "|    policy_gradient_loss | -2.23e-06     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  151\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.91e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 14535        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.36e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.86e+08     |\n",
      "|    n_updates            | 152          |\n",
      "|    policy_gradient_loss | -1.27e-05    |\n",
      "|    value_loss           | 3.73e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  152\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.96e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 14630         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.27e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 153           |\n",
      "|    policy_gradient_loss | 2.4e-06       |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  153\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 14725         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.83e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 154           |\n",
      "|    policy_gradient_loss | 1.16e-05      |\n",
      "|    value_loss           | 3.74e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  154\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 14820         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 155           |\n",
      "|    policy_gradient_loss | 1.69e-05      |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  155\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.9e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 14915         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.06e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 156           |\n",
      "|    policy_gradient_loss | 2.92e-06      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  156\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.89e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 15010        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 9.06e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 157          |\n",
      "|    policy_gradient_loss | -2.18e-05    |\n",
      "|    value_loss           | 3.68e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  157\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.81e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 15105         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.43e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 158           |\n",
      "|    policy_gradient_loss | 3.42e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  158\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 15200         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.12e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 159           |\n",
      "|    policy_gradient_loss | 2.98e-05      |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  159\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 15295         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.2e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 160           |\n",
      "|    policy_gradient_loss | -6.39e-07     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  160\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 15390         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.32e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 161           |\n",
      "|    policy_gradient_loss | 1.91e-05      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  161\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 15485         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.4e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 162           |\n",
      "|    policy_gradient_loss | -5.9e-06      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  162\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 15580         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.69e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 163           |\n",
      "|    policy_gradient_loss | 2.75e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  163\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 15675         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.1e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 164           |\n",
      "|    policy_gradient_loss | 9.57e-06      |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  164\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 15770         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.15e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 165           |\n",
      "|    policy_gradient_loss | -1.89e-05     |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  165\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.98e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 15865        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 5.84e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+08     |\n",
      "|    n_updates            | 166          |\n",
      "|    policy_gradient_loss | -1.08e-05    |\n",
      "|    value_loss           | 3.69e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  166\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.79e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 15960         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.17e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 167           |\n",
      "|    policy_gradient_loss | -3.38e-05     |\n",
      "|    value_loss           | 3.75e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  167\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.91e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 16055         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 6.56e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 168           |\n",
      "|    policy_gradient_loss | 1.32e-05      |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  168\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.88e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 16150        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.08e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.85e+08     |\n",
      "|    n_updates            | 169          |\n",
      "|    policy_gradient_loss | 9.32e-06     |\n",
      "|    value_loss           | 3.7e+08      |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  169\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.9e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 16245         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.14e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 170           |\n",
      "|    policy_gradient_loss | 1.96e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  170\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 16340         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.05e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 171           |\n",
      "|    policy_gradient_loss | 1.18e-06      |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  171\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 16435         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.15e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 172           |\n",
      "|    policy_gradient_loss | -6.35e-06     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  172\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 16530         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.5174048e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.17e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 173           |\n",
      "|    policy_gradient_loss | 4.8e-06       |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  173\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.91e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 16625         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.78e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 174           |\n",
      "|    policy_gradient_loss | -1.68e-06     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  174\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 16720         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8899874e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.69e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 175           |\n",
      "|    policy_gradient_loss | 1.71e-05      |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  175\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 16815         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 6.2e-06       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 176           |\n",
      "|    policy_gradient_loss | -1.46e-05     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  176\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.75e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 16910         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.03e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 177           |\n",
      "|    policy_gradient_loss | -1.38e-05     |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  177\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.92e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 17005         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.4328066e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.2e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 178           |\n",
      "|    policy_gradient_loss | 0.000245      |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  178\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 17100         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.89e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 179           |\n",
      "|    policy_gradient_loss | 2.55e-05      |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  179\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 17195         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00023147809 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9e-06         |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 180           |\n",
      "|    policy_gradient_loss | -0.00042      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  180\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 17290         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 6.5e-06       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 181           |\n",
      "|    policy_gradient_loss | 1.27e-05      |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  181\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.84e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 17385        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.513537e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.13e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 182          |\n",
      "|    policy_gradient_loss | 1.67e-05     |\n",
      "|    value_loss           | 3.66e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  182\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 17480         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.07e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 183           |\n",
      "|    policy_gradient_loss | 3.65e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  183\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 17575         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.08e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 184           |\n",
      "|    policy_gradient_loss | -1.72e-05     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  184\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.96e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 150          |\n",
      "|    total_timesteps      | 17670        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 3.011603e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.06e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+08     |\n",
      "|    n_updates            | 185          |\n",
      "|    policy_gradient_loss | 2.9e-05      |\n",
      "|    value_loss           | 3.65e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  185\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 17765         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.58e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 186           |\n",
      "|    policy_gradient_loss | -1.44e-05     |\n",
      "|    value_loss           | 3.73e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  186\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.72e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 17860         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.1e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 187           |\n",
      "|    policy_gradient_loss | 1.85e-05      |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  187\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.72e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 17955         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.95e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 188           |\n",
      "|    policy_gradient_loss | 1.7e-05       |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  188\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.76e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 18050         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.27e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.79e+08      |\n",
      "|    n_updates            | 189           |\n",
      "|    policy_gradient_loss | 5.85e-06      |\n",
      "|    value_loss           | 3.59e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  189\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 18145         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.19e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 190           |\n",
      "|    policy_gradient_loss | 2.28e-06      |\n",
      "|    value_loss           | 3.61e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  190\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 18240         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.11e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 191           |\n",
      "|    policy_gradient_loss | 1.84e-05      |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  191\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.82e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 18335        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.642888e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.13e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 192          |\n",
      "|    policy_gradient_loss | 2.05e-06     |\n",
      "|    value_loss           | 3.65e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  192\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 18430         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.38e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 193           |\n",
      "|    policy_gradient_loss | -4.98e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  193\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 18525         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.6390205e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.03e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 194           |\n",
      "|    policy_gradient_loss | -1.29e-05     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  194\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.91e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 18620         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.36e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 195           |\n",
      "|    policy_gradient_loss | -1.19e-05     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  195\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.87e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 149         |\n",
      "|    total_timesteps      | 18715       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.26e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.85e+08    |\n",
      "|    n_updates            | 196         |\n",
      "|    policy_gradient_loss | -1.61e-05   |\n",
      "|    value_loss           | 3.7e+08     |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  196\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.91e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 18810        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.266438e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.17e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 197          |\n",
      "|    policy_gradient_loss | -4.5e-07     |\n",
      "|    value_loss           | 3.67e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  197\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.93e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 18905       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.29e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+08    |\n",
      "|    n_updates            | 198         |\n",
      "|    policy_gradient_loss | 2.03e-05    |\n",
      "|    value_loss           | 3.69e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  198\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 19000         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.31e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 199           |\n",
      "|    policy_gradient_loss | 6.63e-06      |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  199\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.76e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 19095         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.22e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 200           |\n",
      "|    policy_gradient_loss | 9.2e-06       |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  200\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 19190         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.26e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 201           |\n",
      "|    policy_gradient_loss | -2.07e-05     |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  201\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.76e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 19285         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5058015e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.29e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 202           |\n",
      "|    policy_gradient_loss | 2.85e-05      |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  202\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.88e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 19380        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.266438e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 9.89e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+08      |\n",
      "|    n_updates            | 203          |\n",
      "|    policy_gradient_loss | -1.22e-05    |\n",
      "|    value_loss           | 3.6e+08      |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  203\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.9e+04      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 153          |\n",
      "|    total_timesteps      | 19475        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.391921e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.18e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 204          |\n",
      "|    policy_gradient_loss | 5.38e-06     |\n",
      "|    value_loss           | 3.68e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  204\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.75e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 19570         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.24e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 205           |\n",
      "|    policy_gradient_loss | -2.99e-05     |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  205\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.91e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 19665        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.133219e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 9.95e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.8e+08      |\n",
      "|    n_updates            | 206          |\n",
      "|    policy_gradient_loss | 5.19e-06     |\n",
      "|    value_loss           | 3.6e+08      |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  206\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 19760         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.29e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 207           |\n",
      "|    policy_gradient_loss | 3.96e-05      |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  207\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.81e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 19855         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.56e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 208           |\n",
      "|    policy_gradient_loss | -1.66e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  208\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.77e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 148           |\n",
      "|    total_timesteps      | 19950         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.93e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 209           |\n",
      "|    policy_gradient_loss | 5.63e-05      |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  209\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.85e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 20045         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.64e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 210           |\n",
      "|    policy_gradient_loss | 5e-05         |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  210\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.87e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 154         |\n",
      "|    total_timesteps      | 20140       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 7.27e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.83e+08    |\n",
      "|    n_updates            | 211         |\n",
      "|    policy_gradient_loss | -4.39e-05   |\n",
      "|    value_loss           | 3.66e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  211\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.78e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 20235         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.3e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 212           |\n",
      "|    policy_gradient_loss | -3.79e-06     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  212\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 20330         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.17e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 213           |\n",
      "|    policy_gradient_loss | 1.97e-05      |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  213\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.89e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 20425        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.133219e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 8.23e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 214          |\n",
      "|    policy_gradient_loss | 1.99e-06     |\n",
      "|    value_loss           | 3.65e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  214\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 20520         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8899874e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.35e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 215           |\n",
      "|    policy_gradient_loss | 4.48e-06      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  215\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.92e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 20615        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.391921e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.16e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 216          |\n",
      "|    policy_gradient_loss | 1.65e-06     |\n",
      "|    value_loss           | 3.65e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  216\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 20710         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1409542e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.02e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 217           |\n",
      "|    policy_gradient_loss | 1.57e-06      |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  217\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 20805         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.26e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 218           |\n",
      "|    policy_gradient_loss | -9.54e-08     |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  218\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 20900         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6577397e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.16e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 219           |\n",
      "|    policy_gradient_loss | -0.000342     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  219\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.85e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 149          |\n",
      "|    total_timesteps      | 20995        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.354276e-07 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.05e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+08     |\n",
      "|    n_updates            | 220          |\n",
      "|    policy_gradient_loss | -7.61e-05    |\n",
      "|    value_loss           | 3.64e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  220\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 21090         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.11e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 221           |\n",
      "|    policy_gradient_loss | 3.5e-05       |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  221\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.88e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 21185         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.33e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 222           |\n",
      "|    policy_gradient_loss | 1.34e-05      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  222\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.83e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 152          |\n",
      "|    total_timesteps      | 21280        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.133219e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.14e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 223          |\n",
      "|    policy_gradient_loss | 1.41e-05     |\n",
      "|    value_loss           | 3.69e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  223\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.94e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 21375         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.42e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 224           |\n",
      "|    policy_gradient_loss | -1.62e-05     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  224\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.9e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 21470         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.2587024e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.2e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 225           |\n",
      "|    policy_gradient_loss | -1.06e-05     |\n",
      "|    value_loss           | 3.71e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  225\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 21565         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6351527e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.12e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 226           |\n",
      "|    policy_gradient_loss | 3e-05         |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  226\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.88e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 21660       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.39e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+08    |\n",
      "|    n_updates            | 227         |\n",
      "|    policy_gradient_loss | 1.88e-05    |\n",
      "|    value_loss           | 3.69e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  227\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.72e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 154          |\n",
      "|    total_timesteps      | 21755        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.133219e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.17e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.83e+08     |\n",
      "|    n_updates            | 228          |\n",
      "|    policy_gradient_loss | -2.8e-05     |\n",
      "|    value_loss           | 3.67e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  228\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.95e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 21850         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.7567684e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.28e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 229           |\n",
      "|    policy_gradient_loss | 1.53e-05      |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  229\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.81e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 21945         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.0571982e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.16e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 230           |\n",
      "|    policy_gradient_loss | -0.00032      |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  230\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.8e+04       |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 22040         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.24e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 231           |\n",
      "|    policy_gradient_loss | -1.01e-05     |\n",
      "|    value_loss           | 3.64e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  231\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.85e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 22135         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.0077355e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.13e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 232           |\n",
      "|    policy_gradient_loss | -8.16e-06     |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  232\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 22230         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.66e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 233           |\n",
      "|    policy_gradient_loss | 1.27e-05      |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  233\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.85e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 22325         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.8861196e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.72e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 234           |\n",
      "|    policy_gradient_loss | 2.16e-07      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  234\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.86e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 22420         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.89e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 235           |\n",
      "|    policy_gradient_loss | -6.76e-06     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  235\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 22515         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5058015e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.06e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 236           |\n",
      "|    policy_gradient_loss | 8.4e-06       |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  236\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.72e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 22610         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8899874e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.5e-05       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 237           |\n",
      "|    policy_gradient_loss | -3.62e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  237\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.81e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 22705        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.133219e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 9.54e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.79e+08     |\n",
      "|    n_updates            | 238          |\n",
      "|    policy_gradient_loss | -1.34e-05    |\n",
      "|    value_loss           | 3.58e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  238\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.97e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 22800         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 6.9015904e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.27e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.81e+08      |\n",
      "|    n_updates            | 239           |\n",
      "|    policy_gradient_loss | 1.98e-05      |\n",
      "|    value_loss           | 3.62e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  239\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 152           |\n",
      "|    total_timesteps      | 22895         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.7606362e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 240           |\n",
      "|    policy_gradient_loss | 1.14e-05      |\n",
      "|    value_loss           | 3.73e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  240\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.79e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 152         |\n",
      "|    total_timesteps      | 22990       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 9.83e-06    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.84e+08    |\n",
      "|    n_updates            | 241         |\n",
      "|    policy_gradient_loss | -3.52e-06   |\n",
      "|    value_loss           | 3.69e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  241\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.93e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 151          |\n",
      "|    total_timesteps      | 23085        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.015471e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.38e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.82e+08     |\n",
      "|    n_updates            | 242          |\n",
      "|    policy_gradient_loss | 2.68e-06     |\n",
      "|    value_loss           | 3.63e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  242\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.99e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 23180         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.44e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 243           |\n",
      "|    policy_gradient_loss | -3.73e-05     |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  243\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 149           |\n",
      "|    total_timesteps      | 23275         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.2548346e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.21e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.87e+08      |\n",
      "|    n_updates            | 244           |\n",
      "|    policy_gradient_loss | -3.52e-05     |\n",
      "|    value_loss           | 3.75e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  244\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 161           |\n",
      "|    total_timesteps      | 23370         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 0.00040657268 |\n",
      "|    clip_fraction        | 0.0105        |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 7.33e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 245           |\n",
      "|    policy_gradient_loss | 0.00363       |\n",
      "|    value_loss           | 3.65e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  245\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.75e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 153           |\n",
      "|    total_timesteps      | 23465         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5058015e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.01e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 246           |\n",
      "|    policy_gradient_loss | 2.14e-05      |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  246\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 23560         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.5058015e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.36e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.8e+08       |\n",
      "|    n_updates            | 247           |\n",
      "|    policy_gradient_loss | -2.7e-05      |\n",
      "|    value_loss           | 3.6e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  247\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 151           |\n",
      "|    total_timesteps      | 23655         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8899874e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.06e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 248           |\n",
      "|    policy_gradient_loss | -2.52e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  248\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.83e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 150           |\n",
      "|    total_timesteps      | 23750         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1370867e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.12e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 249           |\n",
      "|    policy_gradient_loss | -1.74e-05     |\n",
      "|    value_loss           | 3.66e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  249\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.79e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 23845         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.8899874e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 8.94e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 250           |\n",
      "|    policy_gradient_loss | 1.73e-05      |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  250\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.93e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 155           |\n",
      "|    total_timesteps      | 23940         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 9.95e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.82e+08      |\n",
      "|    n_updates            | 251           |\n",
      "|    policy_gradient_loss | -1.12e-05     |\n",
      "|    value_loss           | 3.63e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  251\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.82e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 159           |\n",
      "|    total_timesteps      | 24035         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.7645037e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 6.26e-06      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.85e+08      |\n",
      "|    n_updates            | 252           |\n",
      "|    policy_gradient_loss | 1.69e-07      |\n",
      "|    value_loss           | 3.7e+08       |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  252\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 95          |\n",
      "|    ep_rew_mean          | 9.76e+04    |\n",
      "| time/                   |             |\n",
      "|    fps                  | 0           |\n",
      "|    iterations           | 1           |\n",
      "|    time_elapsed         | 161         |\n",
      "|    total_timesteps      | 24130       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 3.26257e-08 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.75e+03   |\n",
      "|    explained_variance   | 1.23e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 1.82e+08    |\n",
      "|    n_updates            | 253         |\n",
      "|    policy_gradient_loss | 2.02e-05    |\n",
      "|    value_loss           | 3.64e+08    |\n",
      "-----------------------------------------\n",
      "\n",
      "Learned episode:  253\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.88e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 157          |\n",
      "|    total_timesteps      | 24225        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 1.631285e-08 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 8.7e-06      |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.81e+08     |\n",
      "|    n_updates            | 254          |\n",
      "|    policy_gradient_loss | 3.4e-06      |\n",
      "|    value_loss           | 3.63e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  254\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 154           |\n",
      "|    total_timesteps      | 24320         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 1.8822519e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.05e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 255           |\n",
      "|    policy_gradient_loss | 1.51e-05      |\n",
      "|    value_loss           | 3.69e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  255\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 95           |\n",
      "|    ep_rew_mean          | 9.94e+04     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 0            |\n",
      "|    iterations           | 1            |\n",
      "|    time_elapsed         | 142          |\n",
      "|    total_timesteps      | 24415        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0007580092 |\n",
      "|    clip_fraction        | 0.0105       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.75e+03    |\n",
      "|    explained_variance   | 1.13e-05     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 1.84e+08     |\n",
      "|    n_updates            | 256          |\n",
      "|    policy_gradient_loss | 0.0066       |\n",
      "|    value_loss           | 3.69e+08     |\n",
      "------------------------------------------\n",
      "\n",
      "Learned episode:  256\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.87e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 140           |\n",
      "|    total_timesteps      | 24510         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.1409542e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.08e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.86e+08      |\n",
      "|    n_updates            | 257           |\n",
      "|    policy_gradient_loss | -3.09e-06     |\n",
      "|    value_loss           | 3.72e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  257\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 140           |\n",
      "|    total_timesteps      | 24605         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.5096693e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.25e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 258           |\n",
      "|    policy_gradient_loss | 3.11e-07      |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  258\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.84e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 141           |\n",
      "|    total_timesteps      | 24700         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 5.0193385e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.22e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 259           |\n",
      "|    policy_gradient_loss | -5.18e-05     |\n",
      "|    value_loss           | 3.68e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  259\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.89e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 24795         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3880536e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 1.19e-05      |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.83e+08      |\n",
      "|    n_updates            | 260           |\n",
      "|    policy_gradient_loss | -2.77e-05     |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  260\n",
      "\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "-------------------------------------------\n",
      "| rollout/                |               |\n",
      "|    ep_len_mean          | 95            |\n",
      "|    ep_rew_mean          | 9.74e+04      |\n",
      "| time/                   |               |\n",
      "|    fps                  | 0             |\n",
      "|    iterations           | 1             |\n",
      "|    time_elapsed         | 139           |\n",
      "|    total_timesteps      | 24890         |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.3841858e-08 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -4.75e+03     |\n",
      "|    explained_variance   | 5.9e-06       |\n",
      "|    learning_rate        | 0.0003        |\n",
      "|    loss                 | 1.84e+08      |\n",
      "|    n_updates            | 261           |\n",
      "|    policy_gradient_loss | 2.9e-05       |\n",
      "|    value_loss           | 3.67e+08      |\n",
      "-------------------------------------------\n",
      "\n",
      "Learned episode:  261\n",
      "\n",
      "Reset environment to timestamp:  672\n"
     ]
    }
   ],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for week_nr in range(start_week, math.ceil((start_week * 7 + nr_iterations) / 7)):\n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "        \n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = count * 96 + week_nr*7*96\n",
    "        \n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "            \n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "        \n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "        \n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "    \n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "        \n",
    "        # reset environment at beginnning of simulation\n",
    "        if count == 0:\n",
    "            \n",
    "            # create environment\n",
    "            env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 5000, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 234)\n",
    "            \n",
    "            # create RL model\n",
    "            model = PPO(\"MlpPolicy\",env, verbose=2, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "            model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 1024),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1024, 5120),\n",
    "                model.policy.mlp_extractor.policy_net[3]\n",
    "            )\n",
    "            model.policy.action_net =  nn.Linear(5120, 13260)\n",
    "            model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 1028),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1028, 128),\n",
    "                model.policy.mlp_extractor.value_net[3]\n",
    "            )\n",
    "            model.policy.value_net =  nn.Linear(128, 1)\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"stdout\", \"csv\", \"tensorboard\"])\n",
    "            model.set_logger(new_logger)\n",
    "            \n",
    "            #model.policy.to(device)\n",
    "            \n",
    "            #r = validation(model)\n",
    "            #print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            #reward_list.append(r)\n",
    "            #count_list.append(count)\n",
    "            \n",
    "        else: \n",
    "            #env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "            #              electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "            #              planned_durations = planned_durations_day)\n",
    "            s = env.reset()\n",
    "            \n",
    "        \n",
    "        # learn one episode\n",
    "        model.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "            \n",
    "          \n",
    "        print(\"\")\n",
    "        print(\"Learned episode: \",count)\n",
    "        print(\"\")\n",
    "        \n",
    "        #if count in range(5,nr_iterations + 1,10):\n",
    "        #    r = validation(model)\n",
    "        #    print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "        #    reward_list.append(r)\n",
    "        #    count_list.append(count)\n",
    "\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3541b2-3be5-4b3f-a9d7-55e5ed210aa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reset environment to timestamp:  672\n",
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  331457.958398849  CHF   Episodes learned:  0\n",
      "Reset environment to timestamp:  672\n",
      "Reset environment to timestamp:  672\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.02e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 95       |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  0\n",
      "\n",
      "Reset environment to timestamp:  768\n",
      "Reset environment to timestamp:  768\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.06e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 190      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  1\n",
      "\n",
      "Reset environment to timestamp:  864\n",
      "Reset environment to timestamp:  864\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.06e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 285      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  2\n",
      "\n",
      "Reset environment to timestamp:  960\n",
      "Reset environment to timestamp:  960\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.12e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 380      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  3\n",
      "\n",
      "Reset environment to timestamp:  1056\n",
      "Reset environment to timestamp:  1056\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.27e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 475      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  4\n",
      "\n",
      "Reset environment to timestamp:  1152\n",
      "Reset environment to timestamp:  1152\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.24e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 570      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  5\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  333213.66152857494  CHF   Episodes learned:  5\n",
      "Reset environment to timestamp:  1248\n",
      "Reset environment to timestamp:  1248\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.22e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 665      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  6\n",
      "\n",
      "Reset environment to timestamp:  2016\n",
      "Reset environment to timestamp:  2016\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.21e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 760      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  7\n",
      "\n",
      "Reset environment to timestamp:  2112\n",
      "Reset environment to timestamp:  2112\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.22e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 855      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  8\n",
      "\n",
      "Reset environment to timestamp:  2208\n",
      "Reset environment to timestamp:  2208\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.22e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 950      |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  9\n",
      "\n",
      "Reset environment to timestamp:  2304\n",
      "Reset environment to timestamp:  2304\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.24e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 1045     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  10\n",
      "\n",
      "Reset environment to timestamp:  2400\n",
      "Reset environment to timestamp:  2400\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.29e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 1140     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  11\n",
      "\n",
      "Reset environment to timestamp:  2496\n",
      "Reset environment to timestamp:  2496\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.28e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 1235     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  12\n",
      "\n",
      "Reset environment to timestamp:  2592\n",
      "Reset environment to timestamp:  2592\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.27e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 1330     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  13\n",
      "\n",
      "Reset environment to timestamp:  3360\n",
      "Reset environment to timestamp:  3360\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.27e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 1425     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  14\n",
      "\n",
      "Reset environment to timestamp:  3456\n",
      "Reset environment to timestamp:  3456\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.27e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 1520     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  15\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  342259.16153818805  CHF   Episodes learned:  15\n",
      "Reset environment to timestamp:  3552\n",
      "Reset environment to timestamp:  3552\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.27e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 1615     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  16\n",
      "\n",
      "Reset environment to timestamp:  3648\n",
      "Reset environment to timestamp:  3648\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.28e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 1710     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  17\n",
      "\n",
      "Reset environment to timestamp:  3744\n",
      "Reset environment to timestamp:  3744\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.31e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 1805     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  18\n",
      "\n",
      "Reset environment to timestamp:  3840\n",
      "Reset environment to timestamp:  3840\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.31e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 1900     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  19\n",
      "\n",
      "Reset environment to timestamp:  3936\n",
      "Reset environment to timestamp:  3936\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 1995     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  20\n",
      "\n",
      "Reset environment to timestamp:  4704\n",
      "Reset environment to timestamp:  4704\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.29e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 2090     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  21\n",
      "\n",
      "Reset environment to timestamp:  4800\n",
      "Reset environment to timestamp:  4800\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.29e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 2185     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  22\n",
      "\n",
      "Reset environment to timestamp:  4896\n",
      "Reset environment to timestamp:  4896\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.29e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 2280     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  23\n",
      "\n",
      "Reset environment to timestamp:  4992\n",
      "Reset environment to timestamp:  4992\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.29e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 2375     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  24\n",
      "\n",
      "Reset environment to timestamp:  5088\n",
      "Reset environment to timestamp:  5088\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 2470     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  25\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  321347.93100094766  CHF   Episodes learned:  25\n",
      "Reset environment to timestamp:  5184\n",
      "Reset environment to timestamp:  5184\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.31e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 2565     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  26\n",
      "\n",
      "Reset environment to timestamp:  5280\n",
      "Reset environment to timestamp:  5280\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 2660     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  27\n",
      "\n",
      "Reset environment to timestamp:  6048\n",
      "Reset environment to timestamp:  6048\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 2755     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  28\n",
      "\n",
      "Reset environment to timestamp:  6144\n",
      "Reset environment to timestamp:  6144\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 2850     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  29\n",
      "\n",
      "Reset environment to timestamp:  6240\n",
      "Reset environment to timestamp:  6240\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 2945     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  30\n",
      "\n",
      "Reset environment to timestamp:  6336\n",
      "Reset environment to timestamp:  6336\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 3040     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  31\n",
      "\n",
      "Reset environment to timestamp:  6432\n",
      "Reset environment to timestamp:  6432\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 3135     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  32\n",
      "\n",
      "Reset environment to timestamp:  6528\n",
      "Reset environment to timestamp:  6528\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.31e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 3230     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  33\n",
      "\n",
      "Reset environment to timestamp:  6624\n",
      "Reset environment to timestamp:  6624\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.31e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 3325     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  34\n",
      "\n",
      "Reset environment to timestamp:  7392\n",
      "Reset environment to timestamp:  7392\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 3420     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  35\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  351196.89783302264  CHF   Episodes learned:  35\n",
      "Reset environment to timestamp:  7488\n",
      "Reset environment to timestamp:  7488\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 3515     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  36\n",
      "\n",
      "Reset environment to timestamp:  7584\n",
      "Reset environment to timestamp:  7584\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.3e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 3610     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  37\n",
      "\n",
      "Reset environment to timestamp:  7680\n",
      "Reset environment to timestamp:  7680\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.31e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 3705     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  38\n",
      "\n",
      "Reset environment to timestamp:  7776\n",
      "Reset environment to timestamp:  7776\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 3800     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  39\n",
      "\n",
      "Reset environment to timestamp:  7872\n",
      "Reset environment to timestamp:  7872\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 3895     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  40\n",
      "\n",
      "Reset environment to timestamp:  7968\n",
      "Reset environment to timestamp:  7968\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 3990     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  41\n",
      "\n",
      "Reset environment to timestamp:  8736\n",
      "Reset environment to timestamp:  8736\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 4085     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  42\n",
      "\n",
      "Reset environment to timestamp:  8832\n",
      "Reset environment to timestamp:  8832\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 4180     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  43\n",
      "\n",
      "Reset environment to timestamp:  8928\n",
      "Reset environment to timestamp:  8928\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 4275     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  44\n",
      "\n",
      "Reset environment to timestamp:  9024\n",
      "Reset environment to timestamp:  9024\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.32e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 4370     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  45\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  335138.23878237704  CHF   Episodes learned:  45\n",
      "Reset environment to timestamp:  9120\n",
      "Reset environment to timestamp:  9120\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 4465     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  46\n",
      "\n",
      "Reset environment to timestamp:  9216\n",
      "Reset environment to timestamp:  9216\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 4560     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  47\n",
      "\n",
      "Reset environment to timestamp:  9312\n",
      "Reset environment to timestamp:  9312\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 4655     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  48\n",
      "\n",
      "Reset environment to timestamp:  10080\n",
      "Reset environment to timestamp:  10080\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 4750     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  49\n",
      "\n",
      "Reset environment to timestamp:  10176\n",
      "Reset environment to timestamp:  10176\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 4845     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  50\n",
      "\n",
      "Reset environment to timestamp:  10272\n",
      "Reset environment to timestamp:  10272\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 4940     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  51\n",
      "\n",
      "Reset environment to timestamp:  10368\n",
      "Reset environment to timestamp:  10368\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 5035     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  52\n",
      "\n",
      "Reset environment to timestamp:  10464\n",
      "Reset environment to timestamp:  10464\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.34e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 5130     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  53\n",
      "\n",
      "Reset environment to timestamp:  10560\n",
      "Reset environment to timestamp:  10560\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.34e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 5225     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  54\n",
      "\n",
      "Reset environment to timestamp:  10656\n",
      "Reset environment to timestamp:  10656\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 5320     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  55\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  310491.02597915544  CHF   Episodes learned:  55\n",
      "Reset environment to timestamp:  11424\n",
      "Reset environment to timestamp:  11424\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 5415     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  56\n",
      "\n",
      "Reset environment to timestamp:  11520\n",
      "Reset environment to timestamp:  11520\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 5510     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  57\n",
      "\n",
      "Reset environment to timestamp:  11616\n",
      "Reset environment to timestamp:  11616\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 5605     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  58\n",
      "\n",
      "Reset environment to timestamp:  11712\n",
      "Reset environment to timestamp:  11712\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 5700     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  59\n",
      "\n",
      "Reset environment to timestamp:  11808\n",
      "Reset environment to timestamp:  11808\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 5795     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  60\n",
      "\n",
      "Reset environment to timestamp:  11904\n",
      "Reset environment to timestamp:  11904\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 5890     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  61\n",
      "\n",
      "Reset environment to timestamp:  12000\n",
      "Reset environment to timestamp:  12000\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 5985     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  62\n",
      "\n",
      "Reset environment to timestamp:  12768\n",
      "Reset environment to timestamp:  12768\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 6080     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  63\n",
      "\n",
      "Reset environment to timestamp:  12864\n",
      "Reset environment to timestamp:  12864\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 6175     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  64\n",
      "\n",
      "Reset environment to timestamp:  12960\n",
      "Reset environment to timestamp:  12960\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 6270     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  65\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  332053.2547339384  CHF   Episodes learned:  65\n",
      "Reset environment to timestamp:  13056\n",
      "Reset environment to timestamp:  13056\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 6365     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  66\n",
      "\n",
      "Reset environment to timestamp:  13152\n",
      "Reset environment to timestamp:  13152\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.34e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 6460     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  67\n",
      "\n",
      "Reset environment to timestamp:  13248\n",
      "Reset environment to timestamp:  13248\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.34e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 6555     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  68\n",
      "\n",
      "Reset environment to timestamp:  13344\n",
      "Reset environment to timestamp:  13344\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 6650     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  69\n",
      "\n",
      "Reset environment to timestamp:  14112\n",
      "Reset environment to timestamp:  14112\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.33e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 6745     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  70\n",
      "\n",
      "Reset environment to timestamp:  14208\n",
      "Reset environment to timestamp:  14208\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.34e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 6840     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  71\n",
      "\n",
      "Reset environment to timestamp:  14304\n",
      "Reset environment to timestamp:  14304\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.34e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 6935     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  72\n",
      "\n",
      "Reset environment to timestamp:  14400\n",
      "Reset environment to timestamp:  14400\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.34e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 7030     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  73\n",
      "\n",
      "Reset environment to timestamp:  14496\n",
      "Reset environment to timestamp:  14496\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.35e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 7125     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  74\n",
      "\n",
      "Reset environment to timestamp:  14592\n",
      "Reset environment to timestamp:  14592\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.35e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 7220     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  75\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  331867.4023633522  CHF   Episodes learned:  75\n",
      "Reset environment to timestamp:  14688\n",
      "Reset environment to timestamp:  14688\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.35e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 7315     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  76\n",
      "\n",
      "Reset environment to timestamp:  15456\n",
      "Reset environment to timestamp:  15456\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.35e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 7410     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  77\n",
      "\n",
      "Reset environment to timestamp:  15552\n",
      "Reset environment to timestamp:  15552\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.35e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 7505     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  78\n",
      "\n",
      "Reset environment to timestamp:  15648\n",
      "Reset environment to timestamp:  15648\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.35e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 7600     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  79\n",
      "\n",
      "Reset environment to timestamp:  15744\n",
      "Reset environment to timestamp:  15744\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.35e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 7695     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  80\n",
      "\n",
      "Reset environment to timestamp:  15840\n",
      "Reset environment to timestamp:  15840\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 7790     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  81\n",
      "\n",
      "Reset environment to timestamp:  15936\n",
      "Reset environment to timestamp:  15936\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 7885     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  82\n",
      "\n",
      "Reset environment to timestamp:  16032\n",
      "Reset environment to timestamp:  16032\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 7980     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  83\n",
      "\n",
      "Reset environment to timestamp:  16800\n",
      "Reset environment to timestamp:  16800\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8075     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  84\n",
      "\n",
      "Reset environment to timestamp:  16896\n",
      "Reset environment to timestamp:  16896\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8170     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  85\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  333470.6752451888  CHF   Episodes learned:  85\n",
      "Reset environment to timestamp:  16992\n",
      "Reset environment to timestamp:  16992\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8265     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  86\n",
      "\n",
      "Reset environment to timestamp:  17088\n",
      "Reset environment to timestamp:  17088\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8360     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  87\n",
      "\n",
      "Reset environment to timestamp:  17184\n",
      "Reset environment to timestamp:  17184\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8455     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  88\n",
      "\n",
      "Reset environment to timestamp:  17280\n",
      "Reset environment to timestamp:  17280\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 8550     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  89\n",
      "\n",
      "Reset environment to timestamp:  17376\n",
      "Reset environment to timestamp:  17376\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8645     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  90\n",
      "\n",
      "Reset environment to timestamp:  18144\n",
      "Reset environment to timestamp:  18144\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8740     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  91\n",
      "\n",
      "Reset environment to timestamp:  18240\n",
      "Reset environment to timestamp:  18240\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.36e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8835     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  92\n",
      "\n",
      "Reset environment to timestamp:  18336\n",
      "Reset environment to timestamp:  18336\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 8930     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  93\n",
      "\n",
      "Reset environment to timestamp:  18432\n",
      "Reset environment to timestamp:  18432\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 9025     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  94\n",
      "\n",
      "Reset environment to timestamp:  18528\n",
      "Reset environment to timestamp:  18528\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 9120     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  95\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  322451.91620801814  CHF   Episodes learned:  95\n",
      "Reset environment to timestamp:  18624\n",
      "Reset environment to timestamp:  18624\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 9215     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  96\n",
      "\n",
      "Reset environment to timestamp:  18720\n",
      "Reset environment to timestamp:  18720\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 9310     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  97\n",
      "\n",
      "Reset environment to timestamp:  19488\n",
      "Reset environment to timestamp:  19488\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 9405     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  98\n",
      "\n",
      "Reset environment to timestamp:  19584\n",
      "Reset environment to timestamp:  19584\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 9500     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  99\n",
      "\n",
      "Reset environment to timestamp:  19680\n",
      "Reset environment to timestamp:  19680\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 9595     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  100\n",
      "\n",
      "Reset environment to timestamp:  19776\n",
      "Reset environment to timestamp:  19776\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 9690     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  101\n",
      "\n",
      "Reset environment to timestamp:  19872\n",
      "Reset environment to timestamp:  19872\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 9785     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  102\n",
      "\n",
      "Reset environment to timestamp:  19968\n",
      "Reset environment to timestamp:  19968\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 9880     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  103\n",
      "\n",
      "Reset environment to timestamp:  20064\n",
      "Reset environment to timestamp:  20064\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 9975     |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  104\n",
      "\n",
      "Reset environment to timestamp:  20832\n",
      "Reset environment to timestamp:  20832\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 10070    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  105\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  331123.0074862072  CHF   Episodes learned:  105\n",
      "Reset environment to timestamp:  20928\n",
      "Reset environment to timestamp:  20928\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 10165    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  106\n",
      "\n",
      "Reset environment to timestamp:  21024\n",
      "Reset environment to timestamp:  21024\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10260    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  107\n",
      "\n",
      "Reset environment to timestamp:  21120\n",
      "Reset environment to timestamp:  21120\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10355    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  108\n",
      "\n",
      "Reset environment to timestamp:  21216\n",
      "Reset environment to timestamp:  21216\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10450    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  109\n",
      "\n",
      "Reset environment to timestamp:  21312\n",
      "Reset environment to timestamp:  21312\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10545    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  110\n",
      "\n",
      "Reset environment to timestamp:  21408\n",
      "Reset environment to timestamp:  21408\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 10640    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  111\n",
      "\n",
      "Reset environment to timestamp:  22176\n",
      "Reset environment to timestamp:  22176\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10735    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  112\n",
      "\n",
      "Reset environment to timestamp:  22272\n",
      "Reset environment to timestamp:  22272\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10830    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  113\n",
      "\n",
      "Reset environment to timestamp:  22368\n",
      "Reset environment to timestamp:  22368\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 10925    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  114\n",
      "\n",
      "Reset environment to timestamp:  22464\n",
      "Reset environment to timestamp:  22464\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 11020    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  115\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  329390.1212720502  CHF   Episodes learned:  115\n",
      "Reset environment to timestamp:  22560\n",
      "Reset environment to timestamp:  22560\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 11115    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  116\n",
      "\n",
      "Reset environment to timestamp:  22656\n",
      "Reset environment to timestamp:  22656\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 11210    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  117\n",
      "\n",
      "Reset environment to timestamp:  22752\n",
      "Reset environment to timestamp:  22752\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 11305    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  118\n",
      "\n",
      "Reset environment to timestamp:  23520\n",
      "Reset environment to timestamp:  23520\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 11400    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  119\n",
      "\n",
      "Reset environment to timestamp:  23616\n",
      "Reset environment to timestamp:  23616\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 11495    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  120\n",
      "\n",
      "Reset environment to timestamp:  23712\n",
      "Reset environment to timestamp:  23712\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 11590    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  121\n",
      "\n",
      "Reset environment to timestamp:  23808\n",
      "Reset environment to timestamp:  23808\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 11685    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  122\n",
      "\n",
      "Reset environment to timestamp:  23904\n",
      "Reset environment to timestamp:  23904\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 11780    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  123\n",
      "\n",
      "Reset environment to timestamp:  24000\n",
      "Reset environment to timestamp:  24000\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 11875    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  124\n",
      "\n",
      "Reset environment to timestamp:  24096\n",
      "Reset environment to timestamp:  24096\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 11970    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  125\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  332033.9811118273  CHF   Episodes learned:  125\n",
      "Reset environment to timestamp:  24864\n",
      "Reset environment to timestamp:  24864\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 12065    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  126\n",
      "\n",
      "Reset environment to timestamp:  24960\n",
      "Reset environment to timestamp:  24960\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 12160    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  127\n",
      "\n",
      "Reset environment to timestamp:  25056\n",
      "Reset environment to timestamp:  25056\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 12255    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  128\n",
      "\n",
      "Reset environment to timestamp:  25152\n",
      "Reset environment to timestamp:  25152\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 12350    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  129\n",
      "\n",
      "Reset environment to timestamp:  25248\n",
      "Reset environment to timestamp:  25248\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 12445    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  130\n",
      "\n",
      "Reset environment to timestamp:  25344\n",
      "Reset environment to timestamp:  25344\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 12540    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  131\n",
      "\n",
      "Reset environment to timestamp:  25440\n",
      "Reset environment to timestamp:  25440\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 12635    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  132\n",
      "\n",
      "Reset environment to timestamp:  26208\n",
      "Reset environment to timestamp:  26208\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 12730    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  133\n",
      "\n",
      "Reset environment to timestamp:  26304\n",
      "Reset environment to timestamp:  26304\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 12825    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  134\n",
      "\n",
      "Reset environment to timestamp:  26400\n",
      "Reset environment to timestamp:  26400\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 12920    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  135\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  340328.04977807886  CHF   Episodes learned:  135\n",
      "Reset environment to timestamp:  26496\n",
      "Reset environment to timestamp:  26496\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 13015    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  136\n",
      "\n",
      "Reset environment to timestamp:  26592\n",
      "Reset environment to timestamp:  26592\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 13110    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  137\n",
      "\n",
      "Reset environment to timestamp:  26688\n",
      "Reset environment to timestamp:  26688\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 13205    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  138\n",
      "\n",
      "Reset environment to timestamp:  26784\n",
      "Reset environment to timestamp:  26784\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 13300    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  139\n",
      "\n",
      "Reset environment to timestamp:  27552\n",
      "Reset environment to timestamp:  27552\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 13395    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  140\n",
      "\n",
      "Reset environment to timestamp:  27648\n",
      "Reset environment to timestamp:  27648\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 13490    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  141\n",
      "\n",
      "Reset environment to timestamp:  27744\n",
      "Reset environment to timestamp:  27744\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 13585    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  142\n",
      "\n",
      "Reset environment to timestamp:  27840\n",
      "Reset environment to timestamp:  27840\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 13680    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  143\n",
      "\n",
      "Reset environment to timestamp:  27936\n",
      "Reset environment to timestamp:  27936\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 13775    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  144\n",
      "\n",
      "Reset environment to timestamp:  28032\n",
      "Reset environment to timestamp:  28032\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 13870    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  145\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  342065.72626798676  CHF   Episodes learned:  145\n",
      "Reset environment to timestamp:  28128\n",
      "Reset environment to timestamp:  28128\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 13965    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  146\n",
      "\n",
      "Reset environment to timestamp:  28896\n",
      "Reset environment to timestamp:  28896\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 14060    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  147\n",
      "\n",
      "Reset environment to timestamp:  28992\n",
      "Reset environment to timestamp:  28992\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 14155    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  148\n",
      "\n",
      "Reset environment to timestamp:  29088\n",
      "Reset environment to timestamp:  29088\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 14250    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  149\n",
      "\n",
      "Reset environment to timestamp:  29184\n",
      "Reset environment to timestamp:  29184\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 14345    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  150\n",
      "\n",
      "Reset environment to timestamp:  29280\n",
      "Reset environment to timestamp:  29280\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 14440    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  151\n",
      "\n",
      "Reset environment to timestamp:  29376\n",
      "Reset environment to timestamp:  29376\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 14535    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  152\n",
      "\n",
      "Reset environment to timestamp:  29472\n",
      "Reset environment to timestamp:  29472\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 14630    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  153\n",
      "\n",
      "Reset environment to timestamp:  30240\n",
      "Reset environment to timestamp:  30240\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 14725    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  154\n",
      "\n",
      "Reset environment to timestamp:  30336\n",
      "Reset environment to timestamp:  30336\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 14820    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  155\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  331621.8694241181  CHF   Episodes learned:  155\n",
      "Reset environment to timestamp:  30432\n",
      "Reset environment to timestamp:  30432\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 14915    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  156\n",
      "\n",
      "Reset environment to timestamp:  30528\n",
      "Reset environment to timestamp:  30528\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 15010    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  157\n",
      "\n",
      "Reset environment to timestamp:  30624\n",
      "Reset environment to timestamp:  30624\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 15105    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  158\n",
      "\n",
      "Reset environment to timestamp:  30720\n",
      "Reset environment to timestamp:  30720\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 15200    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  159\n",
      "\n",
      "Reset environment to timestamp:  30816\n",
      "Reset environment to timestamp:  30816\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 15295    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  160\n",
      "\n",
      "Reset environment to timestamp:  31584\n",
      "Reset environment to timestamp:  31584\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 15390    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  161\n",
      "\n",
      "Reset environment to timestamp:  31680\n",
      "Reset environment to timestamp:  31680\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 15485    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  162\n",
      "\n",
      "Reset environment to timestamp:  31776\n",
      "Reset environment to timestamp:  31776\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 15580    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  163\n",
      "\n",
      "Reset environment to timestamp:  31872\n",
      "Reset environment to timestamp:  31872\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 15675    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  164\n",
      "\n",
      "Reset environment to timestamp:  31968\n",
      "Reset environment to timestamp:  31968\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 15770    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  165\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  330613.4614653821  CHF   Episodes learned:  165\n",
      "Reset environment to timestamp:  32064\n",
      "Reset environment to timestamp:  32064\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 15865    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  166\n",
      "\n",
      "Reset environment to timestamp:  32160\n",
      "Reset environment to timestamp:  32160\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 15960    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  167\n",
      "\n",
      "Reset environment to timestamp:  32928\n",
      "Reset environment to timestamp:  32928\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 16055    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  168\n",
      "\n",
      "Reset environment to timestamp:  33024\n",
      "Reset environment to timestamp:  33024\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 16150    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  169\n",
      "\n",
      "Reset environment to timestamp:  33120\n",
      "Reset environment to timestamp:  33120\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 16245    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  170\n",
      "\n",
      "Reset environment to timestamp:  33216\n",
      "Reset environment to timestamp:  33216\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 16340    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  171\n",
      "\n",
      "Reset environment to timestamp:  33312\n",
      "Reset environment to timestamp:  33312\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 16435    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  172\n",
      "\n",
      "Reset environment to timestamp:  33408\n",
      "Reset environment to timestamp:  33408\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 16530    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  173\n",
      "\n",
      "Reset environment to timestamp:  33504\n",
      "Reset environment to timestamp:  33504\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 16625    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  174\n",
      "\n",
      "Reset environment to timestamp:  34272\n",
      "Reset environment to timestamp:  34272\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 16720    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  175\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  332221.63718310755  CHF   Episodes learned:  175\n",
      "Reset environment to timestamp:  34368\n",
      "Reset environment to timestamp:  34368\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 16815    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  176\n",
      "\n",
      "Reset environment to timestamp:  34464\n",
      "Reset environment to timestamp:  34464\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 16910    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  177\n",
      "\n",
      "Reset environment to timestamp:  34560\n",
      "Reset environment to timestamp:  34560\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 17005    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  178\n",
      "\n",
      "Reset environment to timestamp:  34656\n",
      "Reset environment to timestamp:  34656\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.48e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 17100    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  179\n",
      "\n",
      "Reset environment to timestamp:  34752\n",
      "Reset environment to timestamp:  34752\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 17195    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  180\n",
      "\n",
      "Reset environment to timestamp:  34848\n",
      "Reset environment to timestamp:  34848\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 17290    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  181\n",
      "\n",
      "Reset environment to timestamp:  35616\n",
      "Reset environment to timestamp:  35616\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 17385    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  182\n",
      "\n",
      "Reset environment to timestamp:  35712\n",
      "Reset environment to timestamp:  35712\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 17480    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  183\n",
      "\n",
      "Reset environment to timestamp:  35808\n",
      "Reset environment to timestamp:  35808\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 17575    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  184\n",
      "\n",
      "Reset environment to timestamp:  35904\n",
      "Reset environment to timestamp:  35904\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 17670    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  185\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  339733.1589478893  CHF   Episodes learned:  185\n",
      "Reset environment to timestamp:  36000\n",
      "Reset environment to timestamp:  36000\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 17765    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  186\n",
      "\n",
      "Reset environment to timestamp:  36096\n",
      "Reset environment to timestamp:  36096\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 17860    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  187\n",
      "\n",
      "Reset environment to timestamp:  36192\n",
      "Reset environment to timestamp:  36192\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 17955    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  188\n",
      "\n",
      "Reset environment to timestamp:  36960\n",
      "Reset environment to timestamp:  36960\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18050    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  189\n",
      "\n",
      "Reset environment to timestamp:  37056\n",
      "Reset environment to timestamp:  37056\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18145    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  190\n",
      "\n",
      "Reset environment to timestamp:  37152\n",
      "Reset environment to timestamp:  37152\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18240    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  191\n",
      "\n",
      "Reset environment to timestamp:  37248\n",
      "Reset environment to timestamp:  37248\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18335    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  192\n",
      "\n",
      "Reset environment to timestamp:  37344\n",
      "Reset environment to timestamp:  37344\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18430    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  193\n",
      "\n",
      "Reset environment to timestamp:  37440\n",
      "Reset environment to timestamp:  37440\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.47e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 18525    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  194\n",
      "\n",
      "Reset environment to timestamp:  37536\n",
      "Reset environment to timestamp:  37536\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18620    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  195\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  322099.56183076836  CHF   Episodes learned:  195\n",
      "Reset environment to timestamp:  38304\n",
      "Reset environment to timestamp:  38304\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 18715    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  196\n",
      "\n",
      "Reset environment to timestamp:  38400\n",
      "Reset environment to timestamp:  38400\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18810    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  197\n",
      "\n",
      "Reset environment to timestamp:  38496\n",
      "Reset environment to timestamp:  38496\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 18905    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  198\n",
      "\n",
      "Reset environment to timestamp:  38592\n",
      "Reset environment to timestamp:  38592\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 19000    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  199\n",
      "\n",
      "Reset environment to timestamp:  38688\n",
      "Reset environment to timestamp:  38688\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.46e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 19095    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  200\n",
      "\n",
      "Reset environment to timestamp:  38784\n",
      "Reset environment to timestamp:  38784\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 19190    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  201\n",
      "\n",
      "Reset environment to timestamp:  38880\n",
      "Reset environment to timestamp:  38880\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 19285    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  202\n",
      "\n",
      "Reset environment to timestamp:  39648\n",
      "Reset environment to timestamp:  39648\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 19380    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  203\n",
      "\n",
      "Reset environment to timestamp:  39744\n",
      "Reset environment to timestamp:  39744\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 19475    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  204\n",
      "\n",
      "Reset environment to timestamp:  39840\n",
      "Reset environment to timestamp:  39840\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 19570    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  205\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  318899.1481081334  CHF   Episodes learned:  205\n",
      "Reset environment to timestamp:  39936\n",
      "Reset environment to timestamp:  39936\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 19665    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  206\n",
      "\n",
      "Reset environment to timestamp:  40032\n",
      "Reset environment to timestamp:  40032\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 19760    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  207\n",
      "\n",
      "Reset environment to timestamp:  40128\n",
      "Reset environment to timestamp:  40128\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 19855    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  208\n",
      "\n",
      "Reset environment to timestamp:  40224\n",
      "Reset environment to timestamp:  40224\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 19950    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  209\n",
      "\n",
      "Reset environment to timestamp:  40992\n",
      "Reset environment to timestamp:  40992\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20045    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  210\n",
      "\n",
      "Reset environment to timestamp:  41088\n",
      "Reset environment to timestamp:  41088\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20140    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  211\n",
      "\n",
      "Reset environment to timestamp:  41184\n",
      "Reset environment to timestamp:  41184\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20235    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  212\n",
      "\n",
      "Reset environment to timestamp:  41280\n",
      "Reset environment to timestamp:  41280\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 20330    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  213\n",
      "\n",
      "Reset environment to timestamp:  41376\n",
      "Reset environment to timestamp:  41376\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20425    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  214\n",
      "\n",
      "Reset environment to timestamp:  41472\n",
      "Reset environment to timestamp:  41472\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20520    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  215\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  332278.4831374667  CHF   Episodes learned:  215\n",
      "Reset environment to timestamp:  41568\n",
      "Reset environment to timestamp:  41568\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20615    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  216\n",
      "\n",
      "Reset environment to timestamp:  42336\n",
      "Reset environment to timestamp:  42336\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20710    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  217\n",
      "\n",
      "Reset environment to timestamp:  42432\n",
      "Reset environment to timestamp:  42432\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20805    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  218\n",
      "\n",
      "Reset environment to timestamp:  42528\n",
      "Reset environment to timestamp:  42528\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 20900    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  219\n",
      "\n",
      "Reset environment to timestamp:  42624\n",
      "Reset environment to timestamp:  42624\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 20995    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  220\n",
      "\n",
      "Reset environment to timestamp:  42720\n",
      "Reset environment to timestamp:  42720\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 21090    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  221\n",
      "\n",
      "Reset environment to timestamp:  42816\n",
      "Reset environment to timestamp:  42816\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 21185    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  222\n",
      "\n",
      "Reset environment to timestamp:  42912\n",
      "Reset environment to timestamp:  42912\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 21280    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  223\n",
      "\n",
      "Reset environment to timestamp:  43680\n",
      "Reset environment to timestamp:  43680\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 21375    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  224\n",
      "\n",
      "Reset environment to timestamp:  43776\n",
      "Reset environment to timestamp:  43776\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 21470    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  225\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  331025.96620746  CHF   Episodes learned:  225\n",
      "Reset environment to timestamp:  43872\n",
      "Reset environment to timestamp:  43872\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 21565    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  226\n",
      "\n",
      "Reset environment to timestamp:  43968\n",
      "Reset environment to timestamp:  43968\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 21660    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  227\n",
      "\n",
      "Reset environment to timestamp:  44064\n",
      "Reset environment to timestamp:  44064\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 21755    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  228\n",
      "\n",
      "Reset environment to timestamp:  44160\n",
      "Reset environment to timestamp:  44160\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 21850    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  229\n",
      "\n",
      "Reset environment to timestamp:  44256\n",
      "Reset environment to timestamp:  44256\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 21945    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  230\n",
      "\n",
      "Reset environment to timestamp:  45024\n",
      "Reset environment to timestamp:  45024\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 22040    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  231\n",
      "\n",
      "Reset environment to timestamp:  45120\n",
      "Reset environment to timestamp:  45120\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 22135    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  232\n",
      "\n",
      "Reset environment to timestamp:  45216\n",
      "Reset environment to timestamp:  45216\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 22230    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  233\n",
      "\n",
      "Reset environment to timestamp:  45312\n",
      "Reset environment to timestamp:  45312\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 22325    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  234\n",
      "\n",
      "Reset environment to timestamp:  45408\n",
      "Reset environment to timestamp:  45408\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 22420    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  235\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  339901.34597519133  CHF   Episodes learned:  235\n",
      "Reset environment to timestamp:  45504\n",
      "Reset environment to timestamp:  45504\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.45e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 22515    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  236\n",
      "\n",
      "Reset environment to timestamp:  45600\n",
      "Reset environment to timestamp:  45600\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 22610    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  237\n",
      "\n",
      "Reset environment to timestamp:  46368\n",
      "Reset environment to timestamp:  46368\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 22705    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  238\n",
      "\n",
      "Reset environment to timestamp:  46464\n",
      "Reset environment to timestamp:  46464\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 22800    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  239\n",
      "\n",
      "Reset environment to timestamp:  46560\n",
      "Reset environment to timestamp:  46560\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 22895    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  240\n",
      "\n",
      "Reset environment to timestamp:  46656\n",
      "Reset environment to timestamp:  46656\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 22990    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  241\n",
      "\n",
      "Reset environment to timestamp:  46752\n",
      "Reset environment to timestamp:  46752\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 23085    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  242\n",
      "\n",
      "Reset environment to timestamp:  46848\n",
      "Reset environment to timestamp:  46848\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 23180    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  243\n",
      "\n",
      "Reset environment to timestamp:  46944\n",
      "Reset environment to timestamp:  46944\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 23275    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  244\n",
      "\n",
      "Reset environment to timestamp:  47712\n",
      "Reset environment to timestamp:  47712\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 23370    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  245\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  342803.8268535182  CHF   Episodes learned:  245\n",
      "Reset environment to timestamp:  47808\n",
      "Reset environment to timestamp:  47808\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 23465    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  246\n",
      "\n",
      "Reset environment to timestamp:  47904\n",
      "Reset environment to timestamp:  47904\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 23560    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  247\n",
      "\n",
      "Reset environment to timestamp:  48000\n",
      "Reset environment to timestamp:  48000\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 23655    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  248\n",
      "\n",
      "Reset environment to timestamp:  48096\n",
      "Reset environment to timestamp:  48096\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 23750    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  249\n",
      "\n",
      "Reset environment to timestamp:  48192\n",
      "Reset environment to timestamp:  48192\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 23845    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  250\n",
      "\n",
      "Reset environment to timestamp:  48288\n",
      "Reset environment to timestamp:  48288\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 23940    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  251\n",
      "\n",
      "Reset environment to timestamp:  49056\n",
      "Reset environment to timestamp:  49056\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24035    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  252\n",
      "\n",
      "Reset environment to timestamp:  49152\n",
      "Reset environment to timestamp:  49152\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24130    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  253\n",
      "\n",
      "Reset environment to timestamp:  49248\n",
      "Reset environment to timestamp:  49248\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24225    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  254\n",
      "\n",
      "Reset environment to timestamp:  49344\n",
      "Reset environment to timestamp:  49344\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24320    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  255\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  321823.45991106925  CHF   Episodes learned:  255\n",
      "Reset environment to timestamp:  49440\n",
      "Reset environment to timestamp:  49440\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 24415    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  256\n",
      "\n",
      "Reset environment to timestamp:  49536\n",
      "Reset environment to timestamp:  49536\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24510    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  257\n",
      "\n",
      "Reset environment to timestamp:  49632\n",
      "Reset environment to timestamp:  49632\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 24605    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  258\n",
      "\n",
      "Reset environment to timestamp:  50400\n",
      "Reset environment to timestamp:  50400\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24700    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  259\n",
      "\n",
      "Reset environment to timestamp:  50496\n",
      "Reset environment to timestamp:  50496\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24795    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  260\n",
      "\n",
      "Reset environment to timestamp:  50592\n",
      "Reset environment to timestamp:  50592\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24890    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  261\n",
      "\n",
      "Reset environment to timestamp:  50688\n",
      "Reset environment to timestamp:  50688\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 24985    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  262\n",
      "\n",
      "Reset environment to timestamp:  50784\n",
      "Reset environment to timestamp:  50784\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25080    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  263\n",
      "\n",
      "Reset environment to timestamp:  50880\n",
      "Reset environment to timestamp:  50880\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.44e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 25175    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  264\n",
      "\n",
      "Reset environment to timestamp:  50976\n",
      "Reset environment to timestamp:  50976\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25270    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  265\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  321488.0585291045  CHF   Episodes learned:  265\n",
      "Reset environment to timestamp:  51744\n",
      "Reset environment to timestamp:  51744\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25365    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  266\n",
      "\n",
      "Reset environment to timestamp:  51840\n",
      "Reset environment to timestamp:  51840\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.43e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25460    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  267\n",
      "\n",
      "Reset environment to timestamp:  51936\n",
      "Reset environment to timestamp:  51936\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25555    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  268\n",
      "\n",
      "Reset environment to timestamp:  52032\n",
      "Reset environment to timestamp:  52032\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25650    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  269\n",
      "\n",
      "Reset environment to timestamp:  52128\n",
      "Reset environment to timestamp:  52128\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 25745    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  270\n",
      "\n",
      "Reset environment to timestamp:  52224\n",
      "Reset environment to timestamp:  52224\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.42e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25840    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  271\n",
      "\n",
      "Reset environment to timestamp:  52320\n",
      "Reset environment to timestamp:  52320\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.41e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 25935    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  272\n",
      "\n",
      "Reset environment to timestamp:  53088\n",
      "Reset environment to timestamp:  53088\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26030    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  273\n",
      "\n",
      "Reset environment to timestamp:  53184\n",
      "Reset environment to timestamp:  53184\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 26125    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  274\n",
      "\n",
      "Reset environment to timestamp:  53280\n",
      "Reset environment to timestamp:  53280\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26220    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  275\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  320953.1830681202  CHF   Episodes learned:  275\n",
      "Reset environment to timestamp:  53376\n",
      "Reset environment to timestamp:  53376\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26315    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  276\n",
      "\n",
      "Reset environment to timestamp:  53472\n",
      "Reset environment to timestamp:  53472\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 26410    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  277\n",
      "\n",
      "Reset environment to timestamp:  53568\n",
      "Reset environment to timestamp:  53568\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26505    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  278\n",
      "\n",
      "Reset environment to timestamp:  53664\n",
      "Reset environment to timestamp:  53664\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26600    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  279\n",
      "\n",
      "Reset environment to timestamp:  54432\n",
      "Reset environment to timestamp:  54432\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26695    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  280\n",
      "\n",
      "Reset environment to timestamp:  54528\n",
      "Reset environment to timestamp:  54528\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26790    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  281\n",
      "\n",
      "Reset environment to timestamp:  54624\n",
      "Reset environment to timestamp:  54624\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 26885    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  282\n",
      "\n",
      "Reset environment to timestamp:  54720\n",
      "Reset environment to timestamp:  54720\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 26980    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  283\n",
      "\n",
      "Reset environment to timestamp:  54816\n",
      "Reset environment to timestamp:  54816\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 114      |\n",
      "|    total_timesteps | 27075    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  284\n",
      "\n",
      "Reset environment to timestamp:  54912\n",
      "Reset environment to timestamp:  54912\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 27170    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  285\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  323113.3162900628  CHF   Episodes learned:  285\n",
      "Reset environment to timestamp:  55008\n",
      "Reset environment to timestamp:  55008\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 27265    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  286\n",
      "\n",
      "Reset environment to timestamp:  55776\n",
      "Reset environment to timestamp:  55776\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.37e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 111      |\n",
      "|    total_timesteps | 27360    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  287\n",
      "\n",
      "Reset environment to timestamp:  55872\n",
      "Reset environment to timestamp:  55872\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 27455    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  288\n",
      "\n",
      "Reset environment to timestamp:  55968\n",
      "Reset environment to timestamp:  55968\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 27550    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  289\n",
      "\n",
      "Reset environment to timestamp:  56064\n",
      "Reset environment to timestamp:  56064\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 27645    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  290\n",
      "\n",
      "Reset environment to timestamp:  56160\n",
      "Reset environment to timestamp:  56160\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 27740    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  291\n",
      "\n",
      "Reset environment to timestamp:  56256\n",
      "Reset environment to timestamp:  56256\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 27835    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  292\n",
      "\n",
      "Reset environment to timestamp:  56352\n",
      "Reset environment to timestamp:  56352\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.38e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 27930    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  293\n",
      "\n",
      "Reset environment to timestamp:  57120\n",
      "Reset environment to timestamp:  57120\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 28025    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  294\n",
      "\n",
      "Reset environment to timestamp:  57216\n",
      "Reset environment to timestamp:  57216\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 28120    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  295\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n",
      "Validation reward:  320804.25109642063  CHF   Episodes learned:  295\n",
      "Reset environment to timestamp:  57312\n",
      "Reset environment to timestamp:  57312\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 28215    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  296\n",
      "\n",
      "Reset environment to timestamp:  57408\n",
      "Reset environment to timestamp:  57408\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 28310    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  297\n",
      "\n",
      "Reset environment to timestamp:  57504\n",
      "Reset environment to timestamp:  57504\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 28405    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  298\n",
      "\n",
      "Reset environment to timestamp:  57600\n",
      "Reset environment to timestamp:  57600\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 28500    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  299\n",
      "\n",
      "Reset environment to timestamp:  57696\n",
      "Reset environment to timestamp:  57696\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.39e+05 |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 28595    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  300\n",
      "\n",
      "Reset environment to timestamp:  58464\n",
      "Reset environment to timestamp:  58464\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 115      |\n",
      "|    total_timesteps | 28690    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  301\n",
      "\n",
      "Reset environment to timestamp:  58560\n",
      "Reset environment to timestamp:  58560\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 28785    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  302\n",
      "\n",
      "Reset environment to timestamp:  58656\n",
      "Reset environment to timestamp:  58656\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 28880    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  303\n",
      "\n",
      "Reset environment to timestamp:  58752\n",
      "Reset environment to timestamp:  58752\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 112      |\n",
      "|    total_timesteps | 28975    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  304\n",
      "\n",
      "Reset environment to timestamp:  58848\n",
      "Reset environment to timestamp:  58848\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 95       |\n",
      "|    ep_rew_mean     | 1.4e+05  |\n",
      "| time/              |          |\n",
      "|    fps             | 0        |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 113      |\n",
      "|    total_timesteps | 29070    |\n",
      "---------------------------------\n",
      "\n",
      "Learned episode:  305\n",
      "\n",
      "Reset environment to timestamp:  0\n",
      "Reset environment to timestamp:  0\n"
     ]
    }
   ],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for week_nr in range(start_week, math.ceil((start_week * 7 + nr_iterations) / 7)):\n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "        \n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = count * 96 + week_nr*7*96\n",
    "        \n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "            \n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "        \n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "        \n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "    \n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "        \n",
    "        # reset environment at beginnning of simulation\n",
    "        if count == 0:\n",
    "            \n",
    "            # create environment\n",
    "            env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 499, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 15451)\n",
    "            model = PPO(\"MlpPolicy\",env, verbose=1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "            model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 1024),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1024, 5120),\n",
    "                model.policy.mlp_extractor.policy_net[3]\n",
    "            )\n",
    "            model.policy.action_net =  nn.Linear(5120, 13260)\n",
    "            model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 1028),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1028, 128),\n",
    "                model.policy.mlp_extractor.value_net[3]\n",
    "            )\n",
    "            model.policy.value_net =  nn.Linear(128, 1)\n",
    "            \n",
    "            # load parameters \n",
    "            model.set_parameters(\"car_sharing_v2g_model1\", device = \"cpu\")\n",
    "            \n",
    "            #model.policy.to(device)\n",
    "            \n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "            \n",
    "        else: \n",
    "            env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day)\n",
    "            s = env.reset()\n",
    "            \n",
    "        \n",
    "        # learn one episode\n",
    "        model.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "            \n",
    "          \n",
    "        print(\"\")\n",
    "        print(\"Learned episode: \",count)\n",
    "        print(\"\")\n",
    "        \n",
    "        if count in range(5,nr_iterations + 1,10):\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a3bacf7-83ff-4d58-b2ea-05128d063238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f597a3b1-539c-464f-b981-71dd9440d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"reward_list_model2\", reward_list)\n",
    "np.save(\"count_list_model2\", count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4add6625-62ad-4953-a52f-7c966fa6e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(reward_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02dc0c25-c4b2-4e29-97aa-6b90a5bfe5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d820746-3aff-4879-82cb-f52c5f7183e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=17682, out_features=1024, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "  (3): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.mlp_extractor.policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2b96a66-e203-4bb3-b96f-ecb7eb66befe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=17682, out_features=1024, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=17682, out_features=1028, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1028, out_features=128, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=5120, out_features=13260, bias=True)\n",
       "  (value_net): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "    nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 1024),  # Modify the first layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 5120),\n",
    "    model.policy.mlp_extractor.policy_net[3]\n",
    ")\n",
    "model.policy.action_net =  nn.Linear(5120, 13260)\n",
    "model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "    nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 1028),  # Modify the first layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1028, 128),\n",
    "    model.policy.mlp_extractor.value_net[3]\n",
    ")\n",
    "model.policy.value_net =  nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "# print network\n",
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee091266-a85c-4ddb-b5d7-21312f6afd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_parameters(\"car_sharing_v2g_model1\", device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d26182bc-b234-410b-90bd-c1511fffc59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stable_baselines3.common.net_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ActorCriticPolicy\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlattenExtractor, MlpExtractor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomPolicy\u001b[39;00m(ActorCriticPolicy):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3.common.net_util'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.net_util import FlattenExtractor, MlpExtractor\n",
    "\n",
    "class CustomPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(*args, **kwargs,\n",
    "                                            net_arch=[dict(pi=[64, 64], vf=[64, 64])],\n",
    "                                            features_extractor_class=FlattenExtractor,\n",
    "                                            features_extractor_kwargs=dict(flatten_dim=1),\n",
    "                                            )\n",
    "        self.mlp_extractor = MlpExtractor(\n",
    "            self.features_extractor.features_dim,\n",
    "            net_arch=[1024, 5120],\n",
    "            activation_fn=torch.nn.Tanh\n",
    "        )\n",
    "\n",
    "model = PPO(CustomPolicy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db7882f4-89cc-4217-a284-d06348b956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad4be9a8-5aa4-496c-8baa-c5d7af8a6170",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ActorCriticPolicy' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ActorCriticPolicy' object has no attribute 'weights'"
     ]
    }
   ],
   "source": [
    "model1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa465bbc-980f-4482-898a-034c5a0867cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.0.weight: copying a param with shape torch.Size([1024, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.policy_net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.policy_net.2.weight: copying a param with shape torch.Size([5120, 1024]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.policy_net.2.bias: copying a param with shape torch.Size([5120]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.0.weight: copying a param with shape torch.Size([1028, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.value_net.0.bias: copying a param with shape torch.Size([1028]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.2.weight: copying a param with shape torch.Size([128, 1028]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.value_net.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for action_net.weight: copying a param with shape torch.Size([13260, 5120]) from checkpoint, the shape in current model is torch.Size([13260, 64]).\n\tsize mismatch for value_net.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcar_sharing_v2g_model1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:737\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably loading a model saved with SB3 < 1.7.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwe deactivated exact_match so you can save the model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: the model should still work fine, this only a warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m         )\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# put other pytorch variables back in place\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pytorch_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:721\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m model\u001b[38;5;241m.\u001b[39m_setup_model()\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# put state_dicts back in place\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# Patch to load Policy saved using SB3 < 1.7.0\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;66;03m# the error is probably due to old policy being loaded\u001b[39;00m\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;66;03m# See https://github.com/DLR-RM/stable-baselines3/issues/1233\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi_features_extractor\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:615\u001b[0m, in \u001b[0;36mBaseAlgorithm.set_parameters\u001b[1;34m(self, load_path_or_dict, exact_match, device)\u001b[0m\n\u001b[0;32m    612\u001b[0m         attr\u001b[38;5;241m.\u001b[39mload_state_dict(params[name])\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;66;03m# Assume attr is th.nn.Module\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m         \u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_match\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m     updated_objects\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_match \u001b[38;5;129;01mand\u001b[39;00m updated_objects \u001b[38;5;241m!=\u001b[39m objects_needing_update:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.0.weight: copying a param with shape torch.Size([1024, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.policy_net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.policy_net.2.weight: copying a param with shape torch.Size([5120, 1024]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.policy_net.2.bias: copying a param with shape torch.Size([5120]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.0.weight: copying a param with shape torch.Size([1028, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.value_net.0.bias: copying a param with shape torch.Size([1028]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.2.weight: copying a param with shape torch.Size([128, 1028]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.value_net.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for action_net.weight: copying a param with shape torch.Size([13260, 5120]) from checkpoint, the shape in current model is torch.Size([13260, 64]).\n\tsize mismatch for value_net.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 64])."
     ]
    }
   ],
   "source": [
    "model.load(\"car_sharing_v2g_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35175df5-602a-4d59-a40c-1c07ee9ea4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

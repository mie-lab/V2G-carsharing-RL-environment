{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a711d1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libaries\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine\n",
    "import time\n",
    "from datetime import date, timedelta\n",
    "from rl_v2g import CarsharingEnv\n",
    "import math\n",
    "import stable_baselines3\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3 import A2C\n",
    "from gym.utils.env_checker import check_env as checker_gym\n",
    "from stable_baselines3.common.env_checker import check_env as checker_baselines3\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from stable_baselines3.common.logger import configure\n",
    "import random\n",
    "# load the database credentials from the JSON file\n",
    "with open('config/credentials.json') as f:\n",
    "    credentials = json.load(f)\n",
    "\n",
    "# create connection string\n",
    "connection_string = f\"postgresql://{credentials['username']}:{credentials['password']}@{credentials['host']}:{credentials['port']}/{credentials['database_name']}\"\n",
    "\n",
    "# create the engine with the connection string\n",
    "engine = create_engine(connection_string)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "215b0673-9dca-4b10-b742-4f4af1d3bc48",
   "metadata": {},
   "source": [
    "# Application of Car-sharing Simulation Environment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783aa047-30ec-4998-93ef-aa05f6d709f2",
   "metadata": {},
   "source": [
    "Choose the timespan for the simulation. The simulation will be executed chronologically, starting from the first day (2019-1-1) and continuing for subsequent days (2019-1-2, 2019-1-3, etc.). If a start date other than 2019-1-1 is selected, the \"Start simulation\" cell below may need to be modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c92e923b-e2c0-4257-9028-d30dbdff5d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set learn period\n",
    "start_date = date(2019, 1, 8)\n",
    "end_date = date(2020, 7, 26)\n",
    "#end_date = date(2019, 1, 10)\n",
    "start_week = 1\n",
    "\n",
    "# set simulation period\n",
    "start_date_simulation = date(2019, 1, 1)\n",
    "end_date_simulation = date(2019, 1, 8)\n",
    "start_week_simulation = 0\n",
    "\n",
    "# calculate number of days to learn\n",
    "nr_iterations = (end_date - start_date).days\n",
    "\n",
    "# calculate number of days to simulate\n",
    "nr_iterations_simulation = (end_date_simulation - start_date_simulation).days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8e51f9-3dc9-4a24-9527-95dc871616d6",
   "metadata": {},
   "source": [
    "# Load data for simulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ec0e94-a367-42fb-bf33-99ef8df0c844",
   "metadata": {},
   "source": [
    "### Car-sharing stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e17d3ddf-c804-442f-8d29-3a23c2305fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station_no</th>\n",
       "      <th>geom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2901</td>\n",
       "      <td>POINT (2555501.836 1145060.068)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2905</td>\n",
       "      <td>POINT (2752963.411 1260089.916)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2910</td>\n",
       "      <td>POINT (2501877.645 1126218.900)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2913</td>\n",
       "      <td>POINT (2682234.096 1243208.370)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2918</td>\n",
       "      <td>POINT (2736874.744 1253090.505)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station_no                             geom\n",
       "0        2901  POINT (2555501.836 1145060.068)\n",
       "1        2905  POINT (2752963.411 1260089.916)\n",
       "2        2910  POINT (2501877.645 1126218.900)\n",
       "3        2913  POINT (2682234.096 1243208.370)\n",
       "4        2918  POINT (2736874.744 1253090.505)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get station geodata, create spatial index\n",
    "sql = \" SELECT * FROM msc_2023_dominik.distinct_stations\"\n",
    "stations = gpd.read_postgis(sql, engine, geom_col='geom',crs = \"EPSG:2056\")\n",
    "stations.sindex\n",
    "stations.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c75c9df-a17b-4aa5-82c7-6b1d9678cac2",
   "metadata": {},
   "source": [
    "### Vehicle information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "0d8127d0-ea76-4840-8b09-d9dccac60708",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>model_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>charge_power</th>\n",
       "      <th>battery_capacity</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2962</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106516</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2963</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106517</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2964</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106518</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2965</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106519</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2966</td>\n",
       "      <td>Combi</td>\n",
       "      <td>106526</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index vehicle_category  vehicle_no                   model_name  \\\n",
       "0   2962          Minivan      106516  eVito 129KB Tourer Pro 3200   \n",
       "1   2963          Minivan      106517  eVito 129KB Tourer Pro 3200   \n",
       "2   2964          Minivan      106518  eVito 129KB Tourer Pro 3200   \n",
       "3   2965          Minivan      106519  eVito 129KB Tourer Pro 3200   \n",
       "4   2966            Combi      106526                   Enyaq iV80   \n",
       "\n",
       "      brand_name  charge_power  battery_capacity  range  \n",
       "0  Mercedes-Benz          11.0             100.0  378.0  \n",
       "1  Mercedes-Benz          11.0             100.0  378.0  \n",
       "2  Mercedes-Benz          11.0             100.0  378.0  \n",
       "3  Mercedes-Benz          11.0             100.0  378.0  \n",
       "4          Skoda          11.0              82.0  420.0  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get vehicle data\n",
    "sql = \"SELECT * FROM msc_2023_dominik.vehicle_information ORDER BY vehicle_no limit 15\"\n",
    "vehicles = pd.read_sql(sql, engine)\n",
    "vehicles.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd729dc1-8210-4b36-89af-82de5ba78cad",
   "metadata": {},
   "source": [
    "### Reservations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "361f0fc4-42f0-4efa-a64b-1ded60e626a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_no</th>\n",
       "      <th>start_station_no</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>reservationfrom_time_discrete</th>\n",
       "      <th>drive_firststart_time_discrete</th>\n",
       "      <th>drive_lastend_time_discrete</th>\n",
       "      <th>reservation_duration</th>\n",
       "      <th>revenue_distance</th>\n",
       "      <th>required_soc</th>\n",
       "      <th>revenue_duration</th>\n",
       "      <th>drive_km</th>\n",
       "      <th>drive_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24281745</td>\n",
       "      <td>4714</td>\n",
       "      <td>114572</td>\n",
       "      <td>72.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>715.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24281754</td>\n",
       "      <td>4714</td>\n",
       "      <td>114582</td>\n",
       "      <td>72.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>716.0</td>\n",
       "      <td>1804.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22919882</td>\n",
       "      <td>4173</td>\n",
       "      <td>116242</td>\n",
       "      <td>576.0</td>\n",
       "      <td>734.0</td>\n",
       "      <td>925.0</td>\n",
       "      <td>672.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>191.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24154068</td>\n",
       "      <td>3057</td>\n",
       "      <td>113667</td>\n",
       "      <td>604.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>924.0</td>\n",
       "      <td>424.0</td>\n",
       "      <td>68.5</td>\n",
       "      <td>51.500000</td>\n",
       "      <td>265.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24340023</td>\n",
       "      <td>2902</td>\n",
       "      <td>116881</td>\n",
       "      <td>604.0</td>\n",
       "      <td>701.0</td>\n",
       "      <td>982.0</td>\n",
       "      <td>380.0</td>\n",
       "      <td>178.4</td>\n",
       "      <td>53.095238</td>\n",
       "      <td>301.5</td>\n",
       "      <td>223.0</td>\n",
       "      <td>283.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reservation_no  start_station_no  vehicle_no  \\\n",
       "0        24281745              4714      114572   \n",
       "1        24281754              4714      114582   \n",
       "2        22919882              4173      116242   \n",
       "3        24154068              3057      113667   \n",
       "4        24340023              2902      116881   \n",
       "\n",
       "   reservationfrom_time_discrete  drive_firststart_time_discrete  \\\n",
       "0                           72.0                           715.0   \n",
       "1                           72.0                           716.0   \n",
       "2                          576.0                           734.0   \n",
       "3                          604.0                           706.0   \n",
       "4                          604.0                           701.0   \n",
       "\n",
       "   drive_lastend_time_discrete  reservation_duration  revenue_distance  \\\n",
       "0                        715.0                1804.0               0.0   \n",
       "1                        716.0                1804.0               0.0   \n",
       "2                        925.0                 672.0               0.0   \n",
       "3                        924.0                 424.0              68.5   \n",
       "4                        982.0                 380.0             178.4   \n",
       "\n",
       "   required_soc  revenue_duration  drive_km  drive_duration  \n",
       "0      0.000000               0.0       1.0             1.0  \n",
       "1      0.000000               0.0       1.0             1.0  \n",
       "2      9.500000               0.0      19.0           191.0  \n",
       "3     51.500000             265.0     103.0           219.0  \n",
       "4     53.095238             301.5     223.0           283.0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get daily reservations, save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "reservations_dict = {}\n",
    "start_date_reservations = start_date\n",
    "while start_date_reservations <= end_date:\n",
    "    sql = \"\"\"SELECT reservation_no, start_station_no, vehicle_no, reservationfrom_time_discrete, drive_firststart_time_discrete, \n",
    "            drive_lastend_time_discrete, reservation_duration, revenue_distance, required_soc, revenue_duration, drive_km, \n",
    "            (floor(EXTRACT(epoch FROM (date_trunc('hour', TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) + \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes' \n",
    "                                - date_trunc('hour', TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) - \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes'\n",
    "                               )) / 900) * 900 + 900) / 900 AS drive_duration\n",
    "            FROM msc_2023_dominik.reservations_long_time \n",
    "            WHERE  DATE(reservationfrom_discrete_date) = '{}' or  DATE(drive_firststart_discrete_date) = '{}' \n",
    "            ORDER BY reservationfrom_discrete\"\"\".format(start_date_reservations, start_date_reservations) \n",
    "    reservations = pd.read_sql(sql, engine)\n",
    "    reservations_dict[start_date_reservations.strftime('%Y-%m-%d')] = reservations\n",
    "    start_date_reservations += delta     \n",
    "reservations_dict[(start_date).strftime('%Y-%m-%d')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a110a9-b2b1-4887-b52d-4fc87278e1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "reservations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "67e6fc03-b963-4138-b7d7-618e371440de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reservation_no</th>\n",
       "      <th>start_station_no</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>reservationfrom_time_discrete</th>\n",
       "      <th>drive_firststart_time_discrete</th>\n",
       "      <th>drive_lastend_time_discrete</th>\n",
       "      <th>reservation_duration</th>\n",
       "      <th>revenue_distance</th>\n",
       "      <th>required_soc</th>\n",
       "      <th>revenue_duration</th>\n",
       "      <th>drive_km</th>\n",
       "      <th>drive_duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24134345</td>\n",
       "      <td>2938</td>\n",
       "      <td>114034</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>44.85</td>\n",
       "      <td>34.500000</td>\n",
       "      <td>13.75</td>\n",
       "      <td>69.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24519097</td>\n",
       "      <td>4407</td>\n",
       "      <td>113833</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.00</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.25</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24519221</td>\n",
       "      <td>3165</td>\n",
       "      <td>116525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24519174</td>\n",
       "      <td>1557</td>\n",
       "      <td>115969</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>45.75</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>43.75</td>\n",
       "      <td>61.0</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24514447</td>\n",
       "      <td>2702</td>\n",
       "      <td>114871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.66</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>7.50</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reservation_no  start_station_no  vehicle_no  \\\n",
       "0        24134345              2938      114034   \n",
       "1        24519097              4407      113833   \n",
       "2        24519221              3165      116525   \n",
       "3        24519174              1557      115969   \n",
       "4        24514447              2702      114871   \n",
       "\n",
       "   reservationfrom_time_discrete  drive_firststart_time_discrete  \\\n",
       "0                            0.0                             1.0   \n",
       "1                            0.0                             2.0   \n",
       "2                            0.0                             0.0   \n",
       "3                            0.0                             0.0   \n",
       "4                            0.0                             4.0   \n",
       "\n",
       "   drive_lastend_time_discrete  reservation_duration  revenue_distance  \\\n",
       "0                         19.0                  22.0             44.85   \n",
       "1                          9.0                  10.0             13.00   \n",
       "2                         96.0                  96.0              0.00   \n",
       "3                         49.0                  50.0             45.75   \n",
       "4                          5.0                   6.0              2.66   \n",
       "\n",
       "   required_soc  revenue_duration  drive_km  drive_duration  \n",
       "0     34.500000             13.75      69.0            20.0  \n",
       "1     10.000000              6.25      20.0             7.0  \n",
       "2      0.000000              0.00       0.0            97.0  \n",
       "3     30.500000             43.75      61.0            50.0  \n",
       "4      1.538462              7.50       4.0             2.0  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get daily reservations, save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "reservations_dict_simulation = {}\n",
    "start_date_reservations = start_date_simulation\n",
    "while start_date_reservations <= end_date_simulation:\n",
    "    sql = \"\"\"SELECT reservation_no, start_station_no, vehicle_no, reservationfrom_time_discrete, drive_firststart_time_discrete, \n",
    "            drive_lastend_time_discrete, reservation_duration, revenue_distance, required_soc, revenue_duration, drive_km, \n",
    "            (floor(EXTRACT(epoch FROM (date_trunc('hour', TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) + \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_lastend, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes' \n",
    "                                - date_trunc('hour', TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) - \n",
    "                                floor(EXTRACT(minute FROM TO_TIMESTAMP(drive_firststart, 'YYYY-MM-DD HH24:MI:SS.MS')) / 15) * interval '15 minutes'\n",
    "                               )) / 900) * 900 + 900) / 900 AS drive_duration\n",
    "            FROM msc_2023_dominik.reservations_long_time \n",
    "            WHERE  DATE(reservationfrom_discrete_date) = '{}' or  DATE(drive_firststart_discrete_date) = '{}' \n",
    "            ORDER BY reservationfrom_discrete\"\"\".format(start_date_reservations, start_date_reservations)\n",
    "    reservations = pd.read_sql(sql, engine)\n",
    "    reservations_dict_simulation[start_date_reservations.strftime('%Y-%m-%d')] = reservations\n",
    "    start_date_reservations += delta\n",
    "reservations_dict_simulation[(start_date_simulation).strftime('%Y-%m-%d')].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "f85c1bb3-758e-455f-bbbb-4837ca89ee4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reservations_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231981c3-a6b3-4fe1-b35c-38218488d645",
   "metadata": {},
   "source": [
    "### Electicity prices for charging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ea91fd7f-4e91-460b-acc1-971747c0dd78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_chf_kwh_0.0</th>\n",
       "      <th>Price_chf_kwh_0.25</th>\n",
       "      <th>Price_chf_kwh_0.5</th>\n",
       "      <th>Price_chf_kwh_0.75</th>\n",
       "      <th>Price_chf_kwh_1.0</th>\n",
       "      <th>Price_chf_kwh_1.25</th>\n",
       "      <th>Price_chf_kwh_1.5</th>\n",
       "      <th>Price_chf_kwh_1.75</th>\n",
       "      <th>Price_chf_kwh_2.0</th>\n",
       "      <th>Price_chf_kwh_2.25</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_chf_kwh_21.75</th>\n",
       "      <th>Price_chf_kwh_22.0</th>\n",
       "      <th>Price_chf_kwh_22.25</th>\n",
       "      <th>Price_chf_kwh_22.5</th>\n",
       "      <th>Price_chf_kwh_22.75</th>\n",
       "      <th>Price_chf_kwh_23.0</th>\n",
       "      <th>Price_chf_kwh_23.25</th>\n",
       "      <th>Price_chf_kwh_23.5</th>\n",
       "      <th>Price_chf_kwh_23.75</th>\n",
       "      <th>Delivery day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.055468</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.050245</td>\n",
       "      <td>0.049484</td>\n",
       "      <td>0.049484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065208</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.065165</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>0.061071</td>\n",
       "      <td>2019-01-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057564</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>0.057086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.067586</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.067641</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>0.064112</td>\n",
       "      <td>2019-01-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.062939</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058443</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072842</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.070312</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>0.061842</td>\n",
       "      <td>2019-01-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.068889</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.061907</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>0.060854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.072212</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.071756</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>0.069389</td>\n",
       "      <td>2019-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.067521</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.061951</td>\n",
       "      <td>0.059366</td>\n",
       "      <td>0.059366</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058595</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.061353</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>0.058606</td>\n",
       "      <td>2019-01-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price_chf_kwh_0.0  Price_chf_kwh_0.25  Price_chf_kwh_0.5  \\\n",
       "0           0.055468            0.055468           0.055468   \n",
       "1           0.061907            0.061907           0.061907   \n",
       "2           0.062939            0.062939           0.062939   \n",
       "3           0.068889            0.068889           0.068889   \n",
       "4           0.067521            0.067521           0.067521   \n",
       "\n",
       "   Price_chf_kwh_0.75  Price_chf_kwh_1.0  Price_chf_kwh_1.25  \\\n",
       "0            0.055468           0.050245            0.050245   \n",
       "1            0.061907           0.057564            0.057564   \n",
       "2            0.062939           0.058443            0.058443   \n",
       "3            0.068889           0.061907            0.061907   \n",
       "4            0.067521           0.061951            0.061951   \n",
       "\n",
       "   Price_chf_kwh_1.5  Price_chf_kwh_1.75  Price_chf_kwh_2.0  \\\n",
       "0           0.050245            0.050245           0.049484   \n",
       "1           0.057564            0.057564           0.057086   \n",
       "2           0.058443            0.058443           0.058150   \n",
       "3           0.061907            0.061907           0.060854   \n",
       "4           0.061951            0.061951           0.059366   \n",
       "\n",
       "   Price_chf_kwh_2.25  ...  Price_chf_kwh_21.75  Price_chf_kwh_22.0  \\\n",
       "0            0.049484  ...             0.065208            0.065165   \n",
       "1            0.057086  ...             0.067586            0.067641   \n",
       "2            0.058150  ...             0.072842            0.070312   \n",
       "3            0.060854  ...             0.072212            0.071756   \n",
       "4            0.059366  ...             0.058595            0.061353   \n",
       "\n",
       "   Price_chf_kwh_22.25  Price_chf_kwh_22.5  Price_chf_kwh_22.75  \\\n",
       "0             0.065165            0.065165             0.065165   \n",
       "1             0.067641            0.067641             0.067641   \n",
       "2             0.070312            0.070312             0.070312   \n",
       "3             0.071756            0.071756             0.071756   \n",
       "4             0.061353            0.061353             0.061353   \n",
       "\n",
       "   Price_chf_kwh_23.0  Price_chf_kwh_23.25  Price_chf_kwh_23.5  \\\n",
       "0            0.061071             0.061071            0.061071   \n",
       "1            0.064112             0.064112            0.064112   \n",
       "2            0.061842             0.061842            0.061842   \n",
       "3            0.069389             0.069389            0.069389   \n",
       "4            0.058606             0.058606            0.058606   \n",
       "\n",
       "   Price_chf_kwh_23.75  Delivery day  \n",
       "0             0.061071    2019-01-08  \n",
       "1             0.064112    2019-01-09  \n",
       "2             0.061842    2019-01-10  \n",
       "3             0.069389    2019-01-11  \n",
       "4             0.058606    2019-01-12  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get charging costs data\n",
    "prices = \"\"\n",
    "for i in range(0, 480, 5):\n",
    "    price = i / 20\n",
    "    prices += '\"Price_chf_kwh_{}\", '.format(price)\n",
    "\n",
    "sql = \"\"\"SELECT {} \"Delivery day\" FROM msc_2023_dominik.charging_costs WHERE \"Delivery day\" >=  '{}' and \"Delivery day\" <=  '{}' ORDER BY \"Delivery day\" \"\"\".format(prices, start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "\n",
    "charging_costs = pd.read_sql(sql, engine)\n",
    "charging_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a518a3fd-5556-412e-8514-cb45384f601c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "charging_costs_dict = {}\n",
    "start_date_electricity = start_date\n",
    "while start_date_electricity <= end_date:\n",
    "    electricity_price_day = charging_costs[charging_costs[\"Delivery day\"].dt.date == start_date_electricity].drop([\"Delivery day\"],axis = 1).iloc[0].values\n",
    "    charging_costs_dict[start_date_electricity.strftime('%Y-%m-%d')] = electricity_price_day\n",
    "    start_date_electricity += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "08b385c5-f02c-40dd-8842-ec3436a920aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31', '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-29', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-25', '2019-05-26', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-20', '2019-06-21', '2019-06-22', '2019-06-23', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-19', '2019-07-20', '2019-07-21', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-27', '2019-07-28', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19', '2019-09-20', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-05', '2019-10-06', '2019-10-07', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-11', '2020-01-12', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16', '2020-01-17', '2020-01-18', '2020-01-19', '2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', '2020-02-01', '2020-02-02', '2020-02-03', '2020-02-04', '2020-02-05', '2020-02-06', '2020-02-07', '2020-02-08', '2020-02-09', '2020-02-10', '2020-02-11', '2020-02-12', '2020-02-13', '2020-02-14', '2020-02-15', '2020-02-16', '2020-02-17', '2020-02-18', '2020-02-19', '2020-02-20', '2020-02-21', '2020-02-22', '2020-02-23', '2020-02-24', '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28', '2020-02-29', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14', '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19', '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28', '2020-04-29', '2020-04-30', '2020-05-01', '2020-05-02', '2020-05-03', '2020-05-04', '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08', '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12', '2020-05-13', '2020-05-14', '2020-05-15', '2020-05-16', '2020-05-17', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21', '2020-05-22', '2020-05-23', '2020-05-24', '2020-05-25', '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29', '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02', '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-06', '2020-06-07', '2020-06-08', '2020-06-09', '2020-06-10', '2020-06-11', '2020-06-12', '2020-06-13', '2020-06-14', '2020-06-15', '2020-06-16', '2020-06-17', '2020-06-18', '2020-06-19', '2020-06-20', '2020-06-21', '2020-06-22', '2020-06-23', '2020-06-24', '2020-06-25', '2020-06-26', '2020-06-27', '2020-06-28', '2020-06-29', '2020-06-30', '2020-07-01', '2020-07-02', '2020-07-03', '2020-07-04', '2020-07-05', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-09', '2020-07-10', '2020-07-11', '2020-07-12', '2020-07-13', '2020-07-14', '2020-07-15', '2020-07-16', '2020-07-17', '2020-07-18', '2020-07-19', '2020-07-20', '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24', '2020-07-25', '2020-07-26'])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charging_costs_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "fd3cd53e-3ed3-498b-9610-75fd56a57ebf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Price_chf_kwh_0.0</th>\n",
       "      <th>Price_chf_kwh_0.25</th>\n",
       "      <th>Price_chf_kwh_0.5</th>\n",
       "      <th>Price_chf_kwh_0.75</th>\n",
       "      <th>Price_chf_kwh_1.0</th>\n",
       "      <th>Price_chf_kwh_1.25</th>\n",
       "      <th>Price_chf_kwh_1.5</th>\n",
       "      <th>Price_chf_kwh_1.75</th>\n",
       "      <th>Price_chf_kwh_2.0</th>\n",
       "      <th>Price_chf_kwh_2.25</th>\n",
       "      <th>...</th>\n",
       "      <th>Price_chf_kwh_21.75</th>\n",
       "      <th>Price_chf_kwh_22.0</th>\n",
       "      <th>Price_chf_kwh_22.25</th>\n",
       "      <th>Price_chf_kwh_22.5</th>\n",
       "      <th>Price_chf_kwh_22.75</th>\n",
       "      <th>Price_chf_kwh_23.0</th>\n",
       "      <th>Price_chf_kwh_23.25</th>\n",
       "      <th>Price_chf_kwh_23.5</th>\n",
       "      <th>Price_chf_kwh_23.75</th>\n",
       "      <th>Delivery day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.054577</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.052927</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>0.051298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055055</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059855</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>0.059844</td>\n",
       "      <td>2019-01-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.054262</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.052840</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>0.045130</td>\n",
       "      <td>...</td>\n",
       "      <td>0.066175</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.065230</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>0.064036</td>\n",
       "      <td>2019-01-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.057585</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.054838</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>0.052471</td>\n",
       "      <td>...</td>\n",
       "      <td>0.068433</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.066262</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>0.062276</td>\n",
       "      <td>2019-01-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.057107</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.056130</td>\n",
       "      <td>0.054241</td>\n",
       "      <td>0.054241</td>\n",
       "      <td>...</td>\n",
       "      <td>0.070214</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.070301</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>0.065914</td>\n",
       "      <td>2019-01-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.068477</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.063503</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>0.059431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.065045</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066381</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>0.066370</td>\n",
       "      <td>2019-01-05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Price_chf_kwh_0.0  Price_chf_kwh_0.25  Price_chf_kwh_0.5  \\\n",
       "0           0.054577            0.054577           0.054577   \n",
       "1           0.054262            0.054262           0.054262   \n",
       "2           0.057585            0.057585           0.057585   \n",
       "3           0.057107            0.057107           0.057107   \n",
       "4           0.068477            0.068477           0.068477   \n",
       "\n",
       "   Price_chf_kwh_0.75  Price_chf_kwh_1.0  Price_chf_kwh_1.25  \\\n",
       "0            0.054577           0.052927            0.052927   \n",
       "1            0.054262           0.052840            0.052840   \n",
       "2            0.057585           0.054838            0.054838   \n",
       "3            0.057107           0.056130            0.056130   \n",
       "4            0.068477           0.063503            0.063503   \n",
       "\n",
       "   Price_chf_kwh_1.5  Price_chf_kwh_1.75  Price_chf_kwh_2.0  \\\n",
       "0           0.052927            0.052927           0.051298   \n",
       "1           0.052840            0.052840           0.045130   \n",
       "2           0.054838            0.054838           0.052471   \n",
       "3           0.056130            0.056130           0.054241   \n",
       "4           0.063503            0.063503           0.059431   \n",
       "\n",
       "   Price_chf_kwh_2.25  ...  Price_chf_kwh_21.75  Price_chf_kwh_22.0  \\\n",
       "0            0.051298  ...             0.055055            0.059855   \n",
       "1            0.045130  ...             0.066175            0.065230   \n",
       "2            0.052471  ...             0.068433            0.066262   \n",
       "3            0.054241  ...             0.070214            0.070301   \n",
       "4            0.059431  ...             0.065045            0.066381   \n",
       "\n",
       "   Price_chf_kwh_22.25  Price_chf_kwh_22.5  Price_chf_kwh_22.75  \\\n",
       "0             0.059855            0.059855             0.059855   \n",
       "1             0.065230            0.065230             0.065230   \n",
       "2             0.066262            0.066262             0.066262   \n",
       "3             0.070301            0.070301             0.070301   \n",
       "4             0.066381            0.066381             0.066381   \n",
       "\n",
       "   Price_chf_kwh_23.0  Price_chf_kwh_23.25  Price_chf_kwh_23.5  \\\n",
       "0            0.059844             0.059844            0.059844   \n",
       "1            0.064036             0.064036            0.064036   \n",
       "2            0.062276             0.062276            0.062276   \n",
       "3            0.065914             0.065914            0.065914   \n",
       "4            0.066370             0.066370            0.066370   \n",
       "\n",
       "   Price_chf_kwh_23.75  Delivery day  \n",
       "0             0.059844    2019-01-01  \n",
       "1             0.064036    2019-01-02  \n",
       "2             0.062276    2019-01-03  \n",
       "3             0.065914    2019-01-04  \n",
       "4             0.066370    2019-01-05  \n",
       "\n",
       "[5 rows x 97 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get charging costs data\n",
    "prices = \"\"\n",
    "for i in range(0, 480, 5):\n",
    "    price = i / 20\n",
    "    prices += '\"Price_chf_kwh_{}\", '.format(price)\n",
    "\n",
    "sql = \"\"\"SELECT {} \"Delivery day\" FROM msc_2023_dominik.charging_costs WHERE \"Delivery day\" >=  '{}' and \"Delivery day\" <=  '{}' ORDER BY \"Delivery day\" \"\"\".format(prices, start_date_simulation.strftime('%Y-%m-%d'), end_date_simulation.strftime('%Y-%m-%d'))\n",
    "\n",
    "charging_costs = pd.read_sql(sql, engine)\n",
    "charging_costs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "97d9360b-58a7-4abc-a745-fa48e34b63b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "charging_costs_dict_simulation = {}\n",
    "start_date_electricity = start_date_simulation\n",
    "while start_date_electricity <= end_date_simulation:\n",
    "    electricity_price_day = charging_costs[charging_costs[\"Delivery day\"].dt.date == start_date_electricity].drop([\"Delivery day\"],axis = 1).iloc[0].values\n",
    "    charging_costs_dict_simulation[start_date_electricity.strftime('%Y-%m-%d')] = electricity_price_day\n",
    "    start_date_electricity += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "8a4bcea5-de92-4b8b-b338-f1c6e920b6ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "charging_costs_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dbf046c-5db6-45c4-ab6e-edf86bfd9f77",
   "metadata": {},
   "source": [
    "### Secondary energy prices (for V2G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "45a1fb02-3e5d-4d8c-8394-f465d7cff15e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Secondary_positive_v2g_prices_chf_kwh</th>\n",
       "      <th>Secondary_negative_v2g_prices_chf_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-08 00:00:00</td>\n",
       "      <td>0.052801</td>\n",
       "      <td>0.035201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-08 00:15:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-08 00:30:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-08 00:45:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-08 01:00:00</td>\n",
       "      <td>0.052687</td>\n",
       "      <td>0.035132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Secondary_positive_v2g_prices_chf_kwh  \\\n",
       "0 2019-01-08 00:00:00                               0.052801   \n",
       "1 2019-01-08 00:15:00                               0.052687   \n",
       "2 2019-01-08 00:30:00                               0.052687   \n",
       "3 2019-01-08 00:45:00                               0.052687   \n",
       "4 2019-01-08 01:00:00                               0.052687   \n",
       "\n",
       "   Secondary_negative_v2g_prices_chf_kwh  \n",
       "0                               0.035201  \n",
       "1                               0.035132  \n",
       "2                               0.035132  \n",
       "3                               0.035132  \n",
       "4                               0.035132  "
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get v2g price data\n",
    "sql = \"\"\"SELECT \"Timestamp\", \"Secondary_positive_v2g_prices_chf_kwh\", \"Secondary_negative_v2g_prices_chf_kwh\" FROM msc_2023_dominik.v2g_prices WHERE \"Timestamp\" >=  '{}' and \"Timestamp\" <=  '{}' ORDER BY \"Timestamp\" \"\"\".format(start_date.strftime('%Y-%m-%d'), end_date.strftime('%Y-%m-%d'))\n",
    "v2g_prices = pd.read_sql(sql, engine)\n",
    "v2g_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2c003997-a4e1-496c-8b8f-f034b238efa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "v2g_price_dict = {}\n",
    "start_date_v2g = start_date\n",
    "while start_date_v2g <= end_date:\n",
    "    v2g_price_day_positive = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_positive_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_day_negative = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_negative_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_dict[start_date_v2g.strftime('%Y-%m-%d')] = [v2g_price_day_positive, v2g_price_day_negative]\n",
    "    start_date_v2g += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "035a9fce-2bb1-47e8-a5e7-f902655900aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-08', '2019-01-09', '2019-01-10', '2019-01-11', '2019-01-12', '2019-01-13', '2019-01-14', '2019-01-15', '2019-01-16', '2019-01-17', '2019-01-18', '2019-01-19', '2019-01-20', '2019-01-21', '2019-01-22', '2019-01-23', '2019-01-24', '2019-01-25', '2019-01-26', '2019-01-27', '2019-01-28', '2019-01-29', '2019-01-30', '2019-01-31', '2019-02-01', '2019-02-02', '2019-02-03', '2019-02-04', '2019-02-05', '2019-02-06', '2019-02-07', '2019-02-08', '2019-02-09', '2019-02-10', '2019-02-11', '2019-02-12', '2019-02-13', '2019-02-14', '2019-02-15', '2019-02-16', '2019-02-17', '2019-02-18', '2019-02-19', '2019-02-20', '2019-02-21', '2019-02-22', '2019-02-23', '2019-02-24', '2019-02-25', '2019-02-26', '2019-02-27', '2019-02-28', '2019-03-01', '2019-03-02', '2019-03-03', '2019-03-04', '2019-03-05', '2019-03-06', '2019-03-07', '2019-03-08', '2019-03-09', '2019-03-10', '2019-03-11', '2019-03-12', '2019-03-13', '2019-03-14', '2019-03-15', '2019-03-16', '2019-03-17', '2019-03-18', '2019-03-19', '2019-03-20', '2019-03-21', '2019-03-22', '2019-03-23', '2019-03-24', '2019-03-25', '2019-03-26', '2019-03-27', '2019-03-28', '2019-03-29', '2019-03-30', '2019-03-31', '2019-04-01', '2019-04-02', '2019-04-03', '2019-04-04', '2019-04-05', '2019-04-06', '2019-04-07', '2019-04-08', '2019-04-09', '2019-04-10', '2019-04-11', '2019-04-12', '2019-04-13', '2019-04-14', '2019-04-15', '2019-04-16', '2019-04-17', '2019-04-18', '2019-04-19', '2019-04-20', '2019-04-21', '2019-04-22', '2019-04-23', '2019-04-24', '2019-04-25', '2019-04-26', '2019-04-27', '2019-04-28', '2019-04-29', '2019-04-30', '2019-05-01', '2019-05-02', '2019-05-03', '2019-05-04', '2019-05-05', '2019-05-06', '2019-05-07', '2019-05-08', '2019-05-09', '2019-05-10', '2019-05-11', '2019-05-12', '2019-05-13', '2019-05-14', '2019-05-15', '2019-05-16', '2019-05-17', '2019-05-18', '2019-05-19', '2019-05-20', '2019-05-21', '2019-05-22', '2019-05-23', '2019-05-24', '2019-05-25', '2019-05-26', '2019-05-27', '2019-05-28', '2019-05-29', '2019-05-30', '2019-05-31', '2019-06-01', '2019-06-02', '2019-06-03', '2019-06-04', '2019-06-05', '2019-06-06', '2019-06-07', '2019-06-08', '2019-06-09', '2019-06-10', '2019-06-11', '2019-06-12', '2019-06-13', '2019-06-14', '2019-06-15', '2019-06-16', '2019-06-17', '2019-06-18', '2019-06-19', '2019-06-20', '2019-06-21', '2019-06-22', '2019-06-23', '2019-06-24', '2019-06-25', '2019-06-26', '2019-06-27', '2019-06-28', '2019-06-29', '2019-06-30', '2019-07-01', '2019-07-02', '2019-07-03', '2019-07-04', '2019-07-05', '2019-07-06', '2019-07-07', '2019-07-08', '2019-07-09', '2019-07-10', '2019-07-11', '2019-07-12', '2019-07-13', '2019-07-14', '2019-07-15', '2019-07-16', '2019-07-17', '2019-07-18', '2019-07-19', '2019-07-20', '2019-07-21', '2019-07-22', '2019-07-23', '2019-07-24', '2019-07-25', '2019-07-26', '2019-07-27', '2019-07-28', '2019-07-29', '2019-07-30', '2019-07-31', '2019-08-01', '2019-08-02', '2019-08-03', '2019-08-04', '2019-08-05', '2019-08-06', '2019-08-07', '2019-08-08', '2019-08-09', '2019-08-10', '2019-08-11', '2019-08-12', '2019-08-13', '2019-08-14', '2019-08-15', '2019-08-16', '2019-08-17', '2019-08-18', '2019-08-19', '2019-08-20', '2019-08-21', '2019-08-22', '2019-08-23', '2019-08-24', '2019-08-25', '2019-08-26', '2019-08-27', '2019-08-28', '2019-08-29', '2019-08-30', '2019-08-31', '2019-09-01', '2019-09-02', '2019-09-03', '2019-09-04', '2019-09-05', '2019-09-06', '2019-09-07', '2019-09-08', '2019-09-09', '2019-09-10', '2019-09-11', '2019-09-12', '2019-09-13', '2019-09-14', '2019-09-15', '2019-09-16', '2019-09-17', '2019-09-18', '2019-09-19', '2019-09-20', '2019-09-21', '2019-09-22', '2019-09-23', '2019-09-24', '2019-09-25', '2019-09-26', '2019-09-27', '2019-09-28', '2019-09-29', '2019-09-30', '2019-10-01', '2019-10-02', '2019-10-03', '2019-10-04', '2019-10-05', '2019-10-06', '2019-10-07', '2019-10-08', '2019-10-09', '2019-10-10', '2019-10-11', '2019-10-12', '2019-10-13', '2019-10-14', '2019-10-15', '2019-10-16', '2019-10-17', '2019-10-18', '2019-10-19', '2019-10-20', '2019-10-21', '2019-10-22', '2019-10-23', '2019-10-24', '2019-10-25', '2019-10-26', '2019-10-27', '2019-10-28', '2019-10-29', '2019-10-30', '2019-10-31', '2019-11-01', '2019-11-02', '2019-11-03', '2019-11-04', '2019-11-05', '2019-11-06', '2019-11-07', '2019-11-08', '2019-11-09', '2019-11-10', '2019-11-11', '2019-11-12', '2019-11-13', '2019-11-14', '2019-11-15', '2019-11-16', '2019-11-17', '2019-11-18', '2019-11-19', '2019-11-20', '2019-11-21', '2019-11-22', '2019-11-23', '2019-11-24', '2019-11-25', '2019-11-26', '2019-11-27', '2019-11-28', '2019-11-29', '2019-11-30', '2019-12-01', '2019-12-02', '2019-12-03', '2019-12-04', '2019-12-05', '2019-12-06', '2019-12-07', '2019-12-08', '2019-12-09', '2019-12-10', '2019-12-11', '2019-12-12', '2019-12-13', '2019-12-14', '2019-12-15', '2019-12-16', '2019-12-17', '2019-12-18', '2019-12-19', '2019-12-20', '2019-12-21', '2019-12-22', '2019-12-23', '2019-12-24', '2019-12-25', '2019-12-26', '2019-12-27', '2019-12-28', '2019-12-29', '2019-12-30', '2019-12-31', '2020-01-01', '2020-01-02', '2020-01-03', '2020-01-04', '2020-01-05', '2020-01-06', '2020-01-07', '2020-01-08', '2020-01-09', '2020-01-10', '2020-01-11', '2020-01-12', '2020-01-13', '2020-01-14', '2020-01-15', '2020-01-16', '2020-01-17', '2020-01-18', '2020-01-19', '2020-01-20', '2020-01-21', '2020-01-22', '2020-01-23', '2020-01-24', '2020-01-25', '2020-01-26', '2020-01-27', '2020-01-28', '2020-01-29', '2020-01-30', '2020-01-31', '2020-02-01', '2020-02-02', '2020-02-03', '2020-02-04', '2020-02-05', '2020-02-06', '2020-02-07', '2020-02-08', '2020-02-09', '2020-02-10', '2020-02-11', '2020-02-12', '2020-02-13', '2020-02-14', '2020-02-15', '2020-02-16', '2020-02-17', '2020-02-18', '2020-02-19', '2020-02-20', '2020-02-21', '2020-02-22', '2020-02-23', '2020-02-24', '2020-02-25', '2020-02-26', '2020-02-27', '2020-02-28', '2020-02-29', '2020-03-01', '2020-03-02', '2020-03-03', '2020-03-04', '2020-03-05', '2020-03-06', '2020-03-07', '2020-03-08', '2020-03-09', '2020-03-10', '2020-03-11', '2020-03-12', '2020-03-13', '2020-03-14', '2020-03-15', '2020-03-16', '2020-03-17', '2020-03-18', '2020-03-19', '2020-03-20', '2020-03-21', '2020-03-22', '2020-03-23', '2020-03-24', '2020-03-25', '2020-03-26', '2020-03-27', '2020-03-28', '2020-03-29', '2020-03-30', '2020-03-31', '2020-04-01', '2020-04-02', '2020-04-03', '2020-04-04', '2020-04-05', '2020-04-06', '2020-04-07', '2020-04-08', '2020-04-09', '2020-04-10', '2020-04-11', '2020-04-12', '2020-04-13', '2020-04-14', '2020-04-15', '2020-04-16', '2020-04-17', '2020-04-18', '2020-04-19', '2020-04-20', '2020-04-21', '2020-04-22', '2020-04-23', '2020-04-24', '2020-04-25', '2020-04-26', '2020-04-27', '2020-04-28', '2020-04-29', '2020-04-30', '2020-05-01', '2020-05-02', '2020-05-03', '2020-05-04', '2020-05-05', '2020-05-06', '2020-05-07', '2020-05-08', '2020-05-09', '2020-05-10', '2020-05-11', '2020-05-12', '2020-05-13', '2020-05-14', '2020-05-15', '2020-05-16', '2020-05-17', '2020-05-18', '2020-05-19', '2020-05-20', '2020-05-21', '2020-05-22', '2020-05-23', '2020-05-24', '2020-05-25', '2020-05-26', '2020-05-27', '2020-05-28', '2020-05-29', '2020-05-30', '2020-05-31', '2020-06-01', '2020-06-02', '2020-06-03', '2020-06-04', '2020-06-05', '2020-06-06', '2020-06-07', '2020-06-08', '2020-06-09', '2020-06-10', '2020-06-11', '2020-06-12', '2020-06-13', '2020-06-14', '2020-06-15', '2020-06-16', '2020-06-17', '2020-06-18', '2020-06-19', '2020-06-20', '2020-06-21', '2020-06-22', '2020-06-23', '2020-06-24', '2020-06-25', '2020-06-26', '2020-06-27', '2020-06-28', '2020-06-29', '2020-06-30', '2020-07-01', '2020-07-02', '2020-07-03', '2020-07-04', '2020-07-05', '2020-07-06', '2020-07-07', '2020-07-08', '2020-07-09', '2020-07-10', '2020-07-11', '2020-07-12', '2020-07-13', '2020-07-14', '2020-07-15', '2020-07-16', '2020-07-17', '2020-07-18', '2020-07-19', '2020-07-20', '2020-07-21', '2020-07-22', '2020-07-23', '2020-07-24', '2020-07-25', '2020-07-26'])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2g_price_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "4ed1cc3d-e732-4e7a-b427-5d16f7fad311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Secondary_positive_v2g_prices_chf_kwh</th>\n",
       "      <th>Secondary_negative_v2g_prices_chf_kwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 00:00:00</td>\n",
       "      <td>0.068370</td>\n",
       "      <td>0.045588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 00:15:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-01 00:30:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 00:45:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-01 01:00:00</td>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.045896</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp  Secondary_positive_v2g_prices_chf_kwh  \\\n",
       "0 2019-01-01 00:00:00                               0.068370   \n",
       "1 2019-01-01 00:15:00                               0.068838   \n",
       "2 2019-01-01 00:30:00                               0.068838   \n",
       "3 2019-01-01 00:45:00                               0.068838   \n",
       "4 2019-01-01 01:00:00                               0.068838   \n",
       "\n",
       "   Secondary_negative_v2g_prices_chf_kwh  \n",
       "0                               0.045588  \n",
       "1                               0.045896  \n",
       "2                               0.045896  \n",
       "3                               0.045896  \n",
       "4                               0.045896  "
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get v2g price data\n",
    "sql = \"\"\"SELECT \"Timestamp\", \"Secondary_positive_v2g_prices_chf_kwh\", \"Secondary_negative_v2g_prices_chf_kwh\" FROM msc_2023_dominik.v2g_prices WHERE \"Timestamp\" >=  '{}' and \"Timestamp\" <=  '{}' ORDER BY \"Timestamp\" \"\"\".format(start_date_simulation.strftime('%Y-%m-%d'), end_date_simulation.strftime('%Y-%m-%d'))\n",
    "v2g_prices = pd.read_sql(sql, engine)\n",
    "v2g_prices.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e336d8c8-67e2-4a61-b30b-71e43a1189c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in dict for fast data access\n",
    "delta = timedelta(days=1)\n",
    "v2g_price_dict_simulation = {}\n",
    "start_date_v2g = start_date_simulation\n",
    "while start_date_v2g <= end_date_simulation:\n",
    "    v2g_price_day_positive = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_positive_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_day_negative = v2g_prices[v2g_prices['Timestamp'].dt.date == pd.Timestamp(start_date_v2g).date()].drop([\"Timestamp\"],axis = 1)[\"Secondary_negative_v2g_prices_chf_kwh\"].values\n",
    "    v2g_price_dict_simulation[start_date_v2g.strftime('%Y-%m-%d')] = [v2g_price_day_positive, v2g_price_day_negative]\n",
    "    start_date_v2g += delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "efdd8077-9174-4e94-88dd-034a39c1d2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['2019-01-01', '2019-01-02', '2019-01-03', '2019-01-04', '2019-01-05', '2019-01-06', '2019-01-07', '2019-01-08'])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2g_price_dict_simulation.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd4bdff-3156-46e4-bf59-d2cc1a042ec9",
   "metadata": {},
   "source": [
    "# Check environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f88a71db-6071-422c-b45b-0ff53dd4a5aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# check if enviornment fullfils requirements of gym and stable-baselines3\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# load discrete table\u001b[39;00m\n\u001b[0;32m      4\u001b[0m sql \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM discrete.discrete_weeks_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ORDER BY vehicle_no\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_sql\u001b[49m\u001b[43m(\u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# load discrete planned reservation table\u001b[39;00m\n\u001b[0;32m      8\u001b[0m sql \u001b[38;5;241m=\u001b[39m  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM msc_2023_dominik.planned_reservations_discrete_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m ORDER BY vehicle_no\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\pandas\\io\\sql.py:590\u001b[0m, in \u001b[0;36mread_sql\u001b[1;34m(sql, con, index_col, coerce_float, params, parse_dates, columns, chunksize)\u001b[0m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pandas_sql\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[0;32m    582\u001b[0m         sql,\n\u001b[0;32m    583\u001b[0m         index_col\u001b[38;5;241m=\u001b[39mindex_col,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    587\u001b[0m         chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m    588\u001b[0m     )\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpandas_sql\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[43msql\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    594\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoerce_float\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcoerce_float\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    595\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparse_dates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparse_dates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    596\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\pandas\\io\\sql.py:1560\u001b[0m, in \u001b[0;36mSQLDatabase.read_query\u001b[1;34m(self, sql, index_col, coerce_float, parse_dates, params, chunksize, dtype)\u001b[0m\n\u001b[0;32m   1512\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1513\u001b[0m \u001b[38;5;124;03mRead SQL query into a DataFrame.\u001b[39;00m\n\u001b[0;32m   1514\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1556\u001b[0m \n\u001b[0;32m   1557\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m args \u001b[38;5;241m=\u001b[39m _convert_params(sql, params)\n\u001b[1;32m-> 1560\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1561\u001b[0m columns \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mkeys()\n\u001b[0;32m   1563\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\pandas\\io\\sql.py:1405\u001b[0m, in \u001b[0;36mSQLDatabase.execute\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1403\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1404\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Simple passthrough to SQLAlchemy connectable\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1405\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnectable\u001b[38;5;241m.\u001b[39mexecution_options()\u001b[38;5;241m.\u001b[39mexecute(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m<string>:2\u001b[0m, in \u001b[0;36mexecute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\util\\deprecations.py:402\u001b[0m, in \u001b[0;36m_decorate_with_warning.<locals>.warned\u001b[1;34m(fn, *args, **kwargs)\u001b[0m\n\u001b[0;32m    400\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_warning:\n\u001b[0;32m    401\u001b[0m     _warn_with_version(message, version, wtype, stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m--> 402\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\engine\\base.py:3176\u001b[0m, in \u001b[0;36mEngine.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   3158\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Executes the given construct and returns a\u001b[39;00m\n\u001b[0;32m   3159\u001b[0m \u001b[38;5;124;03m:class:`_engine.CursorResult`.\u001b[39;00m\n\u001b[0;32m   3160\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3173\u001b[0m \n\u001b[0;32m   3174\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   3175\u001b[0m connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect(close_with_result\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m-> 3176\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\u001b[38;5;241m.\u001b[39mexecute(statement, \u001b[38;5;241m*\u001b[39mmultiparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1291\u001b[0m, in \u001b[0;36mConnection.execute\u001b[1;34m(self, statement, *multiparams, **params)\u001b[0m\n\u001b[0;32m   1282\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(statement, util\u001b[38;5;241m.\u001b[39mstring_types):\n\u001b[0;32m   1283\u001b[0m     util\u001b[38;5;241m.\u001b[39mwarn_deprecated_20(\n\u001b[0;32m   1284\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing a string to Connection.execute() is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1285\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdeprecated and will be removed in version 2.0.  Use the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1288\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdriver-level SQL string.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1289\u001b[0m     )\n\u001b[1;32m-> 1291\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_exec_driver_sql\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1292\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmultiparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1295\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_EMPTY_EXECUTION_OPTS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1296\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfuture\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1297\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1299\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1300\u001b[0m     meth \u001b[38;5;241m=\u001b[39m statement\u001b[38;5;241m.\u001b[39m_execute_on_connection\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1595\u001b[0m, in \u001b[0;36mConnection._exec_driver_sql\u001b[1;34m(self, statement, multiparams, params, execution_options, future)\u001b[0m\n\u001b[0;32m   1585\u001b[0m         (\n\u001b[0;32m   1586\u001b[0m             statement,\n\u001b[0;32m   1587\u001b[0m             distilled_params,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1591\u001b[0m             statement, distilled_parameters, execution_options\n\u001b[0;32m   1592\u001b[0m         )\n\u001b[0;32m   1594\u001b[0m dialect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdialect\n\u001b[1;32m-> 1595\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_context\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1596\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecution_ctx_cls\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_statement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1599\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1600\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexecution_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1601\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdistilled_parameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1603\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1605\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m future:\n\u001b[0;32m   1606\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1862\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1859\u001b[0m             branched\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m   1861\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1862\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_dbapi_exception\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1863\u001b[0m \u001b[43m        \u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1864\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\engine\\base.py:2047\u001b[0m, in \u001b[0;36mConnection._handle_dbapi_exception\u001b[1;34m(self, e, statement, parameters, cursor, context)\u001b[0m\n\u001b[0;32m   2043\u001b[0m         util\u001b[38;5;241m.\u001b[39mraise_(\n\u001b[0;32m   2044\u001b[0m             sqlalchemy_exception, with_traceback\u001b[38;5;241m=\u001b[39mexc_info[\u001b[38;5;241m2\u001b[39m], from_\u001b[38;5;241m=\u001b[39me\n\u001b[0;32m   2045\u001b[0m         )\n\u001b[0;32m   2046\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2047\u001b[0m         \u001b[43mutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwith_traceback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   2050\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reentrant_error\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\util\\compat.py:208\u001b[0m, in \u001b[0;36mraise_\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    205\u001b[0m     exception\u001b[38;5;241m.\u001b[39m__cause__ \u001b[38;5;241m=\u001b[39m replace_context\n\u001b[0;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 208\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;66;03m# credit to\u001b[39;00m\n\u001b[0;32m    211\u001b[0m     \u001b[38;5;66;03m# https://cosmicpercolator.com/2016/01/13/exception-leaks-in-python-2-and-3/\u001b[39;00m\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;66;03m# as the __traceback__ object creates a cycle\u001b[39;00m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m exception, replace_context, from_, with_traceback\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\engine\\base.py:1819\u001b[0m, in \u001b[0;36mConnection._execute_context\u001b[1;34m(self, dialect, constructor, statement, parameters, execution_options, *args, **kw)\u001b[0m\n\u001b[0;32m   1817\u001b[0m                 \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m   1818\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m evt_handled:\n\u001b[1;32m-> 1819\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdialect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdo_execute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1820\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\n\u001b[0;32m   1821\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_events \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine\u001b[38;5;241m.\u001b[39m_has_events:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdispatch\u001b[38;5;241m.\u001b[39mafter_cursor_execute(\n\u001b[0;32m   1825\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1826\u001b[0m         cursor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1830\u001b[0m         context\u001b[38;5;241m.\u001b[39mexecutemany,\n\u001b[0;32m   1831\u001b[0m     )\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\sqlalchemy\\engine\\default.py:732\u001b[0m, in \u001b[0;36mDefaultDialect.do_execute\u001b[1;34m(self, cursor, statement, parameters, context)\u001b[0m\n\u001b[0;32m    731\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdo_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, cursor, statement, parameters, context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 732\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstatement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\encodings\\utf_8.py:15\u001b[0m, in \u001b[0;36mdecode\u001b[1;34m(input, errors)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m### Codec APIs\u001b[39;00m\n\u001b[0;32m     13\u001b[0m encode \u001b[38;5;241m=\u001b[39m codecs\u001b[38;5;241m.\u001b[39mutf_8_encode\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecode\u001b[39m(\u001b[38;5;28minput\u001b[39m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m codecs\u001b[38;5;241m.\u001b[39mutf_8_decode(\u001b[38;5;28minput\u001b[39m, errors, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mIncrementalEncoder\u001b[39;00m(codecs\u001b[38;5;241m.\u001b[39mIncrementalEncoder):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# check if enviornment fullfils requirements of gym and stable-baselines3\n",
    "\n",
    "# load discrete table\n",
    "sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(0)\n",
    "data = pd.read_sql(sql, engine)\n",
    "    \n",
    "# load discrete planned reservation table\n",
    "sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(0)\n",
    "planned_reservations = pd.read_sql(sql, engine)\n",
    "    \n",
    "# load discrete planned reservation duration table\n",
    "sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(0)\n",
    "planned_durations = pd.read_sql(sql, engine)\n",
    "end = time.time()\n",
    "\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "    \n",
    "count = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for week_nr in range(start_week, 1):\n",
    "    # iteration for each day\n",
    "    for day in range(98,99,96):\n",
    "        \n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = count * 96\n",
    "        \n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "            \n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "        \n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "        \n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "    \n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "        \n",
    "        # create environment\n",
    "        env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 10000, penalty_per_kwh = 0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day, RL = True)\n",
    "        \n",
    "        # check implementation \n",
    "        checker_gym(env)\n",
    "        checker_baselines3(env)\n",
    "        # count number of simulated days\n",
    "        count += 1\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c15f8c0-60b6-441a-a835-3a291ba491d1",
   "metadata": {},
   "source": [
    "# Train Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "264c2bc8-fd14-4481-921d-88eeef84a395",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check support of GPU\n",
    "stable_baselines3.common.utils.get_device(device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90b4295f-9b5b-4051-a8e0-6b5301f4968c",
   "metadata": {},
   "source": [
    "Start simulation by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3bce6a6d-ea89-4347-becd-c98a0d328e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    nr_vehicles = len(vehicles)\n",
    "    \n",
    "    global nr_iterations_simulation\n",
    "\n",
    "    # maximal simulation length\n",
    "    if nr_iterations_simulation > 577:\n",
    "        nr_iterations_simulation = 577\n",
    "        \n",
    "    total_reward = 0\n",
    "\n",
    "    count = 0\n",
    "    # iterate over weeks (for loading weekly discrete data)\n",
    "    for week_nr in range(start_week_simulation, math.ceil((start_week_simulation * 7 + nr_iterations_simulation) / 7)):\n",
    "        # load discrete car-sharing table\n",
    "        sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 15\".format(week_nr)\n",
    "        data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 15\".format(week_nr)\n",
    "        planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 15\".format(week_nr)\n",
    "        planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "\n",
    "        # iteration for each day\n",
    "        for day in range(98,676,96):\n",
    "\n",
    "            # calculate number of timesteps since first day of simulation\n",
    "            timesteps_since_start = count * 96\n",
    "\n",
    "            # all requested days are simulated\n",
    "            if count == nr_iterations:\n",
    "                break\n",
    "\n",
    "            # get date\n",
    "            date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "            date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "            # load reservations\n",
    "            reservations = reservations_dict_simulation[date_day_string]\n",
    "\n",
    "            # load electricity prices for charging\n",
    "            electricity_price = charging_costs_dict_simulation[date_day_string]\n",
    "\n",
    "            # load secondary energy prices for v2g\n",
    "            v2g_price = v2g_price_dict_simulation[date_day_string]\n",
    "\n",
    "            # select discrete data of day\n",
    "            daily_data = data.iloc[:,day-97:day-1]\n",
    "            planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "            planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "            # reset environment at beginnning of simulation\n",
    "            if count == 0:\n",
    "                environment = CarsharingEnv(stations, vehicles, planned_bookings = True, \n",
    "                                   daily_data = daily_data, reservations = reservations, electricity_price = electricity_price,\n",
    "                                    timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day, \n",
    "                                    planned_durations = planned_durations_day, random_seed_number = 42, v2g_demand_event_min = 10, v2g_demand_event_max = 10, v2g_penalty = 100, RL = True)\n",
    "                s = environment.reset()\n",
    "\n",
    "            # beginn new day without reseting environemnt \n",
    "            else:\n",
    "                environment.next_day(daily_data, reservations, electricity_price, timesteps_since_start, v2g_price, planned_reservations_day, planned_durations_day)\n",
    "                \n",
    "            # simulate day in 15 min steps\n",
    "            done = False\n",
    "            counter = 0\n",
    "            while not done:\n",
    "\n",
    "                # get your action \n",
    "                act, _states = model.predict(s)\n",
    "\n",
    "                # proceed one time step\n",
    "                s, rew, done, _ = environment.step(act)\n",
    "                \n",
    "                total_reward += rew\n",
    "\n",
    "                counter +=1\n",
    "\n",
    "            # plot summary statistics of episode (day)\n",
    "            #environment.daily_summary_statistics()\n",
    "\n",
    "            # plot summary statistic over full simulation period\n",
    "            #if count == nr_iterations - 1:\n",
    "              #  environment.episode_summary_statistics(nr_iterations)\n",
    "\n",
    "            # count number of simulated days\n",
    "            count += 1\n",
    "            \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a139451f-467d-4639-a689-9392b741e222",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'2019-01-01'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[34], line 39\u001b[0m\n\u001b[0;32m     36\u001b[0m date_day_string \u001b[38;5;241m=\u001b[39m date_day\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;66;03m# load reservations\u001b[39;00m\n\u001b[1;32m---> 39\u001b[0m reservations \u001b[38;5;241m=\u001b[39m \u001b[43mreservations_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdate_day_string\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# load electricity prices for charging\u001b[39;00m\n\u001b[0;32m     42\u001b[0m electricity_price \u001b[38;5;241m=\u001b[39m charging_costs_dict[date_day_string]\n",
      "\u001b[1;31mKeyError\u001b[0m: '2019-01-01'"
     ]
    }
   ],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "model = None\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for j in range(0,4286):\n",
    "    week_nr = random.randrange(1,80)\n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 10\".format(0)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "\n",
    "    # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 10\".format(0)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "    # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 10\".format(0)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "    counter = 0\n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "\n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = counter * 96 + week_nr*7*96\n",
    "\n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "\n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "\n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "\n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "        # reset environment at beginnning of simulation\n",
    "        if count == 0:\n",
    "\n",
    "            # create environment\n",
    "            env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 100, penalty_per_kwh = 1.0, soc_initial_low=0.0, soc_initial_high=0.0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 234, RL = True, v2g_demand_event_min = 10, v2g_demand_event_max = 10)\n",
    "\n",
    "            # create RL model\n",
    "            model = PPO(\"MlpPolicy\",env, verbose=2, gamma = 0.99,  ent_coef=0.01, stats_window_size = 1, n_epochs = 1,  learning_rate=0.000003, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "            model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 42),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(42, 42),\n",
    "                model.policy.mlp_extractor.policy_net[3]\n",
    "            )\n",
    "            model.policy.action_net =  nn.Linear(42, 30)\n",
    "            model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 42),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(42, 42),\n",
    "                model.policy.mlp_extractor.value_net[3]\n",
    "            )\n",
    "            model.policy.value_net =  nn.Linear(42, 1)\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "            model.set_logger(new_logger)\n",
    "\n",
    "            #model.policy.to(device)\n",
    "\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        else: \n",
    "            #env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                #          electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                #          planned_durations = planned_durations_day)\n",
    "            s = env.reset()\n",
    "\n",
    "\n",
    "        # learn one episode\n",
    "        model.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "\n",
    "\n",
    "        if count in range(5,30000,100):\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        count += 1\n",
    "    if count == 5000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 10000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 20000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 29990:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24660fa6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94607119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5732c48",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964afd23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371dc82c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "00860e7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(model):\n",
    "    nr_vehicles = len(vehicles)\n",
    "    \n",
    "    global nr_iterations_simulation\n",
    "\n",
    "    # maximal simulation length\n",
    "    if nr_iterations_simulation > 577:\n",
    "        nr_iterations_simulation = 577\n",
    "        \n",
    "    total_reward = 0\n",
    "\n",
    "    count = 0\n",
    "    # iterate over weeks (for loading weekly discrete data)\n",
    "    for week_nr in range(start_week_simulation, math.ceil((start_week_simulation * 7 + nr_iterations_simulation) / 7)):\n",
    "        # load discrete car-sharing table\n",
    "        sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 15\".format(week_nr)\n",
    "        data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 15\".format(week_nr)\n",
    "        planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 15\".format(week_nr)\n",
    "        planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "\n",
    "        # iteration for each day\n",
    "        for day in range(98,676,96):\n",
    "            day = 98\n",
    "            # calculate number of timesteps since first day of simulation\n",
    "            timesteps_since_start = count * 96\n",
    "\n",
    "            # all requested days are simulated\n",
    "            if count == nr_iterations:\n",
    "                break\n",
    "\n",
    "            # get date\n",
    "            date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "            date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "            # load reservations\n",
    "            reservations = reservations_dict_simulation[date_day_string]\n",
    "\n",
    "            # load electricity prices for charging\n",
    "            electricity_price = charging_costs_dict_simulation[date_day_string]\n",
    "\n",
    "            # load secondary energy prices for v2g\n",
    "            v2g_price = v2g_price_dict_simulation[date_day_string]\n",
    "\n",
    "            # select discrete data of day\n",
    "            daily_data = data.iloc[:,day-97:day-1]\n",
    "            planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "            planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "            # reset environment at beginnning of simulation\n",
    "            if count == 0:\n",
    "                environment = CarsharingEnv(stations, vehicles, planned_bookings = True, \n",
    "                                   daily_data = daily_data, reservations = reservations, electricity_price = electricity_price, soc_initial_low=0.0, soc_initial_high=0.0,\n",
    "                                    timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day, \n",
    "                                    planned_durations = planned_durations_day, penalty_per_kwh = 1.0, random_seed_number = 42, v2g_demand_event_min = 10, v2g_demand_event_max = 10, v2g_penalty = 100, RL = True)\n",
    "                s = environment.reset()\n",
    "\n",
    "            # beginn new day without reseting environemnt \n",
    "            else:\n",
    "                environment.next_day(daily_data, reservations, electricity_price, timesteps_since_start, v2g_price, planned_reservations_day, planned_durations_day)\n",
    "                s = environment.reset()\n",
    "            # simulate day in 15 min steps\n",
    "            done = False\n",
    "            counter = 0\n",
    "            while not done:\n",
    "\n",
    "                # get your action \n",
    "                act, _states = model.predict(s)\n",
    "\n",
    "                # proceed one time step\n",
    "                s, rew, done, _ = environment.step(act)\n",
    "                \n",
    "                total_reward += rew\n",
    "\n",
    "                counter +=1\n",
    "\n",
    "            # plot summary statistics of episode (day)\n",
    "            #environment.daily_summary_statistics()\n",
    "\n",
    "            # plot summary statistic over full simulation period\n",
    "            #if count == nr_iterations - 1:\n",
    "              #  environment.episode_summary_statistics(nr_iterations)\n",
    "\n",
    "            # count number of simulated days\n",
    "            count += 1\n",
    "            \n",
    "    return total_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b1090e76-935a-4516-85e5-58ca624027d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_nr_list = np.array2string(data.vehicle_no.values, separator=',')[1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3ca6ebde-50a4-45db-8846-6554f43760a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vehicle_nr_list = data.vehicle_no.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf786ec2-f0c3-4d0c-b77a-1027fec0cc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>vehicle_category</th>\n",
       "      <th>vehicle_no</th>\n",
       "      <th>model_name</th>\n",
       "      <th>brand_name</th>\n",
       "      <th>charge_power</th>\n",
       "      <th>battery_capacity</th>\n",
       "      <th>range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2962</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106516</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2963</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106517</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2964</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106518</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2965</td>\n",
       "      <td>Minivan</td>\n",
       "      <td>106519</td>\n",
       "      <td>eVito 129KB Tourer Pro 3200</td>\n",
       "      <td>Mercedes-Benz</td>\n",
       "      <td>11.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>378.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2966</td>\n",
       "      <td>Combi</td>\n",
       "      <td>106526</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>3525</td>\n",
       "      <td>Combi</td>\n",
       "      <td>113371</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3526</td>\n",
       "      <td>Combi</td>\n",
       "      <td>113372</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>3527</td>\n",
       "      <td>Combi</td>\n",
       "      <td>113375</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>3528</td>\n",
       "      <td>Combi</td>\n",
       "      <td>113379</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3529</td>\n",
       "      <td>Combi</td>\n",
       "      <td>113380</td>\n",
       "      <td>Enyaq iV80</td>\n",
       "      <td>Skoda</td>\n",
       "      <td>11.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>420.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index vehicle_category  vehicle_no                   model_name  \\\n",
       "0    2962          Minivan      106516  eVito 129KB Tourer Pro 3200   \n",
       "1    2963          Minivan      106517  eVito 129KB Tourer Pro 3200   \n",
       "2    2964          Minivan      106518  eVito 129KB Tourer Pro 3200   \n",
       "3    2965          Minivan      106519  eVito 129KB Tourer Pro 3200   \n",
       "4    2966            Combi      106526                   Enyaq iV80   \n",
       "..    ...              ...         ...                          ...   \n",
       "95   3525            Combi      113371                   Enyaq iV80   \n",
       "96   3526            Combi      113372                   Enyaq iV80   \n",
       "97   3527            Combi      113375                   Enyaq iV80   \n",
       "98   3528            Combi      113379                   Enyaq iV80   \n",
       "99   3529            Combi      113380                   Enyaq iV80   \n",
       "\n",
       "       brand_name  charge_power  battery_capacity  range  \n",
       "0   Mercedes-Benz          11.0             100.0  378.0  \n",
       "1   Mercedes-Benz          11.0             100.0  378.0  \n",
       "2   Mercedes-Benz          11.0             100.0  378.0  \n",
       "3   Mercedes-Benz          11.0             100.0  378.0  \n",
       "4           Skoda          11.0              82.0  420.0  \n",
       "..            ...           ...               ...    ...  \n",
       "95          Skoda          11.0              82.0  420.0  \n",
       "96          Skoda          11.0              82.0  420.0  \n",
       "97          Skoda          11.0              82.0  420.0  \n",
       "98          Skoda          11.0              82.0  420.0  \n",
       "99          Skoda          11.0              82.0  420.0  \n",
       "\n",
       "[100 rows x 8 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vehicles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b595348-5f14-44a4-aeb5-dafb9b8a292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "-------------------------------------\n",
    "| rollout/              |           |\n",
    "|    ep_len_mean        | 95        |\n",
    "|    ep_rew_mean        | 3.07e+03  |\n",
    "| time/                 |           |\n",
    "|    fps                | 27        |\n",
    "|    iterations         | 5         |\n",
    "|    time_elapsed       | 17        |\n",
    "|    total_timesteps    | 475       |\n",
    "| train/                |           |\n",
    "|    entropy_loss       | -101      |\n",
    "|    explained_variance | -1.41e-05 |\n",
    "|    learning_rate      | 0.0007    |\n",
    "|    n_updates          | 29        |\n",
    "|    policy_loss        | 1.28e+05  |\n",
    "|    value_loss         | 2.36e+06  |\n",
    "\n",
    "\n",
    "\n",
    "------------------------------------\n",
    "| rollout/              |          |\n",
    "|    ep_len_mean        | 95       |\n",
    "|    ep_rew_mean        | 3.2e+03  |\n",
    "| time/                 |          |\n",
    "|    fps                | 27       |\n",
    "|    iterations         | 2        |\n",
    "|    time_elapsed       | 6        |\n",
    "|    total_timesteps    | 190      |\n",
    "| train/                |          |\n",
    "|    entropy_loss       | -110     |\n",
    "|    explained_variance | 0.000124 |\n",
    "|    learning_rate      | 0.0007   |\n",
    "|    n_updates          | 1        |\n",
    "|    policy_loss        | 1.43e+05 |\n",
    "|    value_loss         | 2.49e+06 |\n",
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fb7c18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to /tmp/sb3_log/\n",
      "Validation reward:  14693.132820665942  CHF   Episodes learned:  0\n",
      "0\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.05e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -0.000556 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 98        |\n",
      "|    policy_loss        | 1.03e+04  |\n",
      "|    value_loss         | 3.9e+05   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.03e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -6.28e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 197       |\n",
      "|    policy_loss        | 1.15e+03  |\n",
      "|    value_loss         | 7.62e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.0138  |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 296      |\n",
      "|    policy_loss        | 11.3     |\n",
      "|    value_loss         | 21.1     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.03e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -1.1e-05  |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 395       |\n",
      "|    policy_loss        | -2.19e+03 |\n",
      "|    value_loss         | 1.93e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.05e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -0.000571 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 494       |\n",
      "|    policy_loss        | -49.4     |\n",
      "|    value_loss         | 70.1      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.05e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -5.29e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 593       |\n",
      "|    policy_loss        | 5.11e+03  |\n",
      "|    value_loss         | 1.23e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.06e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 5.97e-05 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 692      |\n",
      "|    policy_loss        | 2.86e+03 |\n",
      "|    value_loss         | 3.69e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.00195 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 791      |\n",
      "|    policy_loss        | 25.5     |\n",
      "|    value_loss         | 13.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -9.78e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 890       |\n",
      "|    policy_loss        | 1.5e+03   |\n",
      "|    value_loss         | 1.54e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  14392.465408696598  CHF   Episodes learned:  0\n",
      "1\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -1.14e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1048      |\n",
      "|    policy_loss        | 1.02e+04  |\n",
      "|    value_loss         | 3.89e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -7.15e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1147      |\n",
      "|    policy_loss        | 1.14e+03  |\n",
      "|    value_loss         | 7.63e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 28       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -0.00051 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 1246     |\n",
      "|    policy_loss        | -2.42    |\n",
      "|    value_loss         | 15.8     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | 1.97e-06  |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1345      |\n",
      "|    policy_loss        | -1.03e+03 |\n",
      "|    value_loss         | 5.12e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -1.86e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1444      |\n",
      "|    policy_loss        | -122      |\n",
      "|    value_loss         | 118       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -1.19e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1543      |\n",
      "|    policy_loss        | 5.09e+03  |\n",
      "|    value_loss         | 1.23e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | 1.49e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 1642     |\n",
      "|    policy_loss        | 2.82e+03 |\n",
      "|    value_loss         | 3.69e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -8.61e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1741      |\n",
      "|    policy_loss        | 25.8      |\n",
      "|    value_loss         | 12        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1840      |\n",
      "|    policy_loss        | 1.54e+03  |\n",
      "|    value_loss         | 1.44e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  14029.902862792556  CHF   Episodes learned:  1\n",
      "2\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.03e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 1998      |\n",
      "|    policy_loss        | 1e+04     |\n",
      "|    value_loss         | 3.89e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2097      |\n",
      "|    policy_loss        | 1.11e+03  |\n",
      "|    value_loss         | 7.45e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.08e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -3.96e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2196      |\n",
      "|    policy_loss        | -1.34     |\n",
      "|    value_loss         | 17.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2295     |\n",
      "|    policy_loss        | -529     |\n",
      "|    value_loss         | 1.47e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.09e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -2.98e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2394      |\n",
      "|    policy_loss        | -196      |\n",
      "|    value_loss         | 212       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.09e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2493      |\n",
      "|    policy_loss        | 5e+03     |\n",
      "|    value_loss         | 1.23e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 5.36e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 2592     |\n",
      "|    policy_loss        | 2.88e+03 |\n",
      "|    value_loss         | 3.69e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.09e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -1.63e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2691      |\n",
      "|    policy_loss        | 14.4      |\n",
      "|    value_loss         | 9.93      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.09e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2790      |\n",
      "|    policy_loss        | 1.44e+03  |\n",
      "|    value_loss         | 1.42e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  14665.272738793798  CHF   Episodes learned:  2\n",
      "3\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.03e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 2948      |\n",
      "|    policy_loss        | 9.97e+03  |\n",
      "|    value_loss         | 3.88e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3047      |\n",
      "|    policy_loss        | 1.1e+03   |\n",
      "|    value_loss         | 7.41e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -1.19e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3146      |\n",
      "|    policy_loss        | -11       |\n",
      "|    value_loss         | 17.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3245     |\n",
      "|    policy_loss        | -122     |\n",
      "|    value_loss         | 537      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16       |\n",
      "|    explained_variance | -1.19e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3344      |\n",
      "|    policy_loss        | -257      |\n",
      "|    value_loss         | 326       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.08e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 3443      |\n",
      "|    policy_loss        | 4.88e+03  |\n",
      "|    value_loss         | 1.22e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3542     |\n",
      "|    policy_loss        | 2.74e+03 |\n",
      "|    value_loss         | 3.68e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | -1.2e-05 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3641     |\n",
      "|    policy_loss        | 15.2     |\n",
      "|    value_loss         | 9.99     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3740     |\n",
      "|    policy_loss        | 1.44e+03 |\n",
      "|    value_loss         | 1.51e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  14914.278940514398  CHF   Episodes learned:  3\n",
      "4\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.11e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 98       |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3898     |\n",
      "|    policy_loss        | 9.88e+03 |\n",
      "|    value_loss         | 3.88e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 3997     |\n",
      "|    policy_loss        | 1.12e+03 |\n",
      "|    value_loss         | 7.44e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.11e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -1.01e-05 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4096      |\n",
      "|    policy_loss        | -18.7     |\n",
      "|    value_loss         | 17.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.11e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4195     |\n",
      "|    policy_loss        | -1.5e+03 |\n",
      "|    value_loss         | 1.03e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.12e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4294      |\n",
      "|    policy_loss        | -304      |\n",
      "|    value_loss         | 483       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.11e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4393     |\n",
      "|    policy_loss        | 4.9e+03  |\n",
      "|    value_loss         | 1.23e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4492     |\n",
      "|    policy_loss        | 2.81e+03 |\n",
      "|    value_loss         | 3.66e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.12e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -8.23e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4591      |\n",
      "|    policy_loss        | 14        |\n",
      "|    value_loss         | 9.33      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.12e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 82        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4690      |\n",
      "|    policy_loss        | 1.39e+03  |\n",
      "|    value_loss         | 1.5e+04   |\n",
      "-------------------------------------\n",
      "Validation reward:  14992.86799765399  CHF   Episodes learned:  4\n",
      "5\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.13e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 4848     |\n",
      "|    policy_loss        | 9.86e+03 |\n",
      "|    value_loss         | 3.88e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.13e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 4947      |\n",
      "|    policy_loss        | 1.09e+03  |\n",
      "|    value_loss         | 7.4e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.13e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -8.58e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5046      |\n",
      "|    policy_loss        | -29.1     |\n",
      "|    value_loss         | 19.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.13e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5145      |\n",
      "|    policy_loss        | -235      |\n",
      "|    value_loss         | 1.54e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.14e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -5.96e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5244      |\n",
      "|    policy_loss        | -382      |\n",
      "|    value_loss         | 678       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.13e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5343      |\n",
      "|    policy_loss        | 5.04e+03  |\n",
      "|    value_loss         | 1.21e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.13e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5442     |\n",
      "|    policy_loss        | 2.64e+03 |\n",
      "|    value_loss         | 3.66e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.14e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -9.78e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5541      |\n",
      "|    policy_loss        | -2.1      |\n",
      "|    value_loss         | 7.18      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.14e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5640     |\n",
      "|    policy_loss        | 1.41e+03 |\n",
      "|    value_loss         | 1.49e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  14712.296547834298  CHF   Episodes learned:  5\n",
      "6\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5798     |\n",
      "|    policy_loss        | 9.9e+03  |\n",
      "|    value_loss         | 3.88e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 5897     |\n",
      "|    policy_loss        | 1.06e+03 |\n",
      "|    value_loss         | 7.37e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -6.68e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 5996      |\n",
      "|    policy_loss        | -29.9     |\n",
      "|    value_loss         | 18        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 6095     |\n",
      "|    policy_loss        | 108      |\n",
      "|    value_loss         | 1.15e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -7.15e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6194      |\n",
      "|    policy_loss        | -454      |\n",
      "|    value_loss         | 919       |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6293      |\n",
      "|    policy_loss        | 4.73e+03  |\n",
      "|    value_loss         | 1.22e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 68       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 6392     |\n",
      "|    policy_loss        | 2.67e+03 |\n",
      "|    value_loss         | 3.66e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 76        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -6.08e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6491      |\n",
      "|    policy_loss        | 1.4       |\n",
      "|    value_loss         | 6.44      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 85       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 6590     |\n",
      "|    policy_loss        | 1.4e+03  |\n",
      "|    value_loss         | 1.48e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15260.741452691991  CHF   Episodes learned:  6\n",
      "7\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.16e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6748      |\n",
      "|    policy_loss        | 9.75e+03  |\n",
      "|    value_loss         | 3.86e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 6847     |\n",
      "|    policy_loss        | 1.03e+03 |\n",
      "|    value_loss         | 7.13e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16       |\n",
      "|    explained_variance | -6.68e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 6946      |\n",
      "|    policy_loss        | -27.2     |\n",
      "|    value_loss         | 16.4      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7045     |\n",
      "|    policy_loss        | -779     |\n",
      "|    value_loss         | 3.86e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.5     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7144      |\n",
      "|    policy_loss        | -525      |\n",
      "|    value_loss         | 1.16e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7243     |\n",
      "|    policy_loss        | 4.66e+03 |\n",
      "|    value_loss         | 1.22e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7342     |\n",
      "|    policy_loss        | 2.78e+03 |\n",
      "|    value_loss         | 3.66e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -3.34e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7441      |\n",
      "|    policy_loss        | 4.46      |\n",
      "|    value_loss         | 7.61      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 98        |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 90        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7540      |\n",
      "|    policy_loss        | 1.42e+03  |\n",
      "|    value_loss         | 1.48e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15127.496712060434  CHF   Episodes learned:  7\n",
      "8\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 80       |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 12       |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7698     |\n",
      "|    policy_loss        | 9.65e+03 |\n",
      "|    value_loss         | 3.87e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 83       |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 23       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 7797     |\n",
      "|    policy_loss        | 1.03e+03 |\n",
      "|    value_loss         | 7.37e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 83        |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -4.89e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7896      |\n",
      "|    policy_loss        | -31.9     |\n",
      "|    value_loss         | 17.3      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 83        |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15       |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 7995      |\n",
      "|    policy_loss        | -760      |\n",
      "|    value_loss         | 3.19e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 84        |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 58        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15       |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8094      |\n",
      "|    policy_loss        | -566      |\n",
      "|    value_loss         | 1.45e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.19e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 84       |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8193     |\n",
      "|    policy_loss        | 4.62e+03 |\n",
      "|    value_loss         | 1.21e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.19e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 85       |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.1    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8292     |\n",
      "|    policy_loss        | 2.73e+03 |\n",
      "|    value_loss         | 3.69e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 85        |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 92        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -4.41e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8391      |\n",
      "|    policy_loss        | -16.5     |\n",
      "|    value_loss         | 7.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 85        |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 103       |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8490      |\n",
      "|    policy_loss        | 1.36e+03  |\n",
      "|    value_loss         | 1.48e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15742.365898151667  CHF   Episodes learned:  8\n",
      "9\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 10       |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8648     |\n",
      "|    policy_loss        | 1.01e+04 |\n",
      "|    value_loss         | 3.87e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 88        |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 22        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8747      |\n",
      "|    policy_loss        | 1.02e+03  |\n",
      "|    value_loss         | 7.17e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 88        |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 33        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -2.74e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 8846      |\n",
      "|    policy_loss        | -39.1     |\n",
      "|    value_loss         | 19.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 8945     |\n",
      "|    policy_loss        | -4.4     |\n",
      "|    value_loss         | 610      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 90        |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.6     |\n",
      "|    explained_variance | -5.96e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9044      |\n",
      "|    policy_loss        | -653      |\n",
      "|    value_loss         | 1.77e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 90        |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9143      |\n",
      "|    policy_loss        | 4.99e+03  |\n",
      "|    value_loss         | 1.21e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 90       |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9242     |\n",
      "|    policy_loss        | 2.5e+03  |\n",
      "|    value_loss         | 3.65e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 89        |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 88        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -2.62e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9341      |\n",
      "|    policy_loss        | -6.03     |\n",
      "|    value_loss         | 6.3       |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 99       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9440     |\n",
      "|    policy_loss        | 1.33e+03 |\n",
      "|    value_loss         | 1.47e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15562.809202152861  CHF   Episodes learned:  9\n",
      "10\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 89       |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 11       |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9598     |\n",
      "|    policy_loss        | 9.6e+03  |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 92       |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 21       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9697     |\n",
      "|    policy_loss        | 1.09e+03 |\n",
      "|    value_loss         | 7.31e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 93        |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 31        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -3.93e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9796      |\n",
      "|    policy_loss        | -32       |\n",
      "|    value_loss         | 17.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 92        |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 42        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 9895      |\n",
      "|    policy_loss        | 607       |\n",
      "|    value_loss         | 3.03e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 94       |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 9994     |\n",
      "|    policy_loss        | -712     |\n",
      "|    value_loss         | 2.15e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 95       |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 10093    |\n",
      "|    policy_loss        | 5e+03    |\n",
      "|    value_loss         | 1.21e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 96       |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 10192    |\n",
      "|    policy_loss        | 2.62e+03 |\n",
      "|    value_loss         | 3.62e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 81        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -3.93e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 10291     |\n",
      "|    policy_loss        | -18       |\n",
      "|    value_loss         | 6.18      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 97        |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 91        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 10390     |\n",
      "|    policy_loss        | 1.27e+03  |\n",
      "|    value_loss         | 1.47e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15637.628801784094  CHF   Episodes learned:  10\n",
      "11\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 10548    |\n",
      "|    policy_loss        | 9.44e+03 |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 10647    |\n",
      "|    policy_loss        | 1.01e+03 |\n",
      "|    value_loss         | 7.2e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.4    |\n",
      "|    explained_variance | -3.1e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 10746    |\n",
      "|    policy_loss        | -50      |\n",
      "|    value_loss         | 22.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 10845    |\n",
      "|    policy_loss        | 510      |\n",
      "|    value_loss         | 2.19e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 10944     |\n",
      "|    policy_loss        | -721      |\n",
      "|    value_loss         | 2.49e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 11043     |\n",
      "|    policy_loss        | 4.51e+03  |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 11142    |\n",
      "|    policy_loss        | 2.64e+03 |\n",
      "|    value_loss         | 3.64e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 11241     |\n",
      "|    policy_loss        | -21.5     |\n",
      "|    value_loss         | 7.91      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 11340     |\n",
      "|    policy_loss        | 1.14e+03  |\n",
      "|    value_loss         | 1.47e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15596.966455426556  CHF   Episodes learned:  11\n",
      "12\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.1    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 11498    |\n",
      "|    policy_loss        | 9.56e+03 |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.9    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 11597    |\n",
      "|    policy_loss        | 857      |\n",
      "|    value_loss         | 7.2e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -2.86e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 11696     |\n",
      "|    policy_loss        | -43.2     |\n",
      "|    value_loss         | 19.1      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 39       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.2    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 11795    |\n",
      "|    policy_loss        | 191      |\n",
      "|    value_loss         | 2e+03    |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 49       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 11894    |\n",
      "|    policy_loss        | -656     |\n",
      "|    value_loss         | 2.86e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 59        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 11993     |\n",
      "|    policy_loss        | 4.17e+03  |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 12092    |\n",
      "|    policy_loss        | 2.28e+03 |\n",
      "|    value_loss         | 3.65e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.6     |\n",
      "|    explained_variance | -2.38e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 12191     |\n",
      "|    policy_loss        | -26.1     |\n",
      "|    value_loss         | 7.57      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 87       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 12290    |\n",
      "|    policy_loss        | 1.28e+03 |\n",
      "|    value_loss         | 1.12e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15762.252307804798  CHF   Episodes learned:  12\n",
      "13\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 12448    |\n",
      "|    policy_loss        | 8.86e+03 |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 12547    |\n",
      "|    policy_loss        | 997      |\n",
      "|    value_loss         | 7.13e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.4     |\n",
      "|    explained_variance | -2.74e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 12646     |\n",
      "|    policy_loss        | -51.1     |\n",
      "|    value_loss         | 22.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 12745    |\n",
      "|    policy_loss        | 209      |\n",
      "|    value_loss         | 2.02e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 47       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.8    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 12844    |\n",
      "|    policy_loss        | -777     |\n",
      "|    value_loss         | 3.27e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 12943    |\n",
      "|    policy_loss        | 4.48e+03 |\n",
      "|    value_loss         | 1.2e+05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 13042    |\n",
      "|    policy_loss        | 2.32e+03 |\n",
      "|    value_loss         | 3.63e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -2.03e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 13141     |\n",
      "|    policy_loss        | -29.3     |\n",
      "|    value_loss         | 9.48      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 13240    |\n",
      "|    policy_loss        | 1.13e+03 |\n",
      "|    value_loss         | 1.47e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15309.470554904026  CHF   Episodes learned:  13\n",
      "14\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 13398    |\n",
      "|    policy_loss        | 9.29e+03 |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 13497     |\n",
      "|    policy_loss        | 871       |\n",
      "|    value_loss         | 7.11e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -2.03e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 13596     |\n",
      "|    policy_loss        | -51.9     |\n",
      "|    value_loss         | 24        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 13695    |\n",
      "|    policy_loss        | -957     |\n",
      "|    value_loss         | 5.8e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 13794    |\n",
      "|    policy_loss        | -733     |\n",
      "|    value_loss         | 3.68e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 13893     |\n",
      "|    policy_loss        | 4.42e+03  |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.3    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 13992    |\n",
      "|    policy_loss        | 2.35e+03 |\n",
      "|    value_loss         | 3.63e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -7.15e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 14091     |\n",
      "|    policy_loss        | -24.7     |\n",
      "|    value_loss         | 7.84      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 14190    |\n",
      "|    policy_loss        | 1.18e+03 |\n",
      "|    value_loss         | 1.37e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15491.587023955723  CHF   Episodes learned:  14\n",
      "15\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 14348    |\n",
      "|    policy_loss        | 8.48e+03 |\n",
      "|    value_loss         | 3.84e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 14447     |\n",
      "|    policy_loss        | 833       |\n",
      "|    value_loss         | 7.11e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.16e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -1.79e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 14546     |\n",
      "|    policy_loss        | -61.6     |\n",
      "|    value_loss         | 27.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 14645    |\n",
      "|    policy_loss        | 317      |\n",
      "|    value_loss         | 2.41e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 14744    |\n",
      "|    policy_loss        | -833     |\n",
      "|    value_loss         | 4.12e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 14843    |\n",
      "|    policy_loss        | 3.93e+03 |\n",
      "|    value_loss         | 1.19e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 14942    |\n",
      "|    policy_loss        | 2.24e+03 |\n",
      "|    value_loss         | 3.64e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 15041    |\n",
      "|    policy_loss        | -26.7    |\n",
      "|    value_loss         | 8.33     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 15140    |\n",
      "|    policy_loss        | 1.07e+03 |\n",
      "|    value_loss         | 1.45e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15537.21135139839  CHF   Episodes learned:  15\n",
      "16\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 15298    |\n",
      "|    policy_loss        | 9.85e+03 |\n",
      "|    value_loss         | 3.84e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 15397     |\n",
      "|    policy_loss        | 778       |\n",
      "|    value_loss         | 7.01e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -1.55e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 15496     |\n",
      "|    policy_loss        | -69.2     |\n",
      "|    value_loss         | 31        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 15595    |\n",
      "|    policy_loss        | 415      |\n",
      "|    value_loss         | 2.7e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 15694    |\n",
      "|    policy_loss        | -814     |\n",
      "|    value_loss         | 4.56e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 15793     |\n",
      "|    policy_loss        | 4.61e+03  |\n",
      "|    value_loss         | 1.19e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 15892    |\n",
      "|    policy_loss        | 2.27e+03 |\n",
      "|    value_loss         | 3.58e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 4.17e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 15991    |\n",
      "|    policy_loss        | -27      |\n",
      "|    value_loss         | 8.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 16090     |\n",
      "|    policy_loss        | 1.16e+03  |\n",
      "|    value_loss         | 1.43e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15845.403538929975  CHF   Episodes learned:  16\n",
      "17\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 16248    |\n",
      "|    policy_loss        | 9.97e+03 |\n",
      "|    value_loss         | 3.84e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 16347    |\n",
      "|    policy_loss        | 811      |\n",
      "|    value_loss         | 6.7e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -9.54e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 16446     |\n",
      "|    policy_loss        | -50.5     |\n",
      "|    value_loss         | 22.2      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 16545    |\n",
      "|    policy_loss        | 393      |\n",
      "|    value_loss         | 1.96e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.7     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 16644     |\n",
      "|    policy_loss        | -940      |\n",
      "|    value_loss         | 5.23e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 16743     |\n",
      "|    policy_loss        | 5e+03     |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 16842    |\n",
      "|    policy_loss        | 2.19e+03 |\n",
      "|    value_loss         | 3.56e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 73        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -9.54e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 16941     |\n",
      "|    policy_loss        | -31.3     |\n",
      "|    value_loss         | 9.13      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 83        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 17040     |\n",
      "|    policy_loss        | 1.24e+03  |\n",
      "|    value_loss         | 1.4e+04   |\n",
      "-------------------------------------\n",
      "Validation reward:  15385.776057109655  CHF   Episodes learned:  17\n",
      "18\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 17198     |\n",
      "|    policy_loss        | 9.88e+03  |\n",
      "|    value_loss         | 3.85e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 17297    |\n",
      "|    policy_loss        | 791      |\n",
      "|    value_loss         | 6.48e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -1.19e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 17396     |\n",
      "|    policy_loss        | -38.5     |\n",
      "|    value_loss         | 20        |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 17495    |\n",
      "|    policy_loss        | -24.6    |\n",
      "|    value_loss         | 593      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.6     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 17594     |\n",
      "|    policy_loss        | -1.04e+03 |\n",
      "|    value_loss         | 5.84e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 17693    |\n",
      "|    policy_loss        | 5.11e+03 |\n",
      "|    value_loss         | 1.2e+05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 17792    |\n",
      "|    policy_loss        | 2.29e+03 |\n",
      "|    value_loss         | 3.46e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -2.15e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 17891     |\n",
      "|    policy_loss        | -29.1     |\n",
      "|    value_loss         | 8.68      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 17990    |\n",
      "|    policy_loss        | 1.12e+03 |\n",
      "|    value_loss         | 1.39e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15759.125785716342  CHF   Episodes learned:  18\n",
      "19\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 18148    |\n",
      "|    policy_loss        | 9.64e+03 |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 18247    |\n",
      "|    policy_loss        | 821      |\n",
      "|    value_loss         | 6.91e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -1.91e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 18346     |\n",
      "|    policy_loss        | -45.3     |\n",
      "|    value_loss         | 21.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 18445    |\n",
      "|    policy_loss        | 564      |\n",
      "|    value_loss         | 3.85e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 18544     |\n",
      "|    policy_loss        | -1.08e+03 |\n",
      "|    value_loss         | 6.34e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 18643     |\n",
      "|    policy_loss        | 5.01e+03  |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 18742    |\n",
      "|    policy_loss        | 2.19e+03 |\n",
      "|    value_loss         | 3.55e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.3    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 18841    |\n",
      "|    policy_loss        | -33.2    |\n",
      "|    value_loss         | 9.4      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 18940     |\n",
      "|    policy_loss        | 1.16e+03  |\n",
      "|    value_loss         | 1.39e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15823.960374933655  CHF   Episodes learned:  19\n",
      "20\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.2    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 19098    |\n",
      "|    policy_loss        | 9.75e+03 |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.4     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 19197     |\n",
      "|    policy_loss        | 858       |\n",
      "|    value_loss         | 6.47e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 27        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 19296     |\n",
      "|    policy_loss        | -53.2     |\n",
      "|    value_loss         | 23.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.6    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 19395    |\n",
      "|    policy_loss        | 652      |\n",
      "|    value_loss         | 3.84e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 19494     |\n",
      "|    policy_loss        | -1.02e+03 |\n",
      "|    value_loss         | 6.85e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 19593    |\n",
      "|    policy_loss        | 4.99e+03 |\n",
      "|    value_loss         | 1.2e+05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 19692    |\n",
      "|    policy_loss        | 2.33e+03 |\n",
      "|    value_loss         | 3.49e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 72        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.3     |\n",
      "|    explained_variance | -3.22e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 19791     |\n",
      "|    policy_loss        | -33.7     |\n",
      "|    value_loss         | 9.74      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 19890    |\n",
      "|    policy_loss        | 1.25e+03 |\n",
      "|    value_loss         | 1.4e+04  |\n",
      "------------------------------------\n",
      "Validation reward:  15423.272285004874  CHF   Episodes learned:  20\n",
      "21\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 20048    |\n",
      "|    policy_loss        | 9.53e+03 |\n",
      "|    value_loss         | 3.85e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.16e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 20147    |\n",
      "|    policy_loss        | 944      |\n",
      "|    value_loss         | 6.48e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.5     |\n",
      "|    explained_variance | -1.19e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 20246     |\n",
      "|    policy_loss        | -52.9     |\n",
      "|    value_loss         | 24.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16       |\n",
      "|    explained_variance | 5.96e-08  |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 20345     |\n",
      "|    policy_loss        | -1.39e+03 |\n",
      "|    value_loss         | 8.51e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 20444     |\n",
      "|    policy_loss        | -1.14e+03 |\n",
      "|    value_loss         | 7.65e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 20543    |\n",
      "|    policy_loss        | 4.8e+03  |\n",
      "|    value_loss         | 1.2e+05  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 20642     |\n",
      "|    policy_loss        | 2.35e+03  |\n",
      "|    value_loss         | 3.49e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 70        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.9     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 20741     |\n",
      "|    policy_loss        | -36.2     |\n",
      "|    value_loss         | 10.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 20840    |\n",
      "|    policy_loss        | 1.22e+03 |\n",
      "|    value_loss         | 1.37e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15742.854033421907  CHF   Episodes learned:  21\n",
      "22\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 20998     |\n",
      "|    policy_loss        | 9.58e+03  |\n",
      "|    value_loss         | 3.85e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.19e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15      |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 21097    |\n",
      "|    policy_loss        | 970      |\n",
      "|    value_loss         | 6.55e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.21e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.4     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 21196     |\n",
      "|    policy_loss        | -63.9     |\n",
      "|    value_loss         | 26.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 21295    |\n",
      "|    policy_loss        | 487      |\n",
      "|    value_loss         | 2.6e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 43        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.8     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 21394     |\n",
      "|    policy_loss        | -1.31e+03 |\n",
      "|    value_loss         | 8.33e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 21493     |\n",
      "|    policy_loss        | 4.81e+03  |\n",
      "|    value_loss         | 1.2e+05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 21592    |\n",
      "|    policy_loss        | 2.6e+03  |\n",
      "|    value_loss         | 3.41e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 69       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.4    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 21691    |\n",
      "|    policy_loss        | -27.8    |\n",
      "|    value_loss         | 8.66     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 78        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 21790     |\n",
      "|    policy_loss        | 1.42e+03  |\n",
      "|    value_loss         | 1.4e+04   |\n",
      "-------------------------------------\n",
      "Validation reward:  15678.702961427225  CHF   Episodes learned:  22\n",
      "23\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 21948    |\n",
      "|    policy_loss        | 9.8e+03  |\n",
      "|    value_loss         | 3.84e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 22047    |\n",
      "|    policy_loss        | 983      |\n",
      "|    value_loss         | 6.45e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.1     |\n",
      "|    explained_variance | -1.31e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 22146     |\n",
      "|    policy_loss        | -51.6     |\n",
      "|    value_loss         | 23.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 22245    |\n",
      "|    policy_loss        | 515      |\n",
      "|    value_loss         | 2.54e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.7     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 22344     |\n",
      "|    policy_loss        | -1.24e+03 |\n",
      "|    value_loss         | 9.07e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 22443    |\n",
      "|    policy_loss        | 4.84e+03 |\n",
      "|    value_loss         | 1.2e+05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.5    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 22542    |\n",
      "|    policy_loss        | 2.52e+03 |\n",
      "|    value_loss         | 3.45e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 74        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.5     |\n",
      "|    explained_variance | -2.15e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 22641     |\n",
      "|    policy_loss        | -34.8     |\n",
      "|    value_loss         | 10        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 22740     |\n",
      "|    policy_loss        | 1.3e+03   |\n",
      "|    value_loss         | 1.39e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15713.834795193485  CHF   Episodes learned:  23\n",
      "24\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 22898    |\n",
      "|    policy_loss        | 9.23e+03 |\n",
      "|    value_loss         | 3.84e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 22997    |\n",
      "|    policy_loss        | 878      |\n",
      "|    value_loss         | 6.35e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 29        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 23096     |\n",
      "|    policy_loss        | -56.9     |\n",
      "|    value_loss         | 26.2      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 99        |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 39        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 23195     |\n",
      "|    policy_loss        | 545       |\n",
      "|    value_loss         | 3.73e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 101       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 23294     |\n",
      "|    policy_loss        | -1.23e+03 |\n",
      "|    value_loss         | 9.62e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -16.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 23393     |\n",
      "|    policy_loss        | 4.87e+03  |\n",
      "|    value_loss         | 1.19e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.2    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 23492    |\n",
      "|    policy_loss        | 2.25e+03 |\n",
      "|    value_loss         | 3.48e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 23591    |\n",
      "|    policy_loss        | -50.8    |\n",
      "|    value_loss         | 14.2     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 84        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 23690     |\n",
      "|    policy_loss        | 1.31e+03  |\n",
      "|    value_loss         | 1.35e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15516.304258354949  CHF   Episodes learned:  24\n",
      "25\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.22e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 9         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 23848     |\n",
      "|    policy_loss        | 9.95e+03  |\n",
      "|    value_loss         | 3.83e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 23947    |\n",
      "|    policy_loss        | 866      |\n",
      "|    value_loss         | 6.32e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.8     |\n",
      "|    explained_variance | -1.67e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 24046     |\n",
      "|    policy_loss        | -55.6     |\n",
      "|    value_loss         | 25.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 24145    |\n",
      "|    policy_loss        | 153      |\n",
      "|    value_loss         | 1.24e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.1     |\n",
      "|    explained_variance | -5.96e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 24244     |\n",
      "|    policy_loss        | -1.09e+03 |\n",
      "|    value_loss         | 1.02e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 24343    |\n",
      "|    policy_loss        | 4.97e+03 |\n",
      "|    value_loss         | 1.19e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 24442     |\n",
      "|    policy_loss        | 2.14e+03  |\n",
      "|    value_loss         | 3.46e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 24541    |\n",
      "|    policy_loss        | -45.2    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 24640    |\n",
      "|    policy_loss        | 1.07e+03 |\n",
      "|    value_loss         | 1.35e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15661.057827895862  CHF   Episodes learned:  25\n",
      "26\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 115       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 24798     |\n",
      "|    policy_loss        | 1.01e+04  |\n",
      "|    value_loss         | 3.83e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 24897    |\n",
      "|    policy_loss        | 733      |\n",
      "|    value_loss         | 6.17e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.5     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 24996     |\n",
      "|    policy_loss        | -42.9     |\n",
      "|    value_loss         | 22.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.6     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 25095     |\n",
      "|    policy_loss        | 640       |\n",
      "|    value_loss         | 3.73e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.5     |\n",
      "|    explained_variance | -9.54e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 25194     |\n",
      "|    policy_loss        | -1.28e+03 |\n",
      "|    value_loss         | 1.12e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 25293    |\n",
      "|    policy_loss        | 4.92e+03 |\n",
      "|    value_loss         | 1.19e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 25392     |\n",
      "|    policy_loss        | 2.05e+03  |\n",
      "|    value_loss         | 3.44e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 5.96e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 25491    |\n",
      "|    policy_loss        | -49.8    |\n",
      "|    value_loss         | 15.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 25590    |\n",
      "|    policy_loss        | 943      |\n",
      "|    value_loss         | 1.34e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15895.565439622991  CHF   Episodes learned:  26\n",
      "27\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -16      |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 25748    |\n",
      "|    policy_loss        | 9.43e+03 |\n",
      "|    value_loss         | 3.83e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 114       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.7     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 25847     |\n",
      "|    policy_loss        | 857       |\n",
      "|    value_loss         | 6.37e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.3    |\n",
      "|    explained_variance | 4.77e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 25946    |\n",
      "|    policy_loss        | -73.6    |\n",
      "|    value_loss         | 32.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 26045    |\n",
      "|    policy_loss        | 603      |\n",
      "|    value_loss         | 3.66e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 26144    |\n",
      "|    policy_loss        | -1.4e+03 |\n",
      "|    value_loss         | 1.2e+04  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 52        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 26243     |\n",
      "|    policy_loss        | 4.89e+03  |\n",
      "|    value_loss         | 1.19e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.2    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 26342    |\n",
      "|    policy_loss        | 2.22e+03 |\n",
      "|    value_loss         | 3.41e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 8.34e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 26441    |\n",
      "|    policy_loss        | -41.9    |\n",
      "|    value_loss         | 13       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 26540    |\n",
      "|    policy_loss        | 1.16e+03 |\n",
      "|    value_loss         | 1.34e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15741.727173449097  CHF   Episodes learned:  27\n",
      "28\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 26698    |\n",
      "|    policy_loss        | 1e+04    |\n",
      "|    value_loss         | 3.83e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 26797     |\n",
      "|    policy_loss        | 832       |\n",
      "|    value_loss         | 6.31e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.6     |\n",
      "|    explained_variance | -1.79e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 26896     |\n",
      "|    policy_loss        | -55.1     |\n",
      "|    value_loss         | 27.8      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | 1.79e-07  |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 26995     |\n",
      "|    policy_loss        | -1.03e+03 |\n",
      "|    value_loss         | 5.7e+03   |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 27094     |\n",
      "|    policy_loss        | -1.52e+03 |\n",
      "|    value_loss         | 1.3e+04   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 27193    |\n",
      "|    policy_loss        | 4.73e+03 |\n",
      "|    value_loss         | 1.19e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 65        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.1     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 27292     |\n",
      "|    policy_loss        | 2.06e+03  |\n",
      "|    value_loss         | 3.39e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.3    |\n",
      "|    explained_variance | 1.37e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 27391    |\n",
      "|    policy_loss        | -50.8    |\n",
      "|    value_loss         | 16.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.8    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 27490    |\n",
      "|    policy_loss        | 1.18e+03 |\n",
      "|    value_loss         | 1.34e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15837.513996773148  CHF   Episodes learned:  28\n",
      "29\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.8     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 27648     |\n",
      "|    policy_loss        | 9.27e+03  |\n",
      "|    value_loss         | 3.83e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 18        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 27747     |\n",
      "|    policy_loss        | 707       |\n",
      "|    value_loss         | 6.34e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.2     |\n",
      "|    explained_variance | -1.43e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 27846     |\n",
      "|    policy_loss        | -71.2     |\n",
      "|    value_loss         | 32.3      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.3    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 27945    |\n",
      "|    policy_loss        | 466      |\n",
      "|    value_loss         | 2.58e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.8     |\n",
      "|    explained_variance | -1.31e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 28044     |\n",
      "|    policy_loss        | -1.39e+03 |\n",
      "|    value_loss         | 1.35e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -13.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 28143     |\n",
      "|    policy_loss        | 3.86e+03  |\n",
      "|    value_loss         | 1.18e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 63        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 28242     |\n",
      "|    policy_loss        | 1.92e+03  |\n",
      "|    value_loss         | 3.46e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 1.73e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 28341    |\n",
      "|    policy_loss        | -60.3    |\n",
      "|    value_loss         | 20.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 28440     |\n",
      "|    policy_loss        | 905       |\n",
      "|    value_loss         | 1.36e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15921.491684364522  CHF   Episodes learned:  29\n",
      "30\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 28598    |\n",
      "|    policy_loss        | 9.69e+03 |\n",
      "|    value_loss         | 3.82e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 28697    |\n",
      "|    policy_loss        | 614      |\n",
      "|    value_loss         | 6.62e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.7    |\n",
      "|    explained_variance | 3.58e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 28796    |\n",
      "|    policy_loss        | -62.4    |\n",
      "|    value_loss         | 32.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.7     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 28895     |\n",
      "|    policy_loss        | 466       |\n",
      "|    value_loss         | 3.52e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.6     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 28994     |\n",
      "|    policy_loss        | -1.34e+03 |\n",
      "|    value_loss         | 1.41e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 29093     |\n",
      "|    policy_loss        | 4.38e+03  |\n",
      "|    value_loss         | 1.17e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 29192    |\n",
      "|    policy_loss        | 1.74e+03 |\n",
      "|    value_loss         | 3.47e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 792       |\n",
      "|    time_elapsed       | 71        |\n",
      "|    total_timesteps    | 7920      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 29291     |\n",
      "|    policy_loss        | -52.8     |\n",
      "|    value_loss         | 17.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -11      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 29390    |\n",
      "|    policy_loss        | 752      |\n",
      "|    value_loss         | 1.35e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15913.643507062721  CHF   Episodes learned:  30\n",
      "31\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.28e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.7     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 29548     |\n",
      "|    policy_loss        | 9.66e+03  |\n",
      "|    value_loss         | 3.81e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.28e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 29647    |\n",
      "|    policy_loss        | 663      |\n",
      "|    value_loss         | 6.14e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.28e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.1     |\n",
      "|    explained_variance | -1.19e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 29746     |\n",
      "|    policy_loss        | -71       |\n",
      "|    value_loss         | 36.6      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.8    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 29845    |\n",
      "|    policy_loss        | 626      |\n",
      "|    value_loss         | 3.55e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.5     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 29944     |\n",
      "|    policy_loss        | -1.22e+03 |\n",
      "|    value_loss         | 1.5e+04   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.4    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 30043    |\n",
      "|    policy_loss        | 4.9e+03  |\n",
      "|    value_loss         | 1.18e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 61        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11       |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 30142     |\n",
      "|    policy_loss        | 1.67e+03  |\n",
      "|    value_loss         | 3.43e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 3.64e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 30241    |\n",
      "|    policy_loss        | -79.3    |\n",
      "|    value_loss         | 29.6     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.27e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 79        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.4     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 30340     |\n",
      "|    policy_loss        | 1.12e+03  |\n",
      "|    value_loss         | 1.28e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15888.002944921234  CHF   Episodes learned:  31\n",
      "32\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 30498    |\n",
      "|    policy_loss        | 9.1e+03  |\n",
      "|    value_loss         | 3.81e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.5     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 30597     |\n",
      "|    policy_loss        | 668       |\n",
      "|    value_loss         | 6.43e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 8.94e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 30696    |\n",
      "|    policy_loss        | -73.5    |\n",
      "|    value_loss         | 34.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 30795    |\n",
      "|    policy_loss        | 39.1     |\n",
      "|    value_loss         | 1.12e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.6     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 30894     |\n",
      "|    policy_loss        | -1.27e+03 |\n",
      "|    value_loss         | 1.58e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.8     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 30993     |\n",
      "|    policy_loss        | 3.8e+03   |\n",
      "|    value_loss         | 1.17e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 31092    |\n",
      "|    policy_loss        | 1.66e+03 |\n",
      "|    value_loss         | 3.48e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 1.61e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 31191    |\n",
      "|    policy_loss        | -65.7    |\n",
      "|    value_loss         | 24       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.9    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 31290    |\n",
      "|    policy_loss        | 872      |\n",
      "|    value_loss         | 1.36e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15870.826616177332  CHF   Episodes learned:  32\n",
      "33\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.25e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 8         |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.8     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 31448     |\n",
      "|    policy_loss        | 9.49e+03  |\n",
      "|    value_loss         | 3.8e+05   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -11.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 31547    |\n",
      "|    policy_loss        | 749      |\n",
      "|    value_loss         | 6.4e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.1     |\n",
      "|    explained_variance | -2.38e-06 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 31646     |\n",
      "|    policy_loss        | -74.4     |\n",
      "|    value_loss         | 38.7      |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -10.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 31745     |\n",
      "|    policy_loss        | 443       |\n",
      "|    value_loss         | 3.54e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 44       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.94    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 31844    |\n",
      "|    policy_loss        | -1.6e+03 |\n",
      "|    value_loss         | 1.66e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 53        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -12.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 31943     |\n",
      "|    policy_loss        | 4.13e+03  |\n",
      "|    value_loss         | 1.17e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.65    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 32042    |\n",
      "|    policy_loss        | 1.68e+03 |\n",
      "|    value_loss         | 3.46e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 5.96e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 32141    |\n",
      "|    policy_loss        | -64.2    |\n",
      "|    value_loss         | 23.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.22    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 32240    |\n",
      "|    policy_loss        | 718      |\n",
      "|    value_loss         | 1.16e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  14782.121452210185  CHF   Episodes learned:  33\n",
      "34\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 114      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 32398    |\n",
      "|    policy_loss        | 8.13e+03 |\n",
      "|    value_loss         | 3.79e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.08e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.13     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 32497     |\n",
      "|    policy_loss        | 603       |\n",
      "|    value_loss         | 6.52e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.6     |\n",
      "|    explained_variance | -4.77e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 32596     |\n",
      "|    policy_loss        | -107      |\n",
      "|    value_loss         | 58        |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.06e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.25     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 32695     |\n",
      "|    policy_loss        | 120       |\n",
      "|    value_loss         | 1.56e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.04     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 32794     |\n",
      "|    policy_loss        | -1.22e+03 |\n",
      "|    value_loss         | 1.73e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.2    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 32893    |\n",
      "|    policy_loss        | 3e+03    |\n",
      "|    value_loss         | 1.17e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 62        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.07     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 32992     |\n",
      "|    policy_loss        | 1.7e+03   |\n",
      "|    value_loss         | 3.45e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.5    |\n",
      "|    explained_variance | 2.5e-06  |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 33091    |\n",
      "|    policy_loss        | -78.1    |\n",
      "|    value_loss         | 43       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.3     |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 33190    |\n",
      "|    policy_loss        | 751      |\n",
      "|    value_loss         | 1.35e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15198.364323529682  CHF   Episodes learned:  34\n",
      "35\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.6    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 33348    |\n",
      "|    policy_loss        | 6.5e+03  |\n",
      "|    value_loss         | 3.79e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.07e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 33447    |\n",
      "|    policy_loss        | 524      |\n",
      "|    value_loss         | 6.49e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.2    |\n",
      "|    explained_variance | 1.07e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 33546    |\n",
      "|    policy_loss        | -100     |\n",
      "|    value_loss         | 60.3     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.02e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 108       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 36        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.5      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 33645     |\n",
      "|    policy_loss        | -1.18e+03 |\n",
      "|    value_loss         | 2.03e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.01e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 107       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.6      |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 33744     |\n",
      "|    policy_loss        | -1.16e+03 |\n",
      "|    value_loss         | 1.79e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 56       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.62    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 33843    |\n",
      "|    policy_loss        | 2.6e+03  |\n",
      "|    value_loss         | 1.16e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.56    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 33942    |\n",
      "|    policy_loss        | 1.69e+03 |\n",
      "|    value_loss         | 3.48e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 76       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.5    |\n",
      "|    explained_variance | 2.38e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 34041    |\n",
      "|    policy_loss        | -69.9    |\n",
      "|    value_loss         | 52.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 86       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.54    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 34140    |\n",
      "|    policy_loss        | 739      |\n",
      "|    value_loss         | 1.17e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  13825.711336456998  CHF   Episodes learned:  35\n",
      "36\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.14e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 103      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 34298    |\n",
      "|    policy_loss        | 8.72e+03 |\n",
      "|    value_loss         | 3.79e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.16e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.77    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 34397    |\n",
      "|    policy_loss        | 617      |\n",
      "|    value_loss         | 6.41e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 104       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.3     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 34496     |\n",
      "|    policy_loss        | -92.6     |\n",
      "|    value_loss         | 49.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.19e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 102      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 38       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.75    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 34595    |\n",
      "|    policy_loss        | -312     |\n",
      "|    value_loss         | 2.02e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.19e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 102       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 48        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.63     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 34694     |\n",
      "|    policy_loss        | -1.07e+03 |\n",
      "|    value_loss         | 1.87e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.18e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 57        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -11.3     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 34793     |\n",
      "|    policy_loss        | 3.58e+03  |\n",
      "|    value_loss         | 1.16e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 104      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 66       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.72    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 34892    |\n",
      "|    policy_loss        | 1.29e+03 |\n",
      "|    value_loss         | 3.47e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 75       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.6    |\n",
      "|    explained_variance | 1.73e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 34991    |\n",
      "|    policy_loss        | -86.6    |\n",
      "|    value_loss         | 43.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 84       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.46    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 35090    |\n",
      "|    policy_loss        | 691      |\n",
      "|    value_loss         | 1.28e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  14220.023607701189  CHF   Episodes learned:  36\n",
      "37\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.15e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12      |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 35248    |\n",
      "|    policy_loss        | 7.49e+03 |\n",
      "|    value_loss         | 3.79e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.19e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 35347    |\n",
      "|    policy_loss        | 472      |\n",
      "|    value_loss         | 6.45e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | 1.49e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 35446    |\n",
      "|    policy_loss        | -89.2    |\n",
      "|    value_loss         | 48.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.73    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 35545    |\n",
      "|    policy_loss        | -258     |\n",
      "|    value_loss         | 2.2e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.69     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 35644     |\n",
      "|    policy_loss        | -1.18e+03 |\n",
      "|    value_loss         | 1.95e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.2e+03   |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.72     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 35743     |\n",
      "|    policy_loss        | 2.97e+03  |\n",
      "|    value_loss         | 1.16e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.65    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 35842    |\n",
      "|    policy_loss        | 1.17e+03 |\n",
      "|    value_loss         | 3.47e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.7    |\n",
      "|    explained_variance | 2.5e-06  |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 35941    |\n",
      "|    policy_loss        | -91.9    |\n",
      "|    value_loss         | 49.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.51    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36040    |\n",
      "|    policy_loss        | 612      |\n",
      "|    value_loss         | 1.18e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15245.319452512718  CHF   Episodes learned:  37\n",
      "38\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.16e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12      |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36198    |\n",
      "|    policy_loss        | 7.56e+03 |\n",
      "|    value_loss         | 3.78e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.73    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36297    |\n",
      "|    policy_loss        | 539      |\n",
      "|    value_loss         | 6.49e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36396    |\n",
      "|    policy_loss        | -111     |\n",
      "|    value_loss         | 56       |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.17e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 111       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.89     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 36495     |\n",
      "|    policy_loss        | 263       |\n",
      "|    value_loss         | 3.47e+03  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.16e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.64     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 36594     |\n",
      "|    policy_loss        | -1.22e+03 |\n",
      "|    value_loss         | 2.03e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.15e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36693    |\n",
      "|    policy_loss        | 3.37e+03 |\n",
      "|    value_loss         | 1.16e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.15e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.61    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36792    |\n",
      "|    policy_loss        | 1.47e+03 |\n",
      "|    value_loss         | 3.46e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.14e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.3    |\n",
      "|    explained_variance | 2.62e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36891    |\n",
      "|    policy_loss        | -90.9    |\n",
      "|    value_loss         | 45.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.14e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 36990    |\n",
      "|    policy_loss        | 530      |\n",
      "|    value_loss         | 1.16e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  14549.005797555204  CHF   Episodes learned:  38\n",
      "39\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 37148    |\n",
      "|    policy_loss        | 7.07e+03 |\n",
      "|    value_loss         | 3.78e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.5     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 37247    |\n",
      "|    policy_loss        | 559      |\n",
      "|    value_loss         | 6.49e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 1.37e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 37346    |\n",
      "|    policy_loss        | -120     |\n",
      "|    value_loss         | 70.9     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.74    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 37445    |\n",
      "|    policy_loss        | -546     |\n",
      "|    value_loss         | 8.57e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.72    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 37544    |\n",
      "|    policy_loss        | -935     |\n",
      "|    value_loss         | 2.11e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.27     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 37643     |\n",
      "|    policy_loss        | 3.07e+03  |\n",
      "|    value_loss         | 1.16e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.08e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.96    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 37742    |\n",
      "|    policy_loss        | 1.46e+03 |\n",
      "|    value_loss         | 3.45e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.1e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 72       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.4    |\n",
      "|    explained_variance | 2.62e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 37841    |\n",
      "|    policy_loss        | -92.7    |\n",
      "|    value_loss         | 41.4     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.11e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 891       |\n",
      "|    time_elapsed       | 80        |\n",
      "|    total_timesteps    | 8910      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -8.06     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 37940     |\n",
      "|    policy_loss        | 789       |\n",
      "|    value_loss         | 1.27e+04  |\n",
      "-------------------------------------\n",
      "Validation reward:  15537.197425547394  CHF   Episodes learned:  39\n",
      "40\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 38098    |\n",
      "|    policy_loss        | 9.38e+03 |\n",
      "|    value_loss         | 3.8e+05  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.74    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 38197    |\n",
      "|    policy_loss        | 521      |\n",
      "|    value_loss         | 6.32e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.26e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 38296     |\n",
      "|    policy_loss        | -98.6     |\n",
      "|    value_loss         | 54.5      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.26e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.64    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 38395    |\n",
      "|    policy_loss        | 277      |\n",
      "|    value_loss         | 3.32e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.38     |\n",
      "|    explained_variance | 1.19e-07  |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 38494     |\n",
      "|    policy_loss        | -1.01e+03 |\n",
      "|    value_loss         | 2.19e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.24e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 54        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -9.08     |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 38593     |\n",
      "|    policy_loss        | 2.49e+03  |\n",
      "|    value_loss         | 1.15e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.24e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 63       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.18    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 38692    |\n",
      "|    policy_loss        | 1.1e+03  |\n",
      "|    value_loss         | 3.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.7    |\n",
      "|    explained_variance | 2.38e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 38791    |\n",
      "|    policy_loss        | -103     |\n",
      "|    value_loss         | 58.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.2e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 81       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 38890    |\n",
      "|    policy_loss        | 547      |\n",
      "|    value_loss         | 1.08e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  13668.408634223519  CHF   Episodes learned:  40\n",
      "41\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.98e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -10.3    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39048    |\n",
      "|    policy_loss        | 6.17e+03 |\n",
      "|    value_loss         | 3.77e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.02    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39147    |\n",
      "|    policy_loss        | 541      |\n",
      "|    value_loss         | 6.46e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.9    |\n",
      "|    explained_variance | 2.21e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39246    |\n",
      "|    policy_loss        | -126     |\n",
      "|    value_loss         | 78.5     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2e+03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 35       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.8     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39345    |\n",
      "|    policy_loss        | -804     |\n",
      "|    value_loss         | 1.85e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.96e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 112       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 44        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.91     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 39444     |\n",
      "|    policy_loss        | -1.2e+03  |\n",
      "|    value_loss         | 2.26e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.93e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39543    |\n",
      "|    policy_loss        | 2.1e+03  |\n",
      "|    value_loss         | 1.16e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.92e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.85    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39642    |\n",
      "|    policy_loss        | 1.39e+03 |\n",
      "|    value_loss         | 3.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.91e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -11.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39741    |\n",
      "|    policy_loss        | -85.5    |\n",
      "|    value_loss         | 71       |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.9e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.63    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39840    |\n",
      "|    policy_loss        | 384      |\n",
      "|    value_loss         | 9.4e+03  |\n",
      "------------------------------------\n",
      "Validation reward:  13277.553226363507  CHF   Episodes learned:  41\n",
      "42\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.94e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 115      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -9.79    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 39998    |\n",
      "|    policy_loss        | 5.49e+03 |\n",
      "|    value_loss         | 3.77e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 116      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 17       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.74    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40097    |\n",
      "|    policy_loss        | 470      |\n",
      "|    value_loss         | 6.4e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.07e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 113       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 26        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -15.2     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 40196     |\n",
      "|    policy_loss        | -99.3     |\n",
      "|    value_loss         | 56.7      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 113      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 34       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40295    |\n",
      "|    policy_loss        | 280      |\n",
      "|    value_loss         | 2.93e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.11e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 43       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40394    |\n",
      "|    policy_loss        | -872     |\n",
      "|    value_loss         | 2.34e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 52       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.48    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40493    |\n",
      "|    policy_loss        | 2.64e+03 |\n",
      "|    value_loss         | 1.16e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 61       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.71    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40592    |\n",
      "|    policy_loss        | 1.13e+03 |\n",
      "|    value_loss         | 3.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 70       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.2    |\n",
      "|    explained_variance | 2.44e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40691    |\n",
      "|    policy_loss        | -106     |\n",
      "|    value_loss         | 61.3     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 79       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.64    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40790    |\n",
      "|    policy_loss        | 515      |\n",
      "|    value_loss         | 6.64e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  12566.998426658762  CHF   Episodes learned:  42\n",
      "43\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.95e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.22    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 40948    |\n",
      "|    policy_loss        | 5.26e+03 |\n",
      "|    value_loss         | 3.77e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.02e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.49    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41047    |\n",
      "|    policy_loss        | 374      |\n",
      "|    value_loss         | 6.42e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.06e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 1.91e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41146    |\n",
      "|    policy_loss        | -114     |\n",
      "|    value_loss         | 69.5     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.04e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -6.43     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 41245     |\n",
      "|    policy_loss        | -2.39e+03 |\n",
      "|    value_loss         | 1.21e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.98e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.3     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41344    |\n",
      "|    policy_loss        | -951     |\n",
      "|    value_loss         | 2.41e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.95e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 54       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.54    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41443    |\n",
      "|    policy_loss        | 1.84e+03 |\n",
      "|    value_loss         | 1.15e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.93e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41542    |\n",
      "|    policy_loss        | 1.17e+03 |\n",
      "|    value_loss         | 3.44e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.89e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -11.4    |\n",
      "|    explained_variance | 1.61e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41641    |\n",
      "|    policy_loss        | -95.5    |\n",
      "|    value_loss         | 71.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.89e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.99    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41740    |\n",
      "|    policy_loss        | 460      |\n",
      "|    value_loss         | 9.32e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  13473.358597613622  CHF   Episodes learned:  43\n",
      "44\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.89e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.87    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41898    |\n",
      "|    policy_loss        | 5.04e+03 |\n",
      "|    value_loss         | 3.77e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2e+03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.76    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 41997    |\n",
      "|    policy_loss        | 254      |\n",
      "|    value_loss         | 6.38e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.99e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.7    |\n",
      "|    explained_variance | 1.25e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 42096    |\n",
      "|    policy_loss        | -121     |\n",
      "|    value_loss         | 72.7     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.98e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 35        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.67     |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 42195     |\n",
      "|    policy_loss        | -1.47e+03 |\n",
      "|    value_loss         | 6.72e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2e+03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 45       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.6     |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 42294    |\n",
      "|    policy_loss        | -674     |\n",
      "|    value_loss         | 2.49e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2e+03    |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.84    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 42393    |\n",
      "|    policy_loss        | 1.33e+03 |\n",
      "|    value_loss         | 1.15e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.99e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.32    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 42492    |\n",
      "|    policy_loss        | 1.08e+03 |\n",
      "|    value_loss         | 3.43e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.95e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.2    |\n",
      "|    explained_variance | 1.61e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 42591    |\n",
      "|    policy_loss        | -102     |\n",
      "|    value_loss         | 75.1     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.93e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.21    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 42690    |\n",
      "|    policy_loss        | 465      |\n",
      "|    value_loss         | 9.26e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  12555.68027048677  CHF   Episodes learned:  44\n",
      "45\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.76e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 94        |\n",
      "|    iterations         | 99        |\n",
      "|    time_elapsed       | 10        |\n",
      "|    total_timesteps    | 990       |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -7.66     |\n",
      "|    explained_variance | -3.58e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 42848     |\n",
      "|    policy_loss        | 5.39e+03  |\n",
      "|    value_loss         | 3.76e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.9e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 100      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 19       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.07    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 42947    |\n",
      "|    policy_loss        | 398      |\n",
      "|    value_loss         | 6.38e+03 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2e+03     |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 297       |\n",
      "|    time_elapsed       | 28        |\n",
      "|    total_timesteps    | 2970      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -14.9     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 43046     |\n",
      "|    policy_loss        | -95.2     |\n",
      "|    value_loss         | 57.9      |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.05e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.08    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43145    |\n",
      "|    policy_loss        | 308      |\n",
      "|    value_loss         | 3.3e+03  |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.04e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.08    |\n",
      "|    explained_variance | 1.19e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43244    |\n",
      "|    policy_loss        | -838     |\n",
      "|    value_loss         | 2.56e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.24    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43343    |\n",
      "|    policy_loss        | 1.84e+03 |\n",
      "|    value_loss         | 1.15e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.01e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.09    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43442    |\n",
      "|    policy_loss        | 532      |\n",
      "|    value_loss         | 3.41e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.02e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -13.4    |\n",
      "|    explained_variance | 2.44e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43541    |\n",
      "|    policy_loss        | -103     |\n",
      "|    value_loss         | 60.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.03e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.12    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43640    |\n",
      "|    policy_loss        | 452      |\n",
      "|    value_loss         | 1.11e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  14519.316850998766  CHF   Episodes learned:  45\n",
      "46\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.12e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 112      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -8.69    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43798    |\n",
      "|    policy_loss        | 5.12e+03 |\n",
      "|    value_loss         | 3.76e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.15e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -4.98     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 43897     |\n",
      "|    policy_loss        | 284       |\n",
      "|    value_loss         | 6.31e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.3    |\n",
      "|    explained_variance | 7.75e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 43996    |\n",
      "|    policy_loss        | -139     |\n",
      "|    value_loss         | 94.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.09e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 109      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 36       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.13    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44095    |\n",
      "|    policy_loss        | 141      |\n",
      "|    value_loss         | 2e+03    |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.13e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 109       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 45        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.27     |\n",
      "|    explained_variance | -8.34e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 44194     |\n",
      "|    policy_loss        | -842      |\n",
      "|    value_loss         | 2.65e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.15e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 53       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -7.12    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44293    |\n",
      "|    policy_loss        | 2.11e+03 |\n",
      "|    value_loss         | 1.15e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.17e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 62       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.07    |\n",
      "|    explained_variance | 2.38e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44392    |\n",
      "|    policy_loss        | 969      |\n",
      "|    value_loss         | 3.41e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.18e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 71       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.5    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44491    |\n",
      "|    policy_loss        | -87.2    |\n",
      "|    value_loss         | 42.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.19e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 80       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.12    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44590    |\n",
      "|    policy_loss        | 406      |\n",
      "|    value_loss         | 1.28e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  15937.175143841125  CHF   Episodes learned:  46\n",
      "47\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.28e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.1    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44748    |\n",
      "|    policy_loss        | 9.73e+03 |\n",
      "|    value_loss         | 3.78e+05 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.28e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 198      |\n",
      "|    time_elapsed       | 18       |\n",
      "|    total_timesteps    | 1980     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.25    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44847    |\n",
      "|    policy_loss        | 407      |\n",
      "|    value_loss         | 6.32e+03 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.27e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 108      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 27       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -14.5    |\n",
      "|    explained_variance | 1.19e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 44946    |\n",
      "|    policy_loss        | -105     |\n",
      "|    value_loss         | 65.7     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.25e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 396      |\n",
      "|    time_elapsed       | 37       |\n",
      "|    total_timesteps    | 3960     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.19    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 45045    |\n",
      "|    policy_loss        | 344      |\n",
      "|    value_loss         | 3.2e+03  |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 46        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.18     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 45144     |\n",
      "|    policy_loss        | -1.11e+03 |\n",
      "|    value_loss         | 2.76e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.23e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 594      |\n",
      "|    time_elapsed       | 55       |\n",
      "|    total_timesteps    | 5940     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.07    |\n",
      "|    explained_variance | 5.96e-08 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 45243    |\n",
      "|    policy_loss        | 1.53e+03 |\n",
      "|    value_loss         | 1.14e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 2.23e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 693       |\n",
      "|    time_elapsed       | 64        |\n",
      "|    total_timesteps    | 6930      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.18     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 45342     |\n",
      "|    policy_loss        | 1.1e+03   |\n",
      "|    value_loss         | 3.42e+04  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.22e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 73       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -12.2    |\n",
      "|    explained_variance | 1.49e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 45441    |\n",
      "|    policy_loss        | -114     |\n",
      "|    value_loss         | 81.8     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 2.21e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 82       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.29    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 45540    |\n",
      "|    policy_loss        | 481      |\n",
      "|    value_loss         | 9.19e+03 |\n",
      "------------------------------------\n",
      "Validation reward:  12820.890834877951  CHF   Episodes learned:  47\n",
      "48\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.83e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 110      |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 8        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.93    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 45698    |\n",
      "|    policy_loss        | 4.04e+03 |\n",
      "|    value_loss         | 3.76e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.75e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 110       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 17        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.31     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 45797     |\n",
      "|    policy_loss        | 320       |\n",
      "|    value_loss         | 6.3e+03   |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.69e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 111      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 26       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15      |\n",
      "|    explained_variance | 2.09e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 45896    |\n",
      "|    policy_loss        | -147     |\n",
      "|    value_loss         | 111      |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.65e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 37        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.35     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 45995     |\n",
      "|    policy_loss        | -1.42e+03 |\n",
      "|    value_loss         | 1.04e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 107      |\n",
      "|    iterations         | 495      |\n",
      "|    time_elapsed       | 46       |\n",
      "|    total_timesteps    | 4950     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.26    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 46094    |\n",
      "|    policy_loss        | -932     |\n",
      "|    value_loss         | 2.83e+04 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.69e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 56        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.31     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 46193     |\n",
      "|    policy_loss        | 1.1e+03   |\n",
      "|    value_loss         | 1.15e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.7e+03  |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 65       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.31    |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 46292    |\n",
      "|    policy_loss        | 769      |\n",
      "|    value_loss         | 3.41e+04 |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.69e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 105      |\n",
      "|    iterations         | 792      |\n",
      "|    time_elapsed       | 74       |\n",
      "|    total_timesteps    | 7920     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.63    |\n",
      "|    explained_variance | 3.81e-06 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 46391    |\n",
      "|    policy_loss        | -60.3    |\n",
      "|    value_loss         | 97.2     |\n",
      "------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.67e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 891      |\n",
      "|    time_elapsed       | 83       |\n",
      "|    total_timesteps    | 8910     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.6     |\n",
      "|    explained_variance | 0        |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 46490    |\n",
      "|    policy_loss        | 514      |\n",
      "|    value_loss         | 1.13e+04 |\n",
      "------------------------------------\n",
      "Validation reward:  10487.645789321865  CHF   Episodes learned:  48\n",
      "49\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.68e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 99       |\n",
      "|    iterations         | 99       |\n",
      "|    time_elapsed       | 9        |\n",
      "|    total_timesteps    | 990      |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -6.29    |\n",
      "|    explained_variance | 2.98e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 46648    |\n",
      "|    policy_loss        | 3.14e+03 |\n",
      "|    value_loss         | 3.76e+05 |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.64e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 100       |\n",
      "|    iterations         | 198       |\n",
      "|    time_elapsed       | 19        |\n",
      "|    total_timesteps    | 1980      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.68     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 46747     |\n",
      "|    policy_loss        | 411       |\n",
      "|    value_loss         | 6.26e+03  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.67e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 101      |\n",
      "|    iterations         | 297      |\n",
      "|    time_elapsed       | 29       |\n",
      "|    total_timesteps    | 2970     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -15.6    |\n",
      "|    explained_variance | 4.77e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 46846    |\n",
      "|    policy_loss        | -137     |\n",
      "|    value_loss         | 93.9     |\n",
      "------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.64e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 103       |\n",
      "|    iterations         | 396       |\n",
      "|    time_elapsed       | 38        |\n",
      "|    total_timesteps    | 3960      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.6      |\n",
      "|    explained_variance | 0         |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 46945     |\n",
      "|    policy_loss        | -2.43e+03 |\n",
      "|    value_loss         | 1.17e+05  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.64e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 105       |\n",
      "|    iterations         | 495       |\n",
      "|    time_elapsed       | 47        |\n",
      "|    total_timesteps    | 4950      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.5      |\n",
      "|    explained_variance | -2.38e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 47044     |\n",
      "|    policy_loss        | -857      |\n",
      "|    value_loss         | 2.88e+04  |\n",
      "-------------------------------------\n",
      "-------------------------------------\n",
      "| rollout/              |           |\n",
      "|    ep_len_mean        | 95        |\n",
      "|    ep_rew_mean        | 1.63e+03  |\n",
      "| time/                 |           |\n",
      "|    fps                | 106       |\n",
      "|    iterations         | 594       |\n",
      "|    time_elapsed       | 55        |\n",
      "|    total_timesteps    | 5940      |\n",
      "| train/                |           |\n",
      "|    entropy_loss       | -5.73     |\n",
      "|    explained_variance | -1.19e-07 |\n",
      "|    learning_rate      | 0.0001    |\n",
      "|    n_updates          | 47143     |\n",
      "|    policy_loss        | 1.78e+03  |\n",
      "|    value_loss         | 1.15e+05  |\n",
      "-------------------------------------\n",
      "------------------------------------\n",
      "| rollout/              |          |\n",
      "|    ep_len_mean        | 95       |\n",
      "|    ep_rew_mean        | 1.64e+03 |\n",
      "| time/                 |          |\n",
      "|    fps                | 106      |\n",
      "|    iterations         | 693      |\n",
      "|    time_elapsed       | 64       |\n",
      "|    total_timesteps    | 6930     |\n",
      "| train/                |          |\n",
      "|    entropy_loss       | -5.55    |\n",
      "|    explained_variance | 1.79e-07 |\n",
      "|    learning_rate      | 0.0001   |\n",
      "|    n_updates          | 47242    |\n",
      "|    policy_loss        | 703      |\n",
      "|    value_loss         | 3.41e+04 |\n",
      "------------------------------------\n"
     ]
    }
   ],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "model = None\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for j in range(0,4286):\n",
    "    week_nr = 0\n",
    "    if count == 0:\n",
    "    # load discrete car-sharing table\n",
    "        sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 15\".format(0)\n",
    "        data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 15\".format(0)\n",
    "        planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 15\".format(0)\n",
    "        planned_durations = pd.read_sql(sql, engine)\n",
    "    counter = 0\n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "\n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = counter * 96 \n",
    "\n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "        # load reservations\n",
    "        reservations = reservations_dict_simulation[date_day_string]\n",
    "\n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict_simulation[date_day_string]\n",
    "\n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict_simulation[date_day_string]\n",
    "\n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "        # reset environment at beginnning of simulation\n",
    "        if count == 0:\n",
    "            environment = CarsharingEnv(stations, vehicles, planned_bookings = True, \n",
    "                               daily_data = daily_data, reservations = reservations, electricity_price = electricity_price, soc_initial_low=0.0, soc_initial_high=0.0,\n",
    "                                timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day, \n",
    "                                planned_durations = planned_durations_day, random_seed_number = 42,penalty_per_kwh = 1.0, v2g_demand_event_min = 10, v2g_demand_event_max = 10, v2g_penalty = 100, RL = True)\n",
    "            s = environment.reset()\n",
    "\n",
    "            # create RL model\n",
    "             #model = PPO(\"MlpPolicy\",environment, verbose=2, ent_coef=0.0, stats_window_size = 10, n_epochs = 1, n_steps=95, batch_size = 95, device =\"cpu\", max_grad_norm = 10)\n",
    "            model = A2C(\"MlpPolicy\",environment, verbose=2, device =\"cpu\", n_steps=10,stats_window_size = 100, learning_rate=0.0001,  vf_coef=0.25, ent_coef=0.01, max_grad_norm=0.5)\n",
    "            #model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "            #    nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 100),  # Modify the first layer\n",
    "            #    nn.Tanh(),\n",
    "             #   nn.Linear(100, 42),\n",
    "             #   model.policy.mlp_extractor.policy_net[3]\n",
    "            #)\n",
    "            #model.policy.action_net =  nn.Linear(42, 300)\n",
    "            #model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "            #    nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 42),  # Modify the first layer\n",
    "            #    nn.Tanh(),\n",
    "            #    nn.Linear(42, 42),\n",
    "            #    model.policy.mlp_extractor.value_net[3]\n",
    "            #)\n",
    "            #model.policy.value_net =  nn.Linear(42, 1)\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"stdout\", \"tensorboard\"])\n",
    "            model.set_logger(new_logger)\n",
    "\n",
    "            #model.policy.to(device)\n",
    "\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        else: \n",
    "            #env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                #          electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                #          planned_durations = planned_durations_day)\n",
    "            s = environment.reset()\n",
    "\n",
    "\n",
    "        # learn one episode\n",
    "        print(count)\n",
    "        model.learn(total_timesteps=95* 100, reset_num_timesteps=True, log_interval  = 99)\n",
    "\n",
    "\n",
    "        \n",
    "        r = validation(model)\n",
    "        print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "        reward_list.append(r)\n",
    "        count_list.append(count* 100)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        count += 1\n",
    "    if count == 5000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 10000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 20000:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "    if count == 29990:\n",
    "        model.save(\"car_sharing_v2g_model_small\")\n",
    "        np.save(\"reward_list_model_small\", reward_list)\n",
    "        np.save(\"count_list_model_small\", count_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e44289c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bba8ea12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f2d599",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "298858e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396c744a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cc3af0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8c086a0e-e349-4b00-9f13-e68bf34c1d68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model2 = None\n",
    "count_next_start = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for j in range(0,70):\n",
    "    print(j)\n",
    "    week_nr = random.randrange(1,80)\n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "\n",
    "    # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "    # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "    counter = 0\n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "\n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = counter * 96 + week_nr*7*96\n",
    "\n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "\n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "\n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "\n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "\n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "        # reset environment at beginnning of simulation\n",
    "        if count_next_start == 0:\n",
    "\n",
    "            model2 = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "            model2.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 64),\n",
    "                model.policy.mlp_extractor.policy_net[3]\n",
    "            )\n",
    "            model2.policy.action_net =  nn.Linear(64, 30)\n",
    "            model2.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(64, 64),\n",
    "                model.policy.mlp_extractor.value_net[3]\n",
    "            )\n",
    "            model2.policy.value_net =  nn.Linear(64, 1)\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "            model2.set_logger(new_logger)\n",
    "            model2.set_parameters(\"car_sharing_v2g_model_small\", device = \"cpu\")\n",
    "\n",
    "            new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "            model2.set_logger(new_logger)\n",
    "\n",
    "            #model.policy.to(device)\n",
    "\n",
    "            r = validation(model2)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        else: \n",
    "            env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                          electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                          planned_durations = planned_durations_day)\n",
    "            s = env.reset()\n",
    "\n",
    "\n",
    "        # learn one episode\n",
    "        model2.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "\n",
    "\n",
    "        if count in range(5,30000,100):\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "        counter += 1\n",
    "\n",
    "        count += 1\n",
    "        \n",
    "        count_next_start += 1\n",
    "\n",
    "model2.save(\"car_sharing_v2g_model_small\")\n",
    "np.save(\"reward_list_model_small\", reward_list)\n",
    "np.save(\"count_list_model_small\", count_list)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69091f9-3d5e-492a-bf2a-cbe1fd137a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "    model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.policy_net[3]\n",
    "    )\n",
    "    model.policy.action_net =  nn.Linear(64, 30)\n",
    "    model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.value_net[3]\n",
    "    )\n",
    "    model.policy.value_net =  nn.Linear(64, 1)\n",
    "    new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "    model.set_logger(new_logger)\n",
    "    model.set_parameters(\"car_sharing_v2g_model_small\", device = \"cpu\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5451e90e-d376-4e58-8429-399408b467e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3b11ce-2cdf-4e51-8f4d-be8e7ffac0ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd422f3-658c-4baf-8e96-bd97eb0658fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47fac97-9e37-4001-b613-312ed70d4240",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "\n",
    "model = None\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for i in range(0,60):\n",
    "    print(i)\n",
    "    for j in range(0,70):\n",
    "        print(j)\n",
    "        week_nr = random.randrange(1,80)\n",
    "        # load discrete car-sharing table\n",
    "        sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "        data = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "        planned_reservations = pd.read_sql(sql, engine)\n",
    "\n",
    "        # load discrete planned reservation duration table\n",
    "        sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no limit 10\".format(week_nr)\n",
    "        planned_durations = pd.read_sql(sql, engine)\n",
    "        counter = 0\n",
    "        # iteration for each day\n",
    "        for day in range(98,676,96):\n",
    "\n",
    "            # calculate number of timesteps since first day of simulation\n",
    "            timesteps_since_start = counter * 96 + week_nr*7*96\n",
    "\n",
    "            # all requested days are simulated\n",
    "            if count == nr_iterations:\n",
    "                break\n",
    "\n",
    "            # get date\n",
    "            date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "            date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "\n",
    "            # load reservations\n",
    "            reservations = reservations_dict[date_day_string]\n",
    "\n",
    "            # load electricity prices for charging\n",
    "            electricity_price = charging_costs_dict[date_day_string]\n",
    "\n",
    "            # load secondary energy prices for v2g\n",
    "            v2g_price = v2g_price_dict[date_day_string]\n",
    "\n",
    "            # select discrete data of day\n",
    "            daily_data = data.iloc[:,day-97:day-1]\n",
    "            planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "            planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "\n",
    "            # reset environment at beginnning of simulation\n",
    "            if count == 0:\n",
    "\n",
    "                # create environment\n",
    "                env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 100, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                               electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                               planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 234, RL = True, v2g_demand_event_min = 10, v2g_demand_event_max = 10)\n",
    "\n",
    "                # create RL model\n",
    "                model = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "                model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                    nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    model.policy.mlp_extractor.policy_net[3]\n",
    "                )\n",
    "                model.policy.action_net =  nn.Linear(64, 30)\n",
    "                model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                    nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "                    nn.Tanh(),\n",
    "                    nn.Linear(64, 64),\n",
    "                    model.policy.mlp_extractor.value_net[3]\n",
    "                )\n",
    "                model.policy.value_net =  nn.Linear(64, 1)\n",
    "                new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "                model.set_logger(new_logger)\n",
    "\n",
    "                #model.policy.to(device)\n",
    "\n",
    "                r = validation(model)\n",
    "                print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "                reward_list.append(r)\n",
    "                count_list.append(count)\n",
    "\n",
    "            else: \n",
    "                env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                              electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                              planned_durations = planned_durations_day)\n",
    "                s = env.reset()\n",
    "                \n",
    "            print(\"day\")\n",
    "\n",
    "\n",
    "            # learn one episode\n",
    "            model.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "\n",
    "\n",
    "            if count in range(5,30000,100):\n",
    "                r = validation(model)\n",
    "                print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "                reward_list.append(r)\n",
    "                count_list.append(count)\n",
    "\n",
    "            counter += 1\n",
    "\n",
    "            count += 1\n",
    "   \n",
    "    model.save(\"car_sharing_v2g_model_small\")\n",
    "    np.save(\"reward_list_model_small\", reward_list)\n",
    "    np.save(\"count_list_model_small\", count_list)\n",
    "    \n",
    "    # create environment\n",
    "    env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 100, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                               electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                               planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 234, RL = True, v2g_demand_event_min = 10, v2g_demand_event_max = 10)\n",
    "\n",
    "    \n",
    "    \n",
    "    model = PPO(\"MlpPolicy\",env, verbose=0, stats_window_size = 1, n_epochs = 1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "    model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.policy_net[3]\n",
    "    )\n",
    "    model.policy.action_net =  nn.Linear(64, 30)\n",
    "    model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "        nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 64),  # Modify the first layer\n",
    "        nn.Tanh(),\n",
    "        nn.Linear(64, 64),\n",
    "        model.policy.mlp_extractor.value_net[3]\n",
    "    )\n",
    "    model.policy.value_net =  nn.Linear(64, 1)\n",
    "    new_logger = configure( \"/tmp/sb3_log/\", [\"csv\", \"tensorboard\"])\n",
    "    model.set_logger(new_logger)\n",
    "    model.set_parameters(\"car_sharing_v2g_model_small\", device = \"cpu\")\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c3541b2-3be5-4b3f-a9d7-55e5ed210aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%snakeviz\n",
    "# get number of vehicles\n",
    "nr_vehicles = len(vehicles)\n",
    "\n",
    "# maximal simulation length\n",
    "if nr_iterations > 577:\n",
    "    nr_iterations = 577\n",
    "\n",
    "reward_list = []\n",
    "count_list = []\n",
    "count = 0\n",
    "# iterate over weeks (for loading weekly discrete data)\n",
    "for week_nr in range(start_week, math.ceil((start_week * 7 + nr_iterations) / 7)):\n",
    "    # load discrete car-sharing table\n",
    "    sql =  \"SELECT * FROM discrete.discrete_weeks_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    data = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_reservations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_reservations = pd.read_sql(sql, engine)\n",
    "    \n",
    "    # load discrete planned reservation duration table\n",
    "    sql =  \"SELECT * FROM msc_2023_dominik.planned_durations_discrete_{} ORDER BY vehicle_no\".format(week_nr)\n",
    "    planned_durations = pd.read_sql(sql, engine)\n",
    "        \n",
    "    # iteration for each day\n",
    "    for day in range(98,676,96):\n",
    "        \n",
    "        # calculate number of timesteps since first day of simulation\n",
    "        timesteps_since_start = count * 96 + week_nr*7*96\n",
    "        \n",
    "        # all requested days are simulated\n",
    "        if count == nr_iterations:\n",
    "            break\n",
    "            \n",
    "        # get date\n",
    "        date_day = pd.to_datetime(data.columns[day-97]).date()\n",
    "        date_day_string = date_day.strftime('%Y-%m-%d')\n",
    "        \n",
    "        # load reservations\n",
    "        reservations = reservations_dict[date_day_string]\n",
    "        \n",
    "        # load electricity prices for charging\n",
    "        electricity_price = charging_costs_dict[date_day_string]\n",
    "        \n",
    "        # load secondary energy prices for v2g\n",
    "        v2g_price = v2g_price_dict[date_day_string]\n",
    "    \n",
    "        # select discrete data of day\n",
    "        daily_data = data.iloc[:,day-97:day-1]\n",
    "        planned_reservations_day = planned_reservations.iloc[:,day-97 + 1:day + 1] \n",
    "        planned_durations_day = planned_durations.iloc[:,day-97 + 1:day + 1] \n",
    "        \n",
    "        # reset environment at beginnning of simulation\n",
    "        if count == 0:\n",
    "            \n",
    "            # create environment\n",
    "            env = CarsharingEnv(stations, vehicles, planned_bookings = True, v2g_penalty = 499, penalty_per_kwh = 1.0, daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day, max_distance_car_assingment=300, random_seed_number = 15451)\n",
    "            model = PPO(\"MlpPolicy\",env, verbose=1, n_steps=95, batch_size = 95,device =\"cpu\")\n",
    "            model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 1024),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1024, 5120),\n",
    "                model.policy.mlp_extractor.policy_net[3]\n",
    "            )\n",
    "            model.policy.action_net =  nn.Linear(5120, 13260)\n",
    "            model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "                nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 1028),  # Modify the first layer\n",
    "                nn.Tanh(),\n",
    "                nn.Linear(1028, 128),\n",
    "                model.policy.mlp_extractor.value_net[3]\n",
    "            )\n",
    "            model.policy.value_net =  nn.Linear(128, 1)\n",
    "            \n",
    "            # load parameters \n",
    "            model.set_parameters(\"car_sharing_v2g_model1\", device = \"cpu\")\n",
    "            \n",
    "            #model.policy.to(device)\n",
    "            \n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "            \n",
    "        else: \n",
    "            env.load_new_data(daily_data = daily_data, reservations = reservations,\n",
    "                           electricity_price = electricity_price, timesteps_since_start = timesteps_since_start, v2g_price = v2g_price, planned_reservations = planned_reservations_day,\n",
    "                           planned_durations = planned_durations_day)\n",
    "            s = env.reset()\n",
    "            \n",
    "        \n",
    "        # learn one episode\n",
    "        model.learn(total_timesteps=95, reset_num_timesteps=False)\n",
    "            \n",
    "          \n",
    "        print(\"\")\n",
    "        print(\"Learned episode: \",count)\n",
    "        print(\"\")\n",
    "        \n",
    "        if count in range(5,nr_iterations + 1,10):\n",
    "            r = validation(model)\n",
    "            print(\"Validation reward: \", r, \" CHF   Episodes learned: \",count)\n",
    "            reward_list.append(r)\n",
    "            count_list.append(count)\n",
    "\n",
    "            \n",
    "        count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7a3bacf7-83ff-4d58-b2ea-05128d063238",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f597a3b1-539c-464f-b981-71dd9440d2a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model2\")\n",
    "np.save(\"reward_list_model2\", reward_list)\n",
    "np.save(\"count_list_model2\", count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "4add6625-62ad-4953-a52f-7c966fa6e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 5, 105, 205, 305, 405, 505]\n"
     ]
    }
   ],
   "source": [
    "print(count_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02dc0c25-c4b2-4e29-97aa-6b90a5bfe5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"car_sharing_v2g_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1d820746-3aff-4879-82cb-f52c5f7183e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=17682, out_features=1024, bias=True)\n",
       "  (1): Tanh()\n",
       "  (2): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "  (3): Tanh()\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.mlp_extractor.policy_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c2b96a66-e203-4bb3-b96f-ecb7eb66befe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ActorCriticPolicy(\n",
       "  (features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (pi_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (vf_features_extractor): FlattenExtractor(\n",
       "    (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  )\n",
       "  (mlp_extractor): MlpExtractor(\n",
       "    (policy_net): Sequential(\n",
       "      (0): Linear(in_features=17682, out_features=1024, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1024, out_features=5120, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "    (value_net): Sequential(\n",
       "      (0): Linear(in_features=17682, out_features=1028, bias=True)\n",
       "      (1): Tanh()\n",
       "      (2): Linear(in_features=1028, out_features=128, bias=True)\n",
       "      (3): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (action_net): Linear(in_features=5120, out_features=13260, bias=True)\n",
       "  (value_net): Linear(in_features=128, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.policy.mlp_extractor.policy_net = nn.Sequential(\n",
    "    nn.Linear(model.policy.mlp_extractor.policy_net[0].in_features, 1024),  # Modify the first layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1024, 5120),\n",
    "    model.policy.mlp_extractor.policy_net[3]\n",
    ")\n",
    "model.policy.action_net =  nn.Linear(5120, 13260)\n",
    "model.policy.mlp_extractor.value_net = nn.Sequential(\n",
    "    nn.Linear(model.policy.mlp_extractor.value_net[0].in_features, 1028),  # Modify the first layer\n",
    "    nn.Tanh(),\n",
    "    nn.Linear(1028, 128),\n",
    "    model.policy.mlp_extractor.value_net[3]\n",
    ")\n",
    "model.policy.value_net =  nn.Linear(128, 1)\n",
    "\n",
    "\n",
    "# print network\n",
    "model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ee091266-a85c-4ddb-b5d7-21312f6afd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.set_parameters(\"car_sharing_v2g_model1\", device = \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d26182bc-b234-410b-90bd-c1511fffc59e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'stable_baselines3.common.net_util'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolicies\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ActorCriticPolicy\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mstable_baselines3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcommon\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnet_util\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FlattenExtractor, MlpExtractor\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mCustomPolicy\u001b[39;00m(ActorCriticPolicy):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'stable_baselines3.common.net_util'"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.policies import ActorCriticPolicy\n",
    "from stable_baselines3.common.net_util import FlattenExtractor, MlpExtractor\n",
    "\n",
    "class CustomPolicy(ActorCriticPolicy):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super(CustomPolicy, self).__init__(*args, **kwargs,\n",
    "                                            net_arch=[dict(pi=[64, 64], vf=[64, 64])],\n",
    "                                            features_extractor_class=FlattenExtractor,\n",
    "                                            features_extractor_kwargs=dict(flatten_dim=1),\n",
    "                                            )\n",
    "        self.mlp_extractor = MlpExtractor(\n",
    "            self.features_extractor.features_dim,\n",
    "            net_arch=[1024, 5120],\n",
    "            activation_fn=torch.nn.Tanh\n",
    "        )\n",
    "\n",
    "model = PPO(CustomPolicy, env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "db7882f4-89cc-4217-a284-d06348b956ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = model.policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ad4be9a8-5aa4-496c-8baa-c5d7af8a6170",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ActorCriticPolicy' object has no attribute 'weights'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweights\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\torch\\nn\\modules\\module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1612\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[0;32m   1613\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[1;32m-> 1614\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   1615\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ActorCriticPolicy' object has no attribute 'weights'"
     ]
    }
   ],
   "source": [
    "model1.weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "aa465bbc-980f-4482-898a-034c5a0867cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for ActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.0.weight: copying a param with shape torch.Size([1024, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.policy_net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.policy_net.2.weight: copying a param with shape torch.Size([5120, 1024]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.policy_net.2.bias: copying a param with shape torch.Size([5120]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.0.weight: copying a param with shape torch.Size([1028, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.value_net.0.bias: copying a param with shape torch.Size([1028]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.2.weight: copying a param with shape torch.Size([128, 1028]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.value_net.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for action_net.weight: copying a param with shape torch.Size([13260, 5120]) from checkpoint, the shape in current model is torch.Size([13260, 64]).\n\tsize mismatch for value_net.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 64]).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcar_sharing_v2g_model1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:737\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    728\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    729\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are probably loading a model saved with SB3 < 1.7.0, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    730\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwe deactivated exact_match so you can save the model \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNote: the model should still work fine, this only a warning.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    735\u001b[0m         )\n\u001b[0;32m    736\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 737\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[0;32m    738\u001b[0m \u001b[38;5;66;03m# put other pytorch variables back in place\u001b[39;00m\n\u001b[0;32m    739\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pytorch_variables \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:721\u001b[0m, in \u001b[0;36mBaseAlgorithm.load\u001b[1;34m(cls, path, env, device, custom_objects, print_system_info, force_reset, **kwargs)\u001b[0m\n\u001b[0;32m    717\u001b[0m model\u001b[38;5;241m.\u001b[39m_setup_model()\n\u001b[0;32m    719\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    720\u001b[0m     \u001b[38;5;66;03m# put state_dicts back in place\u001b[39;00m\n\u001b[1;32m--> 721\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_parameters\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexact_match\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    722\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    723\u001b[0m     \u001b[38;5;66;03m# Patch to load Policy saved using SB3 < 1.7.0\u001b[39;00m\n\u001b[0;32m    724\u001b[0m     \u001b[38;5;66;03m# the error is probably due to old policy being loaded\u001b[39;00m\n\u001b[0;32m    725\u001b[0m     \u001b[38;5;66;03m# See https://github.com/DLR-RM/stable-baselines3/issues/1233\u001b[39;00m\n\u001b[0;32m    726\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpi_features_extractor\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\stable_baselines3\\common\\base_class.py:615\u001b[0m, in \u001b[0;36mBaseAlgorithm.set_parameters\u001b[1;34m(self, load_path_or_dict, exact_match, device)\u001b[0m\n\u001b[0;32m    612\u001b[0m         attr\u001b[38;5;241m.\u001b[39mload_state_dict(params[name])\n\u001b[0;32m    613\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    614\u001b[0m         \u001b[38;5;66;03m# Assume attr is th.nn.Module\u001b[39;00m\n\u001b[1;32m--> 615\u001b[0m         \u001b[43mattr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexact_match\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m     updated_objects\u001b[38;5;241m.\u001b[39madd(name)\n\u001b[0;32m    618\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exact_match \u001b[38;5;129;01mand\u001b[39;00m updated_objects \u001b[38;5;241m!=\u001b[39m objects_needing_update:\n",
      "File \u001b[1;32m~\\.conda\\envs\\simulation_car_sharing\\lib\\site-packages\\torch\\nn\\modules\\module.py:2041\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[1;34m(self, state_dict, strict)\u001b[0m\n\u001b[0;32m   2036\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[0;32m   2037\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k) \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[0;32m   2040\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m-> 2041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   2042\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[0;32m   2043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for ActorCriticPolicy:\n\tsize mismatch for mlp_extractor.policy_net.0.weight: copying a param with shape torch.Size([1024, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.policy_net.0.bias: copying a param with shape torch.Size([1024]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.policy_net.2.weight: copying a param with shape torch.Size([5120, 1024]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.policy_net.2.bias: copying a param with shape torch.Size([5120]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.0.weight: copying a param with shape torch.Size([1028, 17682]) from checkpoint, the shape in current model is torch.Size([64, 17682]).\n\tsize mismatch for mlp_extractor.value_net.0.bias: copying a param with shape torch.Size([1028]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for mlp_extractor.value_net.2.weight: copying a param with shape torch.Size([128, 1028]) from checkpoint, the shape in current model is torch.Size([64, 64]).\n\tsize mismatch for mlp_extractor.value_net.2.bias: copying a param with shape torch.Size([128]) from checkpoint, the shape in current model is torch.Size([64]).\n\tsize mismatch for action_net.weight: copying a param with shape torch.Size([13260, 5120]) from checkpoint, the shape in current model is torch.Size([13260, 64]).\n\tsize mismatch for value_net.weight: copying a param with shape torch.Size([1, 128]) from checkpoint, the shape in current model is torch.Size([1, 64])."
     ]
    }
   ],
   "source": [
    "model.load(\"car_sharing_v2g_model1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35175df5-602a-4d59-a40c-1c07ee9ea4a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
